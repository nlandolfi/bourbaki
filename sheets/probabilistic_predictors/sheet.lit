<!--
!name:probabilistic_predictors
!need:predictors
!need:probability_measures
-->

Â§ Why â¦‰
Â¶ â¦Š
  â€– Let $X = \set{a, b}$ and $Y = \set{0, 1}$. â¦‰

  â€– The dataset $((a, 0))$ is consistent, but it is not
    functionally complete. â¦‰

  â€– On the other hand, the dataset $((a,0), (b,0), (a,0), (a,0),
    (a,0), (a, 1))$ â¦‰

  â€– is complete but it is not â€¹functionallyâ€º consistent. â¦‰
â¦‰

Â¶ â¦Š
  â€– In general, if $y_i â‰  y_j$ for some $i$ and $j$ where
    $x_i = x_j$, then the dataset is not functionally consistent. â¦‰

  â€– In the preceding example, both $(a, 0)$ and $(a, 1)$ appear. â¦‰
â¦‰

Â¶ â¦Š
  â€– If we emphasize the â€œpredictiveâ€ aspect of a functional
    inductor, we interpret the input as an object we â€œsee
    beforeâ€ the output. â¦‰

  â€– And so treat $y âˆˆ Y$ as an uncertain outcome which is the
    element associated to $x âˆˆ X$. â¦‰
â¦‰

Â¶ â¦Š
  â€– In this case, we may use the language of probability to
    discuss this uncertain outcome. â¦‰

  â€– If, for example, $Y$ is finite, we can associate a
    distribution with each input $x âˆˆ X$. â¦‰
â¦‰

Â§ Definition â¦‰
Â¶ â¦Š
  â€– Let $(X, ğ’³)$ and $(Y, ğ’´)$ be measurable spaces. â¦‰
â¦‰

Â¶ â¦Š
  â€– A â¬probabilistic functional inductorâ­ (for a dataset of size
    $n$ in $X Ã—Y$) is a function mapping a dataset in $(X
    Ã—Y)^n$ to a family of measures on $(Y, ğ’´)$, indexed by $X$. â¦‰

  â€– We call a function from inputs to output measures a
    â¬probabilistic predictorâ­. â¦‰

  â€– We call the distribution a â¬probabilistic predictionâ­. â¦‰
â¦‰

Â§Â§ Notation â¦‰
Â¶ â¦Š
  â€– Let $â„³(Y, ğ’´)$ be the set of measures on $Y$. â¦‰

  â€– Let $D$ be a dataset in $(X Ã— Y)^n$. â¦‰

  â€– Let $g: X â†’ â„³(Y, ğ’´)$ a probabilistic predictor. â¦‰

  â€– Let $G_n (X Ã—Y)^n â†’ (X â†’ â„³(Y, ğ’´))$ be a predictive
    probabilistic inductor. â¦‰

  â€– Then $G_n(D)$ is a family of measures $\set{g_x: ğ’´ â†’ [0,
    1]}_{x âˆˆ X}$. â¦‰
â¦‰

<tex>
  â€– \blankpage â¦‰
</tex>
