<!--yaml
name: probabilistic_dataset_models
needs:
    - predictors
    - probability_measures
-->

Â§ Why â¦‰
Â¶ â¦Š
  â€– Let $X = \set{a, b}$ and $Y = \set{0, 1}$. Define $f: X
    â†’ Y$ by $f â‰¡ 0$. â¦‰
â¦‰

Â¶ â¦Š
  â€– The dataset $(a, 0)$ is consistent with $f$. â¦‰

  â€– So are the datasets $((a, 0), (a, 0))$ and $((a, 0), (a,
    0), (a, 0))$. â¦‰

  â€– Unfortunately, these datasets are â€œbadâ€ in the sense that we
    do not see the value associated with $b$. â¦‰

  â€– Each dataset is consistent with the (functional) relations
    $\set{(a, 0), (b, 0)}$ and $\set{(a, 0), (b, 1)}$. â¦‰
â¦‰

Â¶ â¦Š
  â€– In other words, a dataset may be incomplete. â¦‰

  â€– In spite of this limitation, we want to discuss an
    inductor's performance on consistent datasets. â¦‰

  â€– One route is to put a measure on the set of training sets
    and only consider high-measure subsets. â¦‰
â¦‰

<!--
We take two steps.
First, we put a measure on the set of training sets and only consider high-measure subsets.
Second, we consider inductors which perform well in some tolerance.
-->

Â§ Definition â¦‰
Â¶ â¦Š
  â€– Let $(X, ğ’³)$ and $(Y, ğ’´)$ be measurable spaces and $R$ be
    a relation on $X Ã— Y$. â¦‰

  â€– Let $Î¼: ğ’³ Ã— ğ’´ â†’ [0, 1]$ be a probability measure so that
    $ğ’Ÿ = (X Ã— Y, ğ’³ Ã— ğ’´, Î¼)$ is a probability space. â¦‰
â¦‰

Â¶ â¦Š
  â€– If $Î¼(B) = 0$ for all $B âŠ‚ \relcomplement{R}{X Ã—Y}$, then
    we call $ğ’Ÿ$ a â¬probabilistic dataset modelâ­ for $R$. â¦‰

  â€– In other words, $Î¼$ gives zero measure to any set of
    points not in the relation. â¦‰

  â€– Equivalently, $Î¼(R) = 1$; or we observe a pair in $R$
    almost surely. â¦‰
â¦‰

Â¶ â¦Š
  â€– If $R$ is functional, then we call $ğ’Ÿ$ a â¬supervised
    probabilistic dataset modelâ­. â¦‰

  â€– In this case, since there is a functional relation between
    $X$ and $Y$, we call the marginal measure $Î¼_X: ğ’³ â†’ [0,
    1]$ the â¬data-generating distributionâ­ or â¬underlying
    distributionâ­ since $Î¼(A) = Î¼_X(\Set*{x âˆˆ X}{(x, y) âˆˆ A)})$. â¦‰

  â€– In this case we call the (functional) relation $R$ the
    â¬correct labeling functionâ­. â¦‰

  â€– Many authors refer to a supervised probabilistic data model
    as the â¬statistical learning (theory) frameworkâ­. â¦‰
â¦‰

Â§ Probable datasets â¦‰
Â¶ â¦Š
  â€– For datasets of size $n$, we use the product measure $((X
    Ã— Y)^n, (ğ’³ Ã— ğ’´)^n, Î¼^n)$. â¦‰

  â€– We interpret this measure as modeling independent and
    identically distributed elements of $R$. â¦‰
â¦‰

Â¶ â¦Š
  â€– For $Î´ âˆˆ (0, 1)$, $ğ’® âŠ‚ (X Ã—Y)^n$ is â¬$1 - Î´$-probableâ­
    if $Î¼^n(S) â‰¥ 1 - Î´$. â¦‰

  â€– We call $Î´$ the â¬confidence parameterâ­. â¦‰

  â€– If $Î´$ is small, we interpret $ğ’®$ as a set of â€œreasonableâ€
    datasets. â¦‰
â¦‰