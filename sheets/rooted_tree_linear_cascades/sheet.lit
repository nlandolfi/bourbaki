<!--
!name:rooted_tree_linear_cascades
!need:rooted_trees
!need:random_vectors
!need:covariance_matrix
!need:identity_matrix
!need:sparse_matrices
-->

§ Why ⦉
¶ ⦊
  ‖ It is natural to look for a class of structural equation
    models with favorable identifiability and properties. ⦉
⦉

§ Definition ⦉
¶ ⦊
  ‖ A ❬$d$-dimensional rooted tree linear cascade❭ is a sequence
    of four objects: a tree on $\set{1, …, d}$, a vertex of
    the tree, a family of real numbers indexed by the edges of
    the tree, and a $d$-dimensional random vector whose covariance
    matrix is the identity matrix. ⦉

  ‖ The cascade is called “$d$-dimensional” because we associate
    it with a random vector (defined as a function of that in
    the form of its definition) whose codomain is $𝗥^d$. ⦉
⦉

¶ ⦊
  ‖ The tree together with the vertex form a rooted tree. ⦉

  ‖ The graph associated with the rooted tree and the family of
    real numbers together form a weighted graph. ⦉
⦉

¶ ⦊
  ‖ The idea is to use the weights and the tree structure to
    recursively define a random vector in terms of elements of
    the given random vector. ⦉

  ‖ Let $C = (T, i, w, e)$ be a $d$-dimensional rooted tree
    linear cascade. ⦉

  ‖ So $T$ is a tree on $\set{1, …, d}$, $i ∈ \set{1, …, d}$
    and $w: T → 𝗥$, and $e: Ω → 𝗥^d$ for some probability
    space $(A, 𝒜, 𝗣)$. ⦉

  ‖ The random vector associated with $C$ is the random variable
    $x: Ω → 𝗥^d$ defined by
    ◇ ⦊
      ‖ x_i = e_i \text{ and } x_j = w_{\set{\pa{j},
        j}}x_{\pa{j}} + e_{j} \text{ for } j ≠ i. ⦉
    ⦉⦉

  ‖ In other words,
    ◇ ⦊
      ‖ e = Ax ⦉
    ⦉
    where $A$ is lower triangle and extremely sparse. ⦉
⦉

§§ Notation ⦉
¶ ⦊
  ‖ Let $(A, 𝒜, 𝗣)$ be a probability space. ⦉

  ‖ Let $e: A → 𝗥^d$ be a random vector, let $T$ be a tree
    on $\set{1, …, d}$ with $a_{ij} = a_{ji}$ the weight on
    edge $\set{i, j} ∈ T$. ⦉
⦉
