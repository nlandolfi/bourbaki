\input{../../sheet.tex}
\sbasic
\input{../multivariate_normals/macros.tex}
\input{../matrix_determinants/macros.tex}
\input{../multivariate_real_densities/macros.tex}
\input{../normal_densities/macros.tex}
\input{../positive_definite_matrices/macros.tex}
\input{../transpose/macros.tex}
\input{../matrices/macros.tex}
\input{../n-dimensional_space/macros.tex}
\input{../probability_densities/macros.tex}
\input{../quadratic_forms/macros.tex}
\input{../symmetric_matrices/macros.tex}
\input{../vectors/macros.tex}
\input{../real_numbers/macros.tex}
\input{../space/macros.tex}
\input{../probability_distributions/macros.tex}
\input{../identity_matrices/macros.tex}
\input{../fields/macros.tex}
\input{../groups/macros.tex}
\input{../rational_numbers/macros.tex}
\input{../probability_outcomes/macros.tex}
\input{../real_summation/macros.tex}
\input{../algebras/macros.tex}
\input{../integer_numbers/macros.tex}
\input{../cardinality/macros.tex}
\input{../probability/macros.tex}
\input{../natural_summation/macros.tex}
\input{../operations/macros.tex}
\input{../solving_equations/macros.tex}
\input{../injective_functions/macros.tex}
\input{../natural_numbers/macros.tex}
\input{../common_sense/macros.tex}
\input{../arithmetic/macros.tex}
\input{../family_operations/macros.tex}
\input{../functions/macros.tex}
\input{../equations/macros.tex}
\input{../families/macros.tex}
\input{../relations/macros.tex}
\input{../identity/macros.tex}
\input{../set_inclusion/macros.tex}
\input{../set_specification/macros.tex}
\input{../ordered_pairs/macros.tex}
\input{../objects/macros.tex}
\input{../set_equality/macros.tex}
\input{../sentences/macros.tex}
\input{../sets/macros.tex}
\input{./macros.tex}
\sstart
\stitle{Normal Differential Entropy}

\ssection{Why}

What is the differential mutual information
between two components of a multivariate normal.

\ssection{Result}

\begin{prop}
Let $g \sim \normal{\mu}{\Sigma}$
Then the differential entropy of g is
\[
  \frac{1}{2}\ln\left((2\pi e)^d \det\Sigma\right)
\]
\end{prop}
\strats
