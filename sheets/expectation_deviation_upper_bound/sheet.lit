<!--yaml
name: expectation_deviation_upper_bound
needs:
    - tail_measure_upper_bound
wikipedia: https://en.wikipedia.org/wiki/Chebyshev%27s_inequality
-->

§ Why ⦉
¶ ⦊
  ‖ We bound the probability that a random variance deviates
    from its mean using its variance. ⦉
⦉

§ Result ⦉

<!-- TODO: assumptions of integrability -->
<statement type='proposition'>
  ‖ Suppose $f: Ω → 𝗥$ is measurable on the probability space
    $(Ω, ℱ, P)$. ⦉

  ‖ Then
    ◇ ⦊
      ‖ P[\abs{f - 𝗘(f)} ≥ t] ≤ \frac{\var f}{t^2} ⦉

      ‖ \quad \text{ for all } t > 0 ⦉
    ⦉⦉
</statement>
<proof>
  ‖ The symbols $\abs{f - 𝗘(f)} ≥ t$ denote the set $\Set*{x ∈
    X}{ \abs{f(x) - 𝗘(f)} ≥ t}$. ⦉

  ‖ This set is the same as the set
    ◇ ⦊
      ‖ \Set*{x ∈ X}{({f(x) - 𝗘(f)})^2 ≥ t^2}. ⦉
    ⦉⦉

  ‖ By using the␣
    <a href='/sheets/tail_measure_upper_bound.html'>
      ‖ tail measure upper bound ⦉
    </a>
    ,
    ◇ ⦊
      ‖ P(\Set*{x ∈ X}{({f(x) - 𝗘(f)})^2 ≥ t^2}) ⦉

      ‖ ≤ ⦉

      ‖ \frac{𝗘(f - 𝗘(f))^2}{t^2}. ⦉
    ⦉⦉

  ‖ We recognize the numerator of the right hand side as the␣
    <a href='/sheets/variance.html'>
      ‖ variance ⦉
    </a>
    ␣of $f$. ⦉
</proof>
¶ ⦊
  ‖ The above is also called ❬Chebychev’s Inequality❭ (or the
    ❬Chebyshev inequality❭). ⦉
⦉

<tex>
  ‖ \blankpage ⦉
</tex>
