
\section*{Why}

We can add and scale matrices, so the $m \times  n$ matrices are a vector space over $\R $.

\section*{Definition}

The \t{matrix sum} of two matrices $A, B \in \R ^{m \times n}$ is the matrix $C \in \R ^{m \times  n}$ defined by $C_{ij} = A_{ij} + B_{ij}$.
In other words, the matrix $C$ is given by summing the entries of $A$ and $B$ ``entry-wise''.
We denote the matrix sum by $A + B$.

For $\alpha  \in \R $, the \t{$\alpha $-scaling} of $A \in \R ^{m \times  n}$ is the matrix $C \in \R ^{m \times  n}$ defined by $C_{ij} = \alpha  A_{ij}$.
In other words, the matrix $C$ is given by scaling the entries of $A$ ``entry-wise''.
We denote the $\alpha $-scaled version of $A$ by $\alpha  A$.
These two definitions are justified by the following.

The \t{matrix space} (or \t{matrix vector space}) is the vector space $\R ^{m \times  n}$ in which addition is given by the matrix sums and scalar multiplication by entry-wise scaling.
Sometimes we reference explicitly the \t{$m\times n$ matrix space}.

\subsection*{Subspaces of symmetric matrices}

Consider the space of square matrices $\R ^{n \times  n}$.
It is obvious that the subset of symmetric matrices is a subspace.
Adding two symmetric matrices gives a symmetric matrix.
Scaling a symmetric matrix by a real number gives a symmetric matrix.
The matrix all of whose entries are 0 is symmetric.

\blankpage