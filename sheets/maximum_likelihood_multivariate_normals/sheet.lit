<!--
!name:maximum_likelihood_multivariate_normals
!need:maximum_likelihood_normals
!need:multivariate_normals
!need:matrix_transpose
-->

¬ß Why ‚¶â
¬∂ ‚¶ä
  ‚Äñ What of the generalization to a multivariate normal. ‚¶â
‚¶â

¬ß Result ‚¶â
<statement type='proposition'>
  ¬∂ ‚¶ä
    ‚Äñ Let $(x^1, ‚Ä¶, x^n)$ be a dataset in $ùó•^d$. ‚¶â

    ‚Äñ Let $f$ be a multivariate normal density with mean
      ‚óá ‚¶ä
        ‚Äñ \frac{1}{n} ‚àë_{k = 1}^{d} x^k ‚¶â
      ‚¶â
      and covariance
      ‚óá ‚¶ä
        ‚Äñ \frac{1}{n} ‚¶â

        ‚Äñ ‚àë_{k = 1}^{n} ‚¶â

        ‚Äñ \left(x^k - \frac{1}{n} ‚àë_{k = 1}^{n} x^k\right) ‚¶â

        ‚Äñ \left(x^k - \frac{1}{n} ‚àë_{k = 1}^{n} x^k\right)^\tp ‚¶â

        ‚Äñ . ‚¶â
      ‚¶â‚¶â

    ‚Äñ Then $f$ is a maximum likelihood multivariate normal
      density. ‚¶â
  ‚¶â

  <proof>
    ¬∂ ‚¶ä
      ‚Äñ We express the log likelihood
        ‚óá ‚¶ä
          ‚Äñ ‚àë_{k = 1}^{n} -\frac{1}{2}(x - Œº)^\tp Œ£^{-1} (x-Œº) -
            \frac{1}{2}\log (2œÄ)^d - \frac{1}{2} \log \det Œ£ ‚¶â
        ‚¶â

        ‚Äñ Let $P = Œ£^{-1}$. The $\log\det Œ£$ is $\log\det
          P^{-1}$ is $\log \left(\det P\right)^{-1}$ is $- \log\det
          P$. ‚¶â

        ‚Äñ Use matrix calculus to get
          ‚óá ‚¶ä
            ‚Äñ \frac{‚àÇ‚Ñì}{‚àÇP} = ‚àë_{k = 1}^{n} (x^k - Œº)(x^k -
              Œº)^\tp - P^{-1}. ‚¶â
          ‚¶â‚¶â‚¶â
    ‚¶â
  </proof>
</statement>
¬∂ ‚¶ä
  ‚Äñ We call these two objects the ‚ù¨maximum likelihood mean‚ù≠ or
    ‚ù¨empirical mean‚ù≠ and ‚ù¨maximum likelihood covariance‚ù≠ or
    ‚ù¨empirical covariance‚ù≠ of the dataset. ‚¶â

  ‚Äñ We call the normal density with the empirical mean and
    empirical covariance the ‚ù¨empirical normal‚ù≠ of the dataset. ‚¶â

  ‚Äñ ‚¶â
‚¶â
