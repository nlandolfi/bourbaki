%!name:unbiased_estimators
%!need:real_numbers
%!need:estimators

\section*{Definition}

Consider a random variable $x: \Omega  \to \R ^n$.
The error of the estimate $\xi  \in \R ^n$ is the random variable $e: \Omega  \to \R ^n$ which is defined by $e(\omega ) = x(\omega ) - \xi $.
The \t{bias} of an estimate is the expected value of the error.
An estimate is \t{unbiased} if it has zero bias.

Likewise, if we have another random variable $y: \Omega  \to \R ^m$, then the error of the estimator $f: \R ^m \to \R ^n$ is the random variable $e: \Omega  \to \R ^n$ defined by $e(\omega ) = f(x(\omega )) - y(\omega )$.

\blankpage