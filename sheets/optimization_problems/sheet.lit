<!--yaml
name: optimization_problems
needs:
    - optimizers
    - real_functions
    - extended_real_numbers
    - greatest_lower_bounds
    - n-dimensional_space
wikipedia: https://en.wikipedia.org/wiki/Optimization_problem
-->

§ Why ⦉
¶ ⦊
  ‖ We are frequently interested in finding minimizers of real
    functions.
    † ⦊
      ‖ Future editions will modify and expand. ⦉
    ⦉⦉
⦉

§ Definition ⦉
¶ ⦊
  ‖ An ❬optimization problem❭ is a pair $(𝒳, f)$ in which $𝒳$
    is a nonempty set called the ❬constraint set❭ and $f: 𝒳 →
    𝗥$ is called the ❬objective❭ (or ❬cost function❭). ⦉
⦉

¶ ⦊
  ‖ If $𝒳$ is finite we call the optimization problem ❬discrete❭. ⦉

  ‖ If $𝒳 ⊂ 𝗥^d$ we call the optimization problem ❬continuous❭. ⦉
⦉

¶ ⦊
  ‖ We refer to all elements of the constraint set as
    ❬feasible❭. ⦉

  ‖ We refer to an element $x ∈ 𝒳$ of the constraint set as
    ❬optimal❭ if $f(x) = \inf_{z ∈ 𝒳}f(z)$. ⦉

  ‖ We also refer to optimal elements as ❬solutions❭ of the
    optimization problem. ⦉
⦉

¶ ⦊
  ‖ It is common for $f$ and $𝒳$ to depend on some other,
    known, given objects. ⦉

  ‖ In this case, these objects are often called ❬parameters❭ or
    ❬problem data❭. ⦉
⦉

§§ Notation ⦉
¶ ⦊
  ‖ We often write optimization problems as
    ◇ ⦊
      ‖ \begin{aligned} ⦉

      ‖ \text{minimize}\quad ❲&❳ f(x) ᜶ ⦉

      ‖ \text{subject to}\quad ❲&❳ x ∈ 𝒳. ⦉

      ‖ \end{aligned} ⦉
    ⦉⦉

  ‖ In this case we call $x$ the ❬decision variable❭. ⦉
⦉

§§ Extended reals ⦉
¶ ⦊
  ‖ It is common to let $f: 𝒳 → \Rbar$, and allow there to
    exist $x ∈ 𝒳$ for which $f(x) = ∞$. ⦉

  ‖ This technique can be used to embed further constraints in
    the objective. ⦉

  ‖ For example, we interpret $f(x) = +∞$ to mean $x$ is
    ‹infeasible›. ⦉
⦉

§§ Maximization ⦉
¶ ⦊
  ‖ If we have some function $g: 𝒳 → \Rbar$ that we wish to
    maximize, we can always convert it to an optimization problem
    by defining $f: 𝒳 → \Rbar$ by $f(x) = -g(x)$. ⦉

  ‖ In this case $g$ is often called a ❬reward❭ (or ❬utility❭,
    ❬profit❭). ⦉
⦉

§ Solvers ⦉
¶ ⦊
  ‖ A ❬solver❭ (or ❬solution method❭, ❬solution algorithm❭) for a
    family of optimization problems is a function $S$ mapping
    optimization problems to solutions. ⦉
⦉

¶ ⦊
  ‖ Loosely speaking, the difficulty of “solving” the optimization
    problem $(𝒳, f)$ depends on the properties of $𝒳$ and $f$
    and the problem “size”. ⦉

  ‖ For example, when $𝒳 ⊂ 𝗥^d$ the difficulty is related to
    the “dimension” $d$ of $x ∈ 𝒳$. ⦉
⦉