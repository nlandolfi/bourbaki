
\section*{Why}

We are frequently interested in finding minimizers of real functions.\footnote{Future editions will modify and expand.}

\section*{Definition}

An \t{optimization problem} (or \t{extremum problem}) is a pair $(\mathcal{X} , f)$ in which $\mathcal{X} $ is a nonempty set called the \t{constraint set} and $f: \mathcal{X}  \to \R $ is called the \t{objective} (or \t{cost function}).

If $\mathcal{X} $ is finite we call the optimization problem \t{discrete}.
If $\mathcal{X}  \subset \R ^d$ we call the optimization problem \t{continuous}.

We refer to all elements of the constraint set as \t{feasible}.
We refer to an element $x \in \mathcal{X} $ of the constraint set as \t{optimal} if $f(x) = \inf_{z \in \mathcal{X} }f(z)$.
We also refer to optimal elements as \t{solutions} of the optimization problem.

It is common for $f$ and $\mathcal{X} $ to depend on some other, known, given objects.
In this case, these objects are often called \t{parameters} or \t{problem data}.

\subsection*{Notation}

We often write optimization problems as
\[
\begin{aligned}
\text{minimize}\quad & f(x) \\
\text{subject to}\quad & x \in \mathcal{X} .
\end{aligned}
\]
In this case we call $x$ the \t{decision variable}.

\subsection*{Extended reals}

It is common to let $f: \mathcal{X}  \to \Rbar$, and allow there to exist $x \in \mathcal{X} $ for which $f(x) = \infty$.
This technique can be used to embed further constraints in the objective.
For example, we interpret $f(x) = +\infty$ to mean $x$ is \textit{infeasible}.

\subsection*{Maximization}

If we have some function $g: \mathcal{X}  \to \Rbar$ that we wish to maximize, we can always convert it to an optimization problem by defining $f: \mathcal{X}  \to \Rbar$ by $f(x) = -g(x)$.
In this case $g$ is often called a \t{reward} (or \t{utility}, \t{profit}).

\section*{Solvers}

A \t{solver} (or \t{solution method}, \t{solution algorithm}) for a family of optimization problems is a function $S$ mapping optimization problems to solutions.

Loosely speaking, the difficulty of ``solving'' the optimization problem $(\mathcal{X} , f)$ depends on the properties of $\mathcal{X} $ and $f$ and the problem ``size''.
For example, when $\mathcal{X}  \subset \R ^d$ the difficulty is related to the ``dimension'' $d$ of $x \in \mathcal{X} $.
