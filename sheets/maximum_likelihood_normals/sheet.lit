<!--
!name:maximum_likelihood_normals
!need:normal_densities
!need:maximum_likelihood_densities
!need:partial_derivatives
!!need:calculus ;) multivariate, too...
-->

¬ß Why ‚¶â
¬∂ ‚¶ä
  ‚Äñ We want to select a normal density which summarizes well a
    dataset. ‚¶â
‚¶â

¬ß Formulation ‚¶â
¬∂ ‚¶ä
  ‚Äñ Let $D = (x^1, ‚Ä¶, x^n)$ be a dataset in $ùó•$. ‚¶â

  ‚Äñ We want to select a density from among normal densities,
    which require specifying a mean and covariance. ‚¶â
‚¶â

¬∂ ‚¶ä
  ‚Äñ Following the principle of maximum likelihood, we want to
    solve
    ‚óá ‚¶ä
      ‚Äñ \maximizationn{Œº,œÉ ‚àà ùó•}{ ‚¶â

      ‚Äñ ‚àè_{k = 1}^{n} \normaldensity{x^k}{Œº}{œÉ} ‚¶â

      ‚Äñ }{ ‚¶â

      ‚Äñ œÉ > 0 ·ú∂ ‚¶â

      ‚Äñ } ‚¶â
    ‚¶â‚¶â

  ‚Äñ We call a solution to the above problem a ‚ù¨maximum
    likelihood normal density‚ù≠ with respect to the dataset. ‚¶â
‚¶â

¬ß Solution ‚¶â
<statement type='proposition'>
  ‚Äñ Let $(x^1, ‚Ä¶, x^n)$ be a dataset in $ùó•$. ‚¶â

  ‚Äñ Let $f$ be a normal density with mean
    ‚óá ‚¶ä
      ‚Äñ \frac{1}{n} ‚àë_{k = 1}^{n} x^k ‚¶â
    ‚¶â
    and covariance
    ‚óá ‚¶ä
      ‚Äñ \frac{1}{n} ‚àë_{k = 1}^{n} \left(x^k - \frac{1}{n} ‚àë_{k =
        1}^{n} x^k\right)^2. ‚¶â
    ‚¶â‚¶â

  ‚Äñ Then $f$ is a maximum likelihood normal density. ‚¶â
</statement>
<proof>
  ‚Äñ Every normal density has two parameters: the mean and the
    covariance. ‚¶â

  ‚Äñ If the likelihood of one normal is less than or equal to
    the likelihood of another, then so also with their log
    likelihoods. ‚¶â

  ‚Äñ Let $f$ be a normal density with parameter $Œº$ and $œÉ^2$. ‚¶â

  ‚Äñ We express the log likelihood of $f$ by
    ‚óá ‚¶ä
      ‚Äñ ‚àë_{k = 1}^{n} \left( \frac{1}{2œÉ^2}(x^k - Œº)^2 -
        \frac{1}{2}\log2œÄœÉ^2\right) ‚¶â
    ‚¶â‚¶â

  ‚Äñ The partial derivative of the log likelihood with respect to
    the mean $(\partial_{Œº} ‚Ñì): ùó•^2 ‚Üí ùó•$ is
    ‚óá ‚¶ä
      ‚Äñ (\partial_Œº ‚Ñì)(Œº, œÉ^2) = - ‚àë_{k = 1}^{n} \frac{1}{œÉ^2}(x
        - Œº) ‚¶â
    ‚¶â
    and with respect to the covariance $(\partial_{œÉ^2} ‚Ñì): ùó•^2
    ‚Üí ùó•$ is
    ‚óá ‚¶ä
      ‚Äñ (\partial_{œÉ^2} ‚Ñì)(Œº, œÉ^2) = ‚¶â

      ‚Äñ \left(\frac{-1}{2(œÉ^2)^{2}}‚àë_{k = 1}^{n}(x^k - Œº)^2\right)-
        \frac{1}{2œÉ^2} ‚¶â
    ‚¶â‚¶â

  ‚Äñ We are interested in finding $Œº_0 ‚àà ùó•$ and $œÉ^2_0 > 0$,
    at which $\partial_Œº ‚Ñì(Œº_0, œÉ^2_0) = 0$ and $\partial_{œÉ^2}
    ‚Ñì(Œº_0, œÉ^2_0) = 0$. ‚¶â

  ‚Äñ So we have two equations. ‚¶â

  ‚Äñ First, notice that $\partial_Œº ‚Ñì$ is zero if an only if
    its first argument (the mean) is $\frac{1}{n} ‚àë_{k = 1}^{n}
    x^k$. ‚¶â

  ‚Äñ Second, notice that for all $Œº, œÉ^2$, $\partial_{œÉ^2}‚Ñì$ is
    zero if and only if
    ‚óá ‚¶ä
      ‚Äñ œÉ^2 = ‚àë_{k = 1}^{n} (x^k - Œº)^2. ‚¶â
    ‚¶â‚¶â

  ‚Äñ So the pair
    ‚óá ‚¶ä
      ‚Äñ \left(\frac{1}{n}‚àë_{k = 1}^{k} x^k, \frac{1}{n} ‚àë_{k =
        1}^{n} (x_k - \frac{1}{n} ‚àë_{k = 1}^{n} x^k)^2\right) ‚¶â
    ‚¶â
    is a stationary point of $‚Ñì$. ‚¶â
</proof>
