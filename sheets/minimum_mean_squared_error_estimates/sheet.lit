<!--
!name:minimum_mean_squared_error_estimates
!need:expectation
!need:estimates
!need:norms
-->

§ Why ⦉
¶ ⦊
  ‖ What is the best estimate for a random variable if we
    consider the square error? ⦉
⦉

§ Definition ⦉
¶ ⦊
  ‖ Let $(Ω, 𝒜, 𝗣)$ be a probability space and $x: Ω → 𝗥$ a
    random variable. ⦉

  ‖ A ❬minimum mean squared error estimate❭ or ❬MMSE estimate❭
    or ❬least square estimate❭ is a value $ξ ∈ 𝗥$ which
    minimizes $𝗘 (x - ξ)^2$. ⦉
⦉

<statement type='proposition'>
  ‖ There is a unique MMSE estimate and it is given by $𝗘(x)$. ⦉
</statement>

§ Vector case ⦉
¶ ⦊
  ‖ Let $(Ω, 𝒜, 𝗣)$ be a probability space and $y: Ω → 𝗥^n$
    a random variable.
    † ⦊
      ‖ Future editions might collapse this into the previous
        case. ⦉
    ⦉⦉
⦉

¶ ⦊
  ‖ A ❬minimum mean squared error estimator❭ or ❬MMSE estimator❭
    or ❬least square estimator❭ is a value $ξ ∈ 𝗥$ which
    minimizes $𝗘 \norm{x - ξ}^2$. ⦉
⦉

<statement type='proposition'>
  ‖ There is a unique MMSE estimator and it is given by $𝗘(y)$. ⦉
</statement>
<tex>
  ‖ \blankpage ⦉
</tex>
