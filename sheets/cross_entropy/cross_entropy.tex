\input{../../sheet.tex}
\sbasic
\input{../logarithm/macros.tex}
\input{../probability_distributions/macros.tex}
\input{../real_numbers/macros.tex}
\input{../probability_outcomes/macros.tex}
\input{../real_summation/macros.tex}
\input{../rational_numbers/macros.tex}
\input{../cardinality/macros.tex}
\input{../probability/macros.tex}
\input{../natural_summation/macros.tex}
\input{../integer_numbers/macros.tex}
\input{../injective_functions/macros.tex}
\input{../natural_numbers/macros.tex}
\input{../common_sense/macros.tex}
\input{../arithmetic/macros.tex}
\input{../family_operations/macros.tex}
\input{../solving_equations/macros.tex}
\input{../functions/macros.tex}
\input{../operations/macros.tex}
\input{../algebras/macros.tex}
\input{../families/macros.tex}
\input{../equations/macros.tex}
\input{../relations/macros.tex}
\input{../set_inclusion/macros.tex}
\input{../set_specification/macros.tex}
\input{../objects/macros.tex}
\input{../ordered_pairs/macros.tex}
\input{../set_equality/macros.tex}
\input{../sentences/macros.tex}
\input{../sets/macros.tex}
\input{../identity/macros.tex}
\input{./macros.tex}
\sstart
\stitle{Cross Entropy}

\ssection{Why}

\ssection{Definition}

Consider two distributions
on the same finite set.
The \ct{cross entropy}{}
of the first distribution
\ct{relative}{} to the
second distribution
is the expectation of the
negative logarithm of the first distribution
under the second distribution.

\ssubsection{Notation}

Let $R$ denote the set of
real numbers. Let
$A$ be a finite set.
Let $p: A \to R$ and
$q: A \to R$ be distributions.
The cross entropy of $p$ relative to $q$
is
\[
  -\sum_{a \in A} q(a) \log(p(a)).
\]
We denote the cross entropy
of $p$ relative to $q$ by
$H(q, p)$.
\strats
