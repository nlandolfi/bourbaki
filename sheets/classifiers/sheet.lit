¬∂ ‚¶ä
  ‚Äñ ‚ù≤%!name:classifiers‚ù≥ ‚¶â

  ‚Äñ ‚ù≤%!need:predictors‚ù≥ ‚¶â

  ‚Äñ ‚ù≤% needed for the horse example, can maybe remove eventually‚ù≥ ‚¶â

  ‚Äñ ‚ù≤%!need:factorials ‚ù≥ ‚¶â

  ‚Äñ ‚ù≤%!refs:sanjay_lall‚àïintroduction_to_machine_learning‚àïclassifiers‚ù≥ u ‚¶â
‚¶â

¬∂ ‚¶ä
  ‚Äñ \ssection{Why} ‚¶â

  ‚Äñ We name a predictor whose set of outputs is finite. ‚¶â
‚¶â

¬∂ ‚¶ä
  ‚Äñ \ssection{Definition} ‚¶â

  ‚Äñ A ‚ù¨classifer‚ù≠ is a predictor whose codomain is a finite set. ‚¶â

  ‚Äñ In this case, we call the outputs ‚ù¨classes‚ù≠ (or ‚ù¨labels‚ù≠,
    ‚ù¨categories‚ù≠, ‚ù¨label set‚ù≠). ‚¶â

  ‚Äñ We call the prediction of a classifier on an input a
    ‚ù¨classification‚ù≠. ‚¶â
‚¶â

¬∂ ‚¶ä
  ‚Äñ If the set of labels has two elements, then we call the
    classifier a ‚ù¨binary classifier‚ù≠ (or ‚ù¨two-way classifier‚ù≠,
    ‚ù¨two-class classifier‚ù≠, ‚ù¨boolean classifier‚ù≠). ‚¶â

  ‚Äñ In the case that there are $k$ labels, we call the
    classifier a ‚ù¨$k$-way classifier‚ù≠ (or ‚ù¨$k$-class
    classifier‚ù≠,‚ù¨multi-class classifier‚ù≠). ‚¶â

  ‚Äñ The second term is meant to indicate, not that the
    classifier assigns to each point several classes, but that
    the classification decision is made ‚Äπbetween‚Ä∫ several classes. ‚¶â
‚¶â

¬∂ ‚¶ä
  ‚Äñ \ssubsection{Basic Example} ‚¶â

  ‚Äñ Let $A$ be a set of inputs and let $B$ be a set of
    labels. ‚¶â

  ‚Äñ Define $B = \set{0, 1}$ (or $\set{-1,1 }$, $\set{‚∏§False‚∏•,
    ‚∏§True‚∏•}$, $\set{‚∏§Negative‚∏•, ‚∏§Positive‚∏•}$). ‚¶â

  ‚Äñ Then $B$ is finite with two elements and $f: A ‚Üí B$ is a
    binary classifier with labels $0$ and $1$. ‚¶â
‚¶â

¬∂ ‚¶ä
  ‚Äñ If the case $B = \set{\text{‚∏§No‚∏•}, ‚∏§Maybe‚∏•, ‚∏§Yes‚∏•}$, we call
    $f: A ‚Üí B$ a three-way classifier. ‚¶â

  ‚Äñ Other examples for $B$ include a list of languages, the set
    of English words in some dictionary, or the set of $m!$
    possible orders of $m$ horses in a race. ‚¶â

  ‚Äñ Often convenient to take $B = \set{1, ‚Ä¶, k}$ for $k ‚àà ùó°$. ‚¶â
‚¶â

¬∂ ‚¶ä
  ‚Äñ \ssubsection{Other terminology} ‚¶â

  ‚Äñ Following our terminology, but speaking of processes, some
    authors refer to the application of inductors for these
    special cases as ‚ù¨binary classification‚ù≠ and ‚ù¨multi-class
    classification‚ù≠. ‚¶â

  ‚Äñ Or they speak of ‚ù¨classification‚ù≠ and a ‚ù¨classification
    problems‚ù≠. ‚¶â

  ‚Äñ Roughly speaking, a classifier ‚ù¨classifies‚ù≠ all inputs into
    categories. ‚¶â
‚¶â

¬∂ ‚¶ä
  ‚Äñ Alternatively, some authors (especially in the statistics
    literature) refer to a classifier as a ‚ù¨discriminator‚ù≠ and
    reference ‚ù¨discrimination problems‚ù≠. ‚¶â
‚¶â
