<!--yaml
name: input_designs
needs:
    - consistent_inductors
-->

§ Why ⦉
¶ ⦊
  ‖ Let $X = \set{a, b}$ and $Y = \set{0, 1}$. Define $f: X
    → Y$ by $f ≡ 0$. ⦉
⦉

¶ ⦊
  ‖ Consider “selecting” elements of $X$ so to determine $f$. ⦉

  ‖ Since $f$ is functional, the program is straightforward. ⦉

  ‖ Observe $f$ at $a$ and at $b$, and then any consistent
    inductor will determine $f$. ⦉
⦉

¶ ⦊
  ‖ So, in some sense, the dataset $((a,0), (b,0))$ is “good”
    in that “reasonable” learning algorithms (those which are
    consistent) will determine $f$ from a dataset consistent with
    $f$. ⦉

  ‖ What of more general domains $X$? ⦉
⦉

§ Definition ⦉
¶ ⦊
  ‖ Let $X$ and $Y$ be sets. ⦉

  ‖ Let $\set{G_n: (X ×Y)^n → (X → Y)}_{n ∈ \N}$ be a family
    of inductors. ⦉
⦉

¶ ⦊
  ‖ An ❬input design❭ (or ❬experiment design❭ or ❬experimental
    design❭) of size $n$ is a sequence of inputs $x_1, …, x_n
    ∈ X$. ⦉

  ‖ The interpretation is that we will observe a dataset $(x_1,
    y_1)$, $…$, $(x_n, y_n)$ consistent with some function and
    that we will “infer” the function $G((x_i,y_i)_{i = 1}^{n})$. ⦉
⦉

¶ ⦊
  ‖ Some authors define a design as a sequence $x_1, …, x_ℓ$
    and nonzero integers $n_1, …, n_{ℓ}$ so that $∑_{i ≤ ℓ} n_i
    = n$. ⦉

  ‖ The correspondence with our definition is obvious. ⦉
⦉

¶ ⦊
  ‖ A ❬conditional input design❭ (of size $k$) for a dataset
    $(x_1,y_1)$, $…$, $(x_m, y_m)$ is a design $x_{m+1}, …,
    x_{m+k} ∈ X$. ⦉

  ‖ The interpretation is that we will observe a dataset $(x_1,
    y_1)$, $…$, $(x_{m+k}, y_{m+k})$ consistent with some function
    and that we will “infer” the function $G((x_i,y_i)_{i =
    1}^{m+k})$. ⦉
⦉

¶ ⦊
  ‖ For both of these designs, our interpretation of these
    objects is “experimental.” ⦉

  ‖ We call $x ∈ X$ the ❬experimental conditions❭ and we call
    $X$ the ❬experimental domain❭. ⦉

  ‖ We think of “choosing” a design and then “running an
    experiment” or “collecting data.” ⦉

  ‖ The experimental conditions are understood to be freely
    chosen (within the domain $X$). ⦉

  ‖ We call an element of the dataset $y_i$ an ❬observed
    response❭ or ❬yield❭. ⦉
⦉

§ Parametrically consistent datasets ⦉
¶ ⦊
  ‖ Let $f: X → Y$ and suppose the dataset is consistent with
    $f$. ⦉

  ‖ Let $Θ$ be a nonempty set. ⦉

  ‖ Suppose there exists $θ^★ ∈ Θ$ and $g: Θ ×X → Y$ so that
    $g(θ^*, x) = f(x)$ for all $x ∈ X$ (and so denote $f$ by
    $g_{θ^{★}}: X → Y$). ⦉
⦉

¶ ⦊
  ‖ In this case we call $θ$ the ❬parameters❭ or ❬parameter
    system❭ and we call $Θ$ the ❬parameter domain❭ (or ❬parameter
    space❭). ⦉

  ‖ We call the dataset ❬parametrically consistent❭. ⦉
⦉

¶ ⦊
  ‖ This decomposition $(θ, x)$ is interpreted as reflecting what
    is within and without of the experimenter's control. ⦉

  ‖ The conditions can be chosen by the experimenters, but the
    parameters are fixed, or “chosen by nature.” ⦉

  ‖ The experimenter “controls” the conditions and nature
    “controls” the parameters. ⦉
⦉