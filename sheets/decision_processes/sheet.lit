<!--
!name:decision_processes
!need:set_numbers
!need:lists
!need:probability_distributions
-->

§ Why ⦉
¶ ⦊
  ‖ We want to talk about making a sequence of decisions. ⦉
⦉

¶ ⦊
  ‖ \ssection{Definition} ⦉
⦉

¶ ⦊
  ‖ Let $S$ and $A$ be finite sets. ⦉

  ‖ Let $T: S × A → (S → [0, 1])$ so that for each $s ∈
    S$ and $a ∈ A$, $T_{sa}: S → [0, 1]$ is a probability
    distribution over $S$. ⦉

  ‖ We call the ordered triple $(S, A, T)$ a ❬finite
    state-action process❭. ⦉
⦉

¶ ⦊
  ‖ A ❬trajectory❭ in the ❬state set❭ $S$ and ❬action set❭ $A$
    is a sequence in $S × A$. ⦉
⦉

¶ ⦊
  ‖ Let $r: S × A × S → 𝗥$, $N ∈ 𝗡$. ⦉
⦉

¶ ⦊
  ‖ A ❬decision process❭ is a sequence $(S, A, T, r, γ, $,
    consists of two sets, a function set, an action ⦉
⦉

¶ ⦊
  ‖ \ssection{Other terminology} ⦉

  ‖ Decision processes are commonly called ❬markov decision
    processes❭.
    † ⦊
      ‖ As usual, we avoid this terminology in connection with
        the projects guidelines against using particular names. ⦉
    ⦉⦉
⦉

¶ ⦊
  ‖ \blankpage ⦉
⦉
