<!--yaml
name: polynomial_fit_models
needs:
    - polynomial_regressors
    - probabilistic_errors_linear_model
    - n-dimensional_line_segments
-->

Â§ Why â¦‰
Â¶ â¦Š
  â€– We can cast various common probabilistic regression models
    into the probabilistic errors linear model by mentioning the
    input space and feature maps. â¦‰

  â€– This unifies our analysis. â¦‰
â¦‰

Â§ Definition â¦‰
Â¶ â¦Š
  â€– â¦‰

  â€– A â¬line fit modelâ­ has input space $ğ—¥$ and output space
    $ğ—¥$. â¦‰

  â€– We use a regression function $Ï†: ğ—¥ â†’ ğ—¥^2$ defined by $Ï†(t)
    = (1, t)^âŠ¤$. â¦‰
â¦‰

Â¶ â¦Š
  â€– We think of $t âˆˆ T âŠ‚ ğ—¥$ as a â€œdose levelâ€ ($T$ is an
    interval). â¦‰

  â€– Given dose levels $t_1, â€¦, t_â„“$ and repetitions $n_1, â€¦,
    n_â„“$ we obtain the design matrix. â¦‰

  â€– Here the regression function generates a line segment
    embedded in the plane $ğ—¥^2$. â¦‰

  â€– We call the parameters the â¬intercept parameterâ­ and â¬slope
    parameterâ­. â¦‰
â¦‰

Â¶ â¦Š
  â€– A â¬parabola fit modelâ­ has input space $ğ—¥$ and output space
    $ğ—¥$. â¦‰

  â€– We use a regression function $Ï†: ğ—¥ â†’ ğ—¥^3$ defined by $Ï†(t)
    = (1, t, t^2)^âŠ¤$. â¦‰

  â€– Here the regression space is a segment of a parabola
    embedded in space $ğ—¥^3$ (since $t âˆˆ T$ an interval). â¦‰
â¦‰

Â¶ â¦Š
  â€– These two are instance of â¬polynomial fit modelsâ­ of degree
    $d â‰¥ 1$, in which the regression function becomes $Ï†: ğ—¥ â†’
    ğ—¥^{d + 1}$ defined by $Ï†(t) = (1, t, t^2, â€¦, t^d)^âŠ¤$. â¦‰

  â€– In this case, the regression range $Ï†(T)$ is a
    one-dimensional curve embedded in $ğ—¥^{d+1}$. â¦‰

  â€– In cases in which it is clear that the input space is a
    single real variable $t$, a linear model for a line fit
    (parabola fit, polynomial fit of degree $d$) is called a
    â¬first-degree modelâ­ (â¬second-degree modelâ­, â¬$d$th degree
    modelâ­). â¦‰
â¦‰

Â§Â§ $m$-way models â¦‰
Â¶ â¦Š
  â€– We can generalize to â¬$m$-way $d$th degree polynomial fit
    modelsâ­ in which the input space is $X âŠ‚ ğ—¥^m$ and the
    regression function $Ï†: ğ—¥^m â†’ ğ—¥^k$ ($k$ is $d+m$ choose $d$)
    is the vector of all monomials of degree $d$ in $m$
    variables. â¦‰
â¦‰

Â¶ â¦Š
  â€– For example, a two-way third-degree model has a regression
    function
    â—‡ â¦Š
      â€– Ï†(t_1, t_2) = \bmat{1 â²&â³ t_1 â²&â³ t_2 â²&â³ t_1^2 â²&â³
        t_1t_2 â²&â³ t_2^2 â²&â³ t_1^3 â²&â³ t_1^2t_2 â²&â³ t_1t_2^2 â²&â³
        t_2^3}^âŠ¤. â¦‰
    â¦‰â¦‰

  â€– Or consider a three way second-degree model with regression
    function
    â—‡ â¦Š
      â€– Ï†(t_1, t_2, t_3) = \bmat{1 â²&â³ t_1 â²&â³ t_2 â²&â³ t_3 â²&â³
        t_1^2 â²&â³ t_1t_2 â²&â³ t_1t_3 â²&â³ t_2^2 â²&â³ t_2t_3 â²&â³
        t_3^2}^âŠ¤. â¦‰
    â¦‰

    â€– Both models will result in parameter vectors of size ten. â¦‰

    â€– We call these models â¬saturatedâ­ because they have every
      possible $d$th degree power or cross product of variables. â¦‰

    â€– In generally, a $m$-way $d$th degree model has $d+m$
      choose $d$ mean parameters. â¦‰â¦‰
â¦‰

Â¶ â¦Š
  â€– In contrast to saturated models we can talk about
    â¬nonsaturatedâ­ models. â¦‰

  â€– For example, a nonsaturated two-way second-degree model has
    $Ï†: ğ—¥^2 â†’ ğ—¥^4$ where $Ï†(t_1, t_2) = (1 , t_1 , t_2 ,
    t_1^2)^âŠ¤$. â¦‰
â¦‰