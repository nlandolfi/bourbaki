
\section*{Why}

We might expect similar precepts to lead to similar postcepts.

\ssection{Definition}
Consider a set of inputs $X$ with a metric $d: X \times X \to \R$
Let $D = (x^1, y^1), \dots , (x^n, y^n)$ a dataset in $X \times  Y$
The \t{nearest-neighbor predictor} is the predictor $f: X \to Y$ which assigns to $x \in X$ the value ...

\ssubsection{Notation}
Let $D = ((a^1, b^1), \dots , (a^n, b^n))$ be a dataset in $A \times  B$, where $A$ and $B$ are non-empty sets.
Let $f$ be the nearest neighbor inductor.
Then $\iota (D)(x)$ is
Let $n$ be a natural number.
Let $\Xi$ be a length $n$ paired record sequence in $\CU \times  \CV$; so
\[
\Xi = ((u^1, v^1), \dots , (u^n, v^n))
\]
with $u^i \in \CU$ and $v^i \in \CV$ for $i = 1,\dots ,n$.

The nearest neighbor induction associates
$\Xi $ with the function $f_{\Xi }$ such that
\[
f_{\Xi }(u) = v^j
\]
where $j < n$ is the largest integer such that
\[
d(u, u^j) = \min_{i} \set{d(u, u^i)}.
\]

\blankpage
