<!--yaml
name: nearest_neighbor_predictors
needs:
    - predictors
    - metrics
-->

§ Why ⦉
¶ ⦊
  ‖ We might expect similar precepts to lead to similar
    postcepts. ⦉
⦉

§ Definition ⦉
¶ ⦊
  ‖ Consider a set of inputs $X$ with a metric $d: X × X →
    𝗥$ ⦉

  ‖ Let $D = (x^1, y^1), …, (x^n, y^n)$ a dataset in $X × Y$ ⦉

  ‖ The ❬nearest-neighbor predictor❭ is the predictor $f: X → Y$
    which assigns to $x ∈ X$ the value ... ⦉
⦉

§§ Notation ⦉
¶ ⦊
  ‖ Let $D = ((a^1, b^1), …, (a^n, b^n))$ be a dataset in $A
    × B$, where $A$ and $B$ are non-empty sets. ⦉

  ‖ Let $f$ be the nearest neighbor inductor. ⦉

  ‖ Then $ι(D)(x)$ is ⦉

  ‖ Let $n$ be a natural number. ⦉

  ‖ Let $Ξ$ be a length $n$ paired record sequence in $𝒰 ×
    𝒱$; so
    ◇ ⦊
      ‖ Ξ = ((u^1, v^1), …, (u^n, v^n)) ⦉
    ⦉
    with $u^i ∈ 𝒰$ and $v^i ∈ 𝒱$ for $i = 1,…,n$. ⦉
⦉

¶ ⦊
  ‖ The nearest neighbor induction associates ⦉

  ‖ $Ξ$ with the function $f_{Ξ}$ such that
    ◇ ⦊
      ‖ f_{Ξ}(u) = v^j ⦉
    ⦉
    where $j < n$ is the largest integer such that
    ◇ ⦊
      ‖ d(u, u^j) = \min_{i} \set{d(u, u^i)}. ⦉
    ⦉⦉
⦉

¶ ⦊
  ‖ \blankpage ⦉
⦉
