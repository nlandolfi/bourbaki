<!--
!name:supervised_probabilistic_data_models
!need:predictors
!need:independent_and_identically_distributed_random_variables
!need:approximators
!refs:shai_shalev-schwartz2014understanding
-->

Â§ Why â¦‰
Â¶ â¦Š
  â€– We want to discuss an inductor's performance on consistent
    (but possibly incomplete) datasets. â¦‰
â¦‰

Â¶ â¦Š
  â€– We take two steps. First, put a measure on the set of
    training sets and only consider high-measure subsets. â¦‰

  â€– Second, consider predictors performing well in some tolerance. â¦‰
â¦‰

Â§ Definition â¦‰
Â¶ â¦Š
  â€– Let $(X, ğ’³, Î¼)$ be a probability space and $(Y, ğ’´)$ a
    measurable space. â¦‰

  â€– Let $f: X â†’ Y$ measurable. â¦‰

  â€– We call the pair $((X, ğ’³, Î¼), f)$ a â¬(supervised)
    probabilistic data modelâ­. â¦‰
â¦‰

Â¶ â¦Š
  â€– We interpret $Î¼$ as the â¬data-generating distributionâ­ or
    â¬underlying distributionâ­ and $f$ as the â¬correct labeling
    functionâ­. â¦‰

  â€– Many authors refer to a supervised probabilistic data model
    as the â¬statistical learning (theory) frameworkâ­. â¦‰
â¦‰

Â§ Probable datasets â¦‰
Â¶ â¦Š
  â€– We put a measure on the set of datasets by using the
    product measure $(X^n, ğ’³^n, Î¼^n)$. â¦‰

  â€– We interpret this as a model for a training set of
    independent and identically distributed inputs. â¦‰
â¦‰

Â¶ â¦Š
  â€– â¦‰

  â€– For $Î´ âˆˆ (0, 1)$, $ğ’® âŠ‚ X^n$ is â¬$1-Î´$-representativeâ­ if
    $Î¼^n(ğ’®) â‰¥ 1 - Î´$. â¦‰

  â€– If $ğ’®$ is $1-Î´$-representative for small $Î´$, we think of
    $ğ’®$ as a set of â€œprobableâ€ or â€œreasonableâ€ datasets. â¦‰

  â€– We call $Î´$ the â¬confidence parameterâ­. â¦‰
â¦‰

Â§ Prediction error â¦‰
Â¶ â¦Š
  â€– The â¬errorâ­ of (measurable) $h: X â†’ Y$ (under $Î¼$ and $f$)
    is
    â—‡ â¦Š
      â€– \underset{Î¼, f}{\mathword{error}}(h) = Î¼(\Set*{x âˆˆ ğ’³}{h(x)
        â‰  f(x)}). â¦‰
    â¦‰â¦‰

  â€– We interpret this as the probability that the predictor
    mislabels a point. â¦‰

  â€– The â¬accuracyâ­ of $h$ is $1 - \mathword{error}_{Î¼, f}(h)$. â¦‰
â¦‰

Â¶ â¦Š
  â€– Since $(f, g) â†¦ Î¼[f(x) â‰  g(x)]$ is a metric on $L^2(X, ğ’³,
    Î¼, Y)$ we can talk about the error as the â€œdistanceâ€ from
    the correct label classifier. â¦‰

  â€– Thus we will say that $Ïµ âˆˆ (0, 1)$, (measurable) $h: ğ’³ â†’
    ğ’´$ â¬$Ïµ$-approximatesâ­ the correct labeling function $f$ if
    $\mathword{error}(h) â‰¤ Ïµ$. â¦‰

  â€– Roughly speaking, if $Ïµ â‰ª 1$, the the error of the
    hypothesis is â€œfairly small.â€ â¦‰

  â€– We call $Ïµ$ the â¬accuracy parameterâ­, since the accuracy of
    such a predictor is $1 - Ïµ$. â¦‰
â¦‰

Â§ Other terminology â¦‰
Â¶ â¦Š
  â€– A â¬hypothesis classâ­ is a subset of the measurable functions
    from $X â†’ Y$. â¦‰

  â€– Other names for the error of a classifier include the
    â¬generalization errorâ­, the â¬riskâ­ or the â¬true errorâ­ or
    â¬lossâ­. â¦‰
â¦‰
