%!name:probability_distributions
%!need:real_summation
%!need:uncertain_outcomes
%!need:intervals

\section*{Why}

To talk about uncertain outcomes, we assign credibility to each outcome according to our intuition of proportion.
  \ifhmode\unskip\fi\footnote{
Future editions may drop the dependence on real numbers, and use intuition of repeated trials to introduce \textit{rational} probability distributions.
  }

\section*{Definition}

A \t{probability distribution} (or \t{probability mass function} (\t{pmf}), or \t{proportion distribution}) is a real-valued function from a finite set of outcomes which is non-negative and normalized.
A real-valued function on a finite set is \t{normalized} if the sum of its results is 1.
We will refer to these as \t{distributions}.
The \t{probability of an outcome} is the result of the outcome under the distribution.

The probability of an outcome is meant to indicate the credibility of an outcome.
The word probabiliy has its roots in the English word probable, which has the Middle English sense \say{worthy of belief}.
The probability of an outcome models how worthy of belief it is, relative to other outcomes.
In the case of flipping a coin, or rolling a die, all outcomes are equally worthy of belief.

When an outcome has a higher probability than a second outcome we say that the first is \t{more probable} than the second.
Similarly we say that the first outcome is \t{less probable} than the second outcome if it has higher probability than the second.

\subsection*{Notation}

Let $A$ be a set and let $p: A \to \R $ be a distribution.
Then
  \[
\textstyle
p(a) \geq 0 \text{ for all } a \in A \text{ and } \sum\_{a \in A} p(a) = 1.
  \]

\begin{proposition}For all $a \in A$, $p(a) \leq 1$.
\begin{proof}Let $a \in A$.
By definition, $p(a) \geq 0$..
Second, since $p$ is normalized, $p(a) \leq \sum_{b \in A} p(b) = 1$.\end{proof}\end{proposition}
\section*{Example: coin}

When flipping a coin, both a heads and a tails are equally worthy of belief.
Thus we say that the outcome $0$ (tails) has probability $\nicefrac{1}{2}$ and likewise for the outcome $1$ (heads)
In this case we say that we are modeling a \t{fair coin}.

\section*{Example: die}

When rolling a die, all six sides are equally worthy of belief.
Thus we say that the outcomes $1, 2, 3, 4, 5, 6$ each have probability $\nicefrac{1}{6}$.
Prior to roll, each is equally credible.
In this case we say that we are modeing a \t{fair die}.
