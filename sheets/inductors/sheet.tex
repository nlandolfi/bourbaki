%!name:inductors
%!need:datasets

\ssection{Why}

We want to talk about learning
associations between objects
in time or space.

\ssection{Definition}

Let $A$ and $B$ be sets.
An \t{inductor} is a function mapping a dataset of paired records in $A \times B$ to a function from $A$ to $B$.

We call the elements of $A$ the \t{precepts} and the elements of $B$ the \t{postcepts}.
We call a function from the precepts to the postcepts a \t{predictor}.
We call the result of a precept under a predictor a \t{prediction}.

Using this language, an inductor maps datasets to predictors.
A predictor maps precepts to postcepts.

\ssubsection{Notation}

Let $D$ be a dataset of size $n$ in $A \cross B$.
Let $g: A \to B$, a predictor, which makes prediction $g(a)$ on precept $a \in A$.
Let $f: (A \cross B)^n \to (A \to B)$, an inductor.
Then $f(D)$ is the predictor which the inductor associates with dataset $D$.

\ssubsection{Other terminology}

Many authorities call the precepts the \t{independent variables}, \t{explanatory variables}, \t{inputs}, \t{covariates}, \t{patterns} or \t{observations}.
Similarly, some call the postcepts the \t{dependent variables}, \t{outputs}, \t{targets}, \t{outcomes} or \t{observational outcomes}.
Some call a predictor an \t{input-output} mapping.
A predictor is sometimes called a \t{point predictor}.\footnote{Future editions may remove this. The intuition for the word point is from the real numbers, which is not a prerequistite sheet.}
Some authors refer to a prediction as a \t{guess}.

\ssubsection{Learning algorithms}

We use a predictor to make guesses on precepts which do not appear in the dataset that was used to construct the predictor.
We refer to the task of proposing a predictor for a particular dataset a \t{learning problem}.

It is common in this context to refer to an inductor as a \t{learning algorithm} and call the task or problem of constructing a predictor from a dataset  \t{supervised learning}.
By supervision, we mean to indicate that we have the postcepts corresponding to the precepts.

In line with this usage, the postcepts are often called \t{labels} and the labels are said \say{to provide supervision.}
In this context, the dataset used to construct the predictor (i.e., the argument to the inductor) is called the \t{training dataset}.
