¬∂ ‚¶ä
  ‚Äñ ‚ù≤%!name:inductors‚ù≥ ‚¶â

  ‚Äñ ‚ù≤%!need:datasets‚ù≥ ‚¶â
‚¶â

¬∂ ‚¶ä
  ‚Äñ \ssection{Why} ‚¶â

  ‚Äñ We discuss learning (or inferring) relations from examples. ‚¶â
‚¶â

¬∂ ‚¶ä
  ‚Äñ \ssection{Definition} ‚¶â
‚¶â

¬∂ ‚¶ä
  ‚Äñ Let $X$ and $Y$ be sets. ‚¶â

  ‚Äñ A ‚ù¨relation inductor‚ù≠ (for a dataset of size $n$ in $X √ó
    Y$) is a function mapping a dataset in $(X √ó Y)^n$ to a
    relation between $X$ and $Y$. ‚¶â

  ‚Äñ We frequently use the term inductor to refer to a family
    of inductors, indexed by $n ‚àà ùó°$. ‚¶â
‚¶â

¬∂ ‚¶ä
  ‚Äñ An inductor is ‚ù¨functional‚ù≠ if it produces functions. ‚¶â

  ‚Äñ In this case, we call the elements of $X$ the ‚ù¨inputs‚ù≠ and
    the elements of $Y$ the ‚ù¨outputs‚ù≠. ‚¶â

  ‚Äñ We call a function from inputs to outputs a ‚ù¨predictor‚ù≠ and
    call the result of an input under a predictor a ‚ù¨prediction‚ù≠. ‚¶â

  ‚Äñ Using this language, a functional inductor maps datasets to
    predictors. ‚¶â

  ‚Äñ A predictor maps inputs to outputs. ‚¶â
‚¶â

¬∂ ‚¶ä
  ‚Äñ To every relation between $X$ and $Y$ corresponds a
    characteristic function on $X √ó Y$ and vice versa. ‚¶â

  ‚Äñ For this reason, henceforth by ‚ù¨inductor‚ù≠ we mean a
    functional inductor. ‚¶â

  ‚Äñ A relational inductor on a dataset in $(X √ó Y)^n$ can be
    modeled by a functional inductor on a dataset in $((X √ó Y)
    √ó \set{0, 1})^n$. ‚¶â
‚¶â

¬∂ ‚¶ä
  ‚Äñ \ssubsection{Notation} ‚¶â
‚¶â

¬∂ ‚¶ä
  ‚Äñ Let $D$ be a dataset of size $n$ in $X \cross Y$. ‚¶â

  ‚Äñ Let $g: X ‚Üí Y$, a predictor, which makes prediction $g(x)$
    on input $x ‚àà X$. ‚¶â

  ‚Äñ Let $G_n: (X \cross Y)^n ‚Üí (X √ó Y)$ be an inductor. ‚¶â

  ‚Äñ Then $G_n(D)$ is the predictor which the inductor associates
    with dataset $D$. ‚¶â

  ‚Äñ And $\set{G_n: (X √ó Y)^n ‚Üí \powerset{(X √ó Y)}}_{n ‚àà \N}$
    is a family of inductors. ‚¶â
‚¶â

¬∂ ‚¶ä
  ‚Äñ \ssection{Consistent and complete datasets} ‚¶â
‚¶â

¬∂ ‚¶ä
  ‚Äñ Let $D = ((x_i, y_i))_{i =1}^{n}$ be a dataset and $R ‚äÇ X
    √ó Y$ a relation. ‚¶â

  ‚Äñ $D$ is ‚ù¨consistent with $R$‚ù≠ if each $(x_i, y_i) ‚àà R$. ‚¶â

  ‚Äñ $D$ is ‚ù¨consistent‚ù≠ if there exists a relation with which
    it is consistent. ‚¶â

  ‚Äñ A dataset is always consistent (take $R = X √ó Y$). ‚¶â

  ‚Äñ $D$ is ‚ù¨functionally consistent‚ù≠ if it is consistent with a
    function; in this case, $x_i = x_j ‚áí y_i = y_j$. ‚¶â

  ‚Äñ $D$ is ‚ù¨functionally complete‚ù≠ if $\union_i\set{x_i} = X$. ‚¶â

  ‚Äñ In this case, the dataset includes every element of the
    relation. ‚¶â
‚¶â

¬∂ ‚¶ä
  ‚Äñ \ssubsection{Other terminology} ‚¶â
‚¶â

¬∂ ‚¶ä
  ‚Äñ Other terms for the inputs include ‚ù¨independent variables‚ù≠,
    ‚ù¨explanatory variables‚ù≠, ‚ù¨precepts‚ù≠, ‚ù¨covariates‚ù≠, ‚ù¨patterns‚ù≠,
    ‚ù¨instances‚ù≠, or ‚ù¨observations‚ù≠. ‚¶â

  ‚Äñ Other terms for the outputs include ‚ù¨dependent variables‚ù≠,
    ‚ù¨explained variables‚ù≠, ‚ù¨postcepts‚ù≠, ‚ù¨targets‚ù≠, ‚ù¨outcomes‚ù≠,
    ‚ù¨labels‚ù≠ or ‚ù¨observational outcomes‚ù≠. ‚¶â
‚¶â

¬∂ ‚¶ä
  ‚Äñ Other terms for a predictor include ‚ù¨input-output‚ù≠ mapping,
    ‚ù¨prediction rule‚ù≠, ‚ù¨hypothesis‚ù≠, ‚ù¨concept‚ù≠, or ‚ù¨classifier‚ù≠. ‚¶â

  ‚Äñ Since a predictor can be used to ‚ù¨guess‚ù≠ the output of an
    input, some authors call an inductor (or family of inductors)
    a ‚ù¨learner‚ù≠ or ‚ù¨learning algorithm‚ù≠ or ‚ù¨supervised learning
    algorithm‚ù≠ and refer to the argument as the ‚ù¨training
    dataset‚ù≠. ‚¶â

  ‚Äñ Often the word ‚Äúsupervised‚Äù is included, as in ‚ù¨supervised
    learning‚ù≠. ‚¶â

  ‚Äñ This language intends to indicate that inputs are given
    along with outputs, and these outputs ‚Äúprovide supervision to
    the algorithm.‚Äù ‚¶â
‚¶â
