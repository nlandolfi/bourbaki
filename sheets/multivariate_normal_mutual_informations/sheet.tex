
%!name:multivariate_normal_mutual_informations
%!need:multivariate_normal_entropy
%!need:differential_mutual_information
%!need:normal_correlation

\section*{Why}

What is the differential mutual information between two components of a multivariate normal?

\section*{Result}

\begin{proposition}
Let $g \sim \normal{\mu }{\Sigma }$.
Then the mutual information between
component $i$ and component $j$ is
\[
-\frac{1}{2}\ln(1 - \rho _{ij}^2)
\]
where $\rho _{ij}$ is the correlation between components $i$ and $j$.
\end{proposition}

\blankpage