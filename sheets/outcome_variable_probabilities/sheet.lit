¶ ⦊
  ‖ ❲%!name:outcome_variable_probabilities❳ ⦉

  ‖ ❲%!need:uncertain_outcomes❳ ⦉

  ‖ ❲%!need:event_probabilities❳ ⦉
⦉

¶ ⦊
  ‖ \ssection{Why} ⦉

  ‖ Given a probability measure on the events of a set of
    outcomes, we can discuss probabilities of outcome variables. ⦉
⦉

¶ ⦊
  ‖ \ssection{Definition} ⦉

  ‖ Let $p: Ω → 𝗥$ be a probability distribution with
    corresponding probability measure $𝗣: \powerset{Ω} → 𝗥$. ⦉

  ‖ Suppose $x: Ω → V$ is an outcome variable. ⦉

  ‖ The ❬probability $x = a$❭, for $a ∈ Ω$, is
    ◇ ⦊
      ‖ \textstyle ⦉

      ‖ 𝗣(\Set{ω ∈ Ω}{x(ω) = a}). ⦉
    ⦉⦉

  ‖ From the definition of $𝗣$, we express the above as
    ◇ ⦊
      ‖ \textstyle ⦉

      ‖ ∑_{ω ∈ Ω | x(ω) = a} p(ω). ⦉
    ⦉⦉

  ‖ We refer to the probability of the ‹event› that $x = a$. ⦉
⦉

¶ ⦊
  ‖ \ssubsection{Notation} ⦉

  ‖ We denote the probability that $x = a$ by $𝗣[x =a]$. ⦉

  ‖ Our square brackets deviate from the slightly slippery but
    universally standard notation $𝗣(x = a)$. ⦉

  ‖ We prefer the square brackets, since $x=a$ is not itself an
    argument to $𝗣$, but shorthand for $(\Set{ω ∈ Ω}{x(ω) = a})$. ⦉
⦉

¶ ⦊
  ‖ Accordingly, there are many similar notations. ⦉

  ‖ For example if $V = 𝗡$, $𝗣[x ≥ a]$ is $𝗣(\Set{ω ∈ Ω}{x(ω)
    ≥ a})$. ⦉

  ‖ Or, $𝗣[x ∈ C]$ means $𝗣(\Set{x ∈ Ω}{x(ω) ∈ C})$. ⦉

  ‖ Since the ‹event› that $x = a$ is the inverse image of
    $\set{a}$ under $x$, we also use the notation $x^{-1}(a)$. ⦉

  ‖ Or generally, $x^{-1}(C)$. ⦉
⦉

¶ ⦊
  ‖ \ssubsection{Example: sum of two dice} ⦉

  ‖ Define $Ω = \set{1, …, 6}^2$ and define $p: Ω → 𝗥$ with
    $p(ω) = \nicefrac{1}{36}$ for each $ω ∈ Ω$. ⦉

  ‖ Define $x: Ω → 𝗡$ by $x(ω_1, ω_2) = ω_1 + ω_2$. ⦉

  ‖ Then $𝗣[x = 4] = p((2, 2)) + p(1, 3) + p(3, 1) =
    \nicefrac{1}{12}$. ⦉
⦉

¶ ⦊
  ‖ \ssubsection{Induced probability} ⦉

  ‖ For $x: Ω → V$, the events $x^{-1}(a)$ for $a ∈ V$
    partition $Ω$. ⦉

  ‖ Define $q: V → 𝗥$ by
    ◇ ⦊
      ‖ q(a) = 𝗣[x = a]. ⦉
    ⦉⦉

  ‖ Since $∪_{a ∈ V} x^{-1}(a) = Ω$, $∑_{a ∈ A} q(a) = 1$. ⦉
⦉

¶ ⦊
  ‖ We call $q$ the ❬induced distribution❭ (or ❬induced
    probability mass function❭) of the random variable $x$. ⦉

  ‖ It is common to denote it by $p_{x}$. ⦉

  ‖ Thus we can think of $V$ as a set of outcomes, which we
    call the outcomes ❬induced❭ by $x$. ⦉
⦉

¶ ⦊
  ‖ If $x: Ω → V$ is a random variable and $f: V → U$, then
    if we define $y: Ω → V$ so that $y \equiv f(x)$, $y$ is
    a random variable with induced distribution $p_{y}: Ω → 𝗥$
    satisfying
    ◇ ⦊
      ‖ \textstyle ⦉

      ‖ p_{y}(b) = ∑_{a ∈ V | y(a) = b} p_x(a). ⦉
    ⦉⦉
⦉

¶ ⦊
  ‖ As a matter of practical computation, we can evaluate
    probabilities having to do with the outcome variable $x$
    using $p_x$ instead of $p$. ⦉

  ‖ For example with $x$ as in the example above, $𝗣(x = 4
    \text{ or } x = 5) = p_x(4) + p_x(5)$, rather than $∑_{ω
    ∈ Ω | x(ω) = 4 \text{ or } x(ω) = 5} p(ω)$. ⦉
⦉
