%!name:outcome_variable_probabilities
%!need:uncertain_outcomes
%!need:event_probabilities

\ssection{Why}
Given a probability measure on the events of a set of outcomes, we can discuss probabilities of outcome variables.

\ssection{Definition}
Let $p: \Omega  \to \R $ be a probability distribution with corresponding probability measure $\mathbfsf{P} : \powerset{\Omega } \to \R $.
Suppose $x: \Omega  \to V$ is an outcome variable.
The \t{probability $x = a$}, for $a \in \Omega $, is
  \[
\textstyle
\mathbfsf{P} (\Set{\omega  \in \Omega }{x(\omega ) = a}).
  \]
From the definition of $\mathbfsf{P} $, we express the above as
  \[
\textstyle
\sum_{\omega  \in \Omega  \mid x(\omega ) = a} p(\omega ).
  \]
We refer to the probability of the \textit{event} that $x = a$.

\ssubsection{Notation}
We denote the probability that $x = a$ by $\mathbfsf{P} [x =a]$.
Our square brackets deviate from the slightly slippery but universally standard notation $\mathbfsf{P} (x = a)$.
We prefer the square brakcets, since $x=a$ is not itself an argument to $\mathbfsf{P} $, but shorthand for $(\Set{\omega  \in \Omega }{x(\omega ) = a})$.

Accordingly, there are many similar notations.
For example if $V = \N $, $\mathbfsf{P} [x \geq a]$ is $\mathbfsf{P} (\Set{\omega  \in \Omega }{x(\omega ) \geq a})$.
Or, $\mathbfsf{P} [x \in C]$ means $\mathbfsf{P} (\Set{x \in \Omega }{x(\omega ) \in C})$.
Since the \textit{event} that $x = a$ is the inverse image of $\set{a}$ under $x$, we also use the notaion $x^{-1}(a)$.
Or generally, $x^{-1}(C)$.

\ssubsection{Example: sum of two dice}
Define $\Omega  = \set{1, \dots, 6}^2$ and define $p: \Omega \to \R $ with $p(\omega ) = \nicefrac{1}{36}$ for each $\omega \in \Omega $.
Define $x: \Omega  \to \N $ by $x(\omega _1, \omega _2) = \omega _1 + \omega _2$.
Then $\mathbfsf{P} [x = 4] = p((2, 2)) + p(1, 3) + p(3, 1) = \nicefrac{1}{12}$.

\ssubsection{Induced probability}
For $x: \Omega  \to V$, the events $x^{-1}(a)$ for $a \in V$ partition $\Omega $.
Define $q: V \to \R $ by
  \[
q(a) = \mathbfsf{P} [x = a].
  \]
Since $\cup_{a \in V} x^{-1}(a) = \Omega $, $\sum_{a \in A} q(a) = 1$.

We call $q$ the \t{induced distribution} (or \t{induced probability mass function}) of the random variable $x$.
It is common to denote it by $p_{x}$.
Thus we can think of $V$ as a set of outcomes, which we call the outcomes \t{induced} by $x$.

If $x: \Omega  \to V$ is a random variable and $f: V \to U$, then if we define $y: \Omega  \to V$ so that $y \equiv f(x)$, $y$ is a random variable with induced distribution $p_{y}: \Omega  \to \R $ satisfying
  \[
\textstyle
p_{y}(b) = \sum_{a \in V \mid y(a) = b} p_x(a).
  \]

As a matter of practical computation, we can evaluate probabilities having to do with the outcome variable $x$ using $p_x$ instead of $p$.
For example with $x$ as in the example above, $\mathbfsf{P} (x = 4 \text{ or } x = 5) = p_x(4) + p_x(5)$, rather than $\sum_{\omega  \in \Omega  \mid x(\omega ) = 4 \text{ or } x(\omega ) = 5} p(\omega )$.
