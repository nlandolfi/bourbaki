\input{../../sheet.tex}
\sbasic
\input{../sentences/macros.tex}
\input{../sets/macros.tex}
\input{../set_specification/macros.tex}
\input{../set_equality/macros.tex}
\input{../unordered_pairs/macros.tex}
\input{../objects/macros.tex}
\input{../set_inclusion/macros.tex}
\input{../ordered_pairs/macros.tex}
\input{../identity/macros.tex}
\input{../power_set/macros.tex}
\input{../relations/macros.tex}
\input{../equations/macros.tex}
\input{../families/macros.tex}
\input{../algebras/macros.tex}
\input{../operations/macros.tex}
\input{../functions/macros.tex}
\input{../equation_solutions/macros.tex}
\input{../family_operations/macros.tex}
\input{../arithmetic/macros.tex}
\input{../common_sense/macros.tex}
\input{../natural_numbers/macros.tex}
\input{../injective_functions/macros.tex}
\input{../integer_numbers/macros.tex}
\input{../length_common_notions/macros.tex}
\input{../natural_summation/macros.tex}
\input{../probability/macros.tex}
\input{../cardinality/macros.tex}
\input{../rational_numbers/macros.tex}
\input{../distance/macros.tex}
\input{../real_summation/macros.tex}
\input{../probability_outcomes/macros.tex}
\input{../intervals/macros.tex}
\input{../real_numbers/macros.tex}
\input{../metrics/macros.tex}
\input{../probability_distributions/macros.tex}
\input{../logarithm/macros.tex}
\input{../similarity_functions/macros.tex}
\input{../entropy/macros.tex}
\input{../cross_entropy/macros.tex}
\input{../relative_entropy/macros.tex}
\input{./macros.tex}
\sstart
\stitle{Mutual Information}

\ssection{Why}

\ssection{Definition}

The mutual information of
a joint distribution over
two random variables is
the entropy of the product
of the marginal distributions
relative to the joint distribution.

\ssubsection{Notation}

Let $R$ be the set of real
numbers.
Let $A$ and $B$ be
two non-empty sets.
Let $p: A \times B \to R$ be
a distribution.
\strats
