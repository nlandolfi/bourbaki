<!--
!name:predictors
!need:lists
-->

§ Why ⦉
¶ ⦊
  ‖ We discuss inferring (or learning) functions from examples. ⦉
⦉

§ Definitions ⦉
¶ ⦊
  ‖ Suppose $𝒰$ and $𝒱$ are two sets. ⦉

  ‖ A ❬predictor❭ from $𝒰$ to $𝒱$ is a function $f: 𝒰 → 𝒱$. ⦉

  ‖ We call $𝒰$ the ❬inputs❭, $𝒱$ the ❬outputs❭, and $f(u)$ the
    ❬prediction❭ of $f$ on $u ∈ 𝒰$. ⦉
⦉

¶ ⦊
  ‖ An ❬inductor❭ is a function from datasets in $𝒰 × 𝒱$ to
    predictors from $𝒰$ to $𝒱$. ⦉

  ‖ A ❬learner❭ (or ❬learning algorithm❭) is a family of
    inductors whose index set is $𝗡$, and whose $n$th term is
    is an inductor for a dataset of size $n$. ⦉
⦉

§ Predicting relations ⦉
¶ ⦊
  ‖ A ❬relation inductor❭ is a function from finite datasets in
    $𝒰 × 𝒱$ to ‹relations› on $𝒰 × 𝒱$. ⦉

  ‖ Since we can associate any relation $R$ between $𝒰$ and $𝒱$
    with a function $f: 𝒰 × 𝒱 → \set{0, 1}$, $f(u, v) = 1$
    if and only if $(u, v) ∈ R$, the predictor case accomodates
    general relations, beyond functions. ⦉
⦉

§§ Notation ⦉
¶ ⦊
  ‖ Let $D$ be a dataset of size $n$ in $𝒰 × 𝒱$. ⦉

  ‖ Let $g: 𝒰 → 𝒱$, a predictor, which makes prediction $g(u)$
    on input $u ∈ 𝒰$. ⦉

  ‖ Let $G_n: (𝒰 × 𝒱)^n → (𝒰 × 𝒱)$ be an inductor, so that
    $G_n(D)$ is the predictor which the inductor associates with
    dataset $D$. ⦉

  ‖ Then $\set{G_n: (𝒰 × 𝒱)^n → \powerset{(𝒰 × 𝒱)}}_{n ∈ 𝗡}$
    is a learner. ⦉
⦉

§ Consistent and complete datasets ⦉
¶ ⦊
  ‖ Let $D = ((u_i, v_i))_{i = 1}^{n}$ be a dataset and $R ⊂
    X × Y$ a relation. ⦉

  ‖ $D$ is ❬consistent with❭ $R$ if $(u_i, v_i) ∈ R$ for all
    $i = 1, …, n$. ⦉

  ‖ $D$ is ❬consistent❭ if there exists a relation with which
    it is consistent. ⦉

  ‖ A dataset is always consistent (take $R = 𝒰 × 𝒱$). ⦉

  ‖ $D$ is ❬functionally consistent❭ if it is consistent with a
    function; in this case, $x_i = x_j ⇒ y_i = y_j$. ⦉

  ‖ $D$ is ❬functionally complete❭ if $∪_i\set{x_i} = X$. ⦉

  ‖ In this case, the dataset includes every element of the
    relation. ⦉
⦉

§§ Other terminology ⦉
¶ ⦊
  ‖ Other terms for the inputs include ❬independent variables❭,
    ❬explanatory variables❭, ❬precepts❭, ❬covariates❭, ❬patterns❭,
    ❬instances❭, or ❬observations❭. ⦉

  ‖ Other terms for the outputs include ❬dependent variables❭,
    ❬explained variables❭, ❬postcepts❭, ❬targets❭, ❬outcomes❭,
    ❬labels❭ or ❬observational outcomes❭. ⦉

  ‖ An input-output pair is sometimes called a ❬record pair❭. ⦉
⦉

¶ ⦊
  ‖ Other terms for a learner include ❬learning algorithm❭, or
    ❬supervised learning algorithm❭. ⦉

  ‖ Other terms for a predictor include ❬input-output mapping❭,
    ❬prediction rule❭, ❬hypothesis❭, ❬concept❭, or ❬classifier❭. ⦉
⦉
