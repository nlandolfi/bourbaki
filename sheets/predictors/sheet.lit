¶ ⦊
  ‖ ❲%!name:predictors❳ ⦉

  ‖ ❲%!need:lists❳ ⦉
⦉

¶ ⦊
  ‖ \ssection{Why} ⦉

  ‖ We discuss inferring (or learning) functions from examples. ⦉
⦉

¶ ⦊
  ‖ \ssection{Definitions} ⦉

  ‖ A ❬predictor❭ $f: \CU → \CV$ is a function from $\CU$ to
    $\CV$. ⦉

  ‖ An ❬inducer❭ is a function from finite datasets in $\CU ×
    \CV$ to predictors from $\CU$ to $\CV$. ⦉

  ‖ A ❬learner❭ is a function family of inducers, indexed by
    $n$, each defined for datasets of size $n$.
    ‖ We call the elements of $\CU$ ❬inputs❭ and the elements
      of $\CV$ ❬outputs❭. ⦉⦉
⦉

¶ ⦊
  ‖ \ssubsection{Predictors} ⦉

  ‖ An ❬function inducer❭ is an inducer from datasets functions,
    in which case we call the elements of $\CU$ ❬inputs❭ and
    the elements of $\CV$ ❬outputs❭. ⦉

  ‖ We also refer to a function inputs to outputs as a
    ❬predictor❭ and call the result of an input under a
    predictor a ❬prediction❭. ⦉

  ‖ Predictors map inputs to ouputs, and (functional) inducers
    map datasets to predictors. ⦉
⦉

¶ ⦊
  ‖ \ssection{Relation inducers} ⦉

  ‖ We need only consider the case of functional inducers, since
    we can associate a relation $R$ on $\CU × \CV$ with a
    function function $f: \CU × \CU → \set{0, 1}$ defined by
    $f(u, v) = 1$ if $(u, v) ∈ R$. ⦉

  ‖ Henceforth, by ❬inducer❭ we mean a ‹functional› inducer. ⦉
⦉

¶ ⦊
  ‖ \ssubsection{Notation} ⦉
⦉

¶ ⦊
  ‖ Let $D$ be a dataset of size $n$ in $\CU \cross \CV$. ⦉

  ‖ Let $g: \CU → \CV$, a predictor, which makes prediction
    $g(u)$ on input $u ∈ \CU$. ⦉

  ‖ Let $G_n: (\CU \cross \CV)^n → (\CU × \CV)$ be an inductor. ⦉

  ‖ Then $G_n(D)$ is the predictor which the inductor associates
    with dataset $D$. ⦉

  ‖ And $\set{G_n: (\CU × \CV)^n → \powerset{(\CU × \CV)}}_{n ∈
    \N}$ is a family of inductors. ⦉
⦉

¶ ⦊
  ‖ \ssection{Consistent and complete datasets} ⦉
⦉

¶ ⦊
  ‖ Let $D = ((u_i, v_i))_{i = 1}^{n}$ be a dataset and $R ⊂
    X × Y$ a relation. ⦉

  ‖ $D$ is ❬consistent with $R$❭ if each $(u_i, v_i) ∈ R$. ⦉

  ‖ $D$ is ❬consistent❭ if there exists a relation with which
    it is consistent. ⦉

  ‖ A dataset is always consistent (take $R = \CU × \CV$). ⦉

  ‖ $D$ is ❬functionally consistent❭ if it is consistent with a
    function; in this case, $x_i = x_j ⇒ y_i = y_j$. ⦉

  ‖ $D$ is ❬functionally complete❭ if $\union_i\set{x_i} = X$. ⦉

  ‖ In this case, the dataset includes every element of the
    relation. ⦉
⦉

¶ ⦊
  ‖ \ssubsection{Other terminology} ⦉
⦉

¶ ⦊
  ‖ Other terms for the inputs include ❬independent variables❭,
    ❬explanatory variables❭, ❬precepts❭, ❬covariates❭, ❬patterns❭,
    ❬instances❭, or ❬observations❭. ⦉

  ‖ Other terms for the outputs include ❬dependent variables❭,
    ❬explained variables❭, ❬postcepts❭, ❬targets❭, ❬outcomes❭,
    ❬labels❭ or ❬observational outcomes❭. ⦉

  ‖ An input, output pair is sometimes called a ❬record pair❭. ⦉
⦉

¶ ⦊
  ‖ Other terms for a functional inductor include ❬learning
    algorithm❭, ❬learner❭, ❬supervised learning algorithm❭. ⦉

  ‖ Other terms for a predictor include ❬input-output❭ mapping,
    ❬prediction rule❭, ❬hypothesis❭, ❬concept❭, or ❬classifier❭. ⦉
⦉
