¶ ⦊
  ‖ ❲%!name:predictors❳ ⦉

  ‖ ❲%!need:lists❳ ⦉
⦉

¶ ⦊
  ‖ \ssection{Why} ⦉

  ‖ We discuss inferring (or learning) functions from examples. ⦉
⦉

¶ ⦊
  ‖ \ssection{Definitions} ⦉

  ‖ A ❬predictor❭ $f: \CU → \CV$ is a function from $\CU$ to
    $\CV$. ⦉

  ‖ An ❬inducer❭ is a function from finite datasets in $\CU ×
    \CV$ to predictors from $\CU$ to $\CV$. ⦉

  ‖ A ❬learner❭ is a function family of inducers, indexed by
    $n$, each defined for datasets of size $n$. ⦉

  ‖ We call $\CU$ the ❬inputs❭, $\CV$ the ❬outputs❭, and $f(u)$
    the ❬prediction❭ of $f$ on $u ∈ \CU$. ⦉
⦉

¶ ⦊
  ‖ \ssection{Predicting relations} ⦉

  ‖ A ❬relation inducer❭ is a function from finite datasets in
    $\CU × \CV$ to ‹relations› on $\CU × \CV$. ⦉

  ‖ Since we can associate any relation $R$ between $\CU$ and
    $\CV$ with a function $f: \CU × \CV → \set{0, 1}$, $f(u,
    v) = 1$ if and only if $(u, v) ∈ R$, the predictor case
    can accomodate learning general relations, beyond functions. ⦉
⦉

¶ ⦊
  ‖ \ssubsection{Notation} ⦉
⦉

¶ ⦊
  ‖ Let $D$ be a dataset of size $n$ in $\CU \cross \CV$. ⦉

  ‖ Let $g: \CU → \CV$, a predictor, which makes prediction
    $g(u)$ on input $u ∈ \CU$. ⦉

  ‖ Let $G_n: (\CU \cross \CV)^n → (\CU × \CV)$ be an inducer,
    so that $G_n(D)$ is the predictor which the inductor
    associates with dataset $D$. ⦉

  ‖ Then $\set{G_n: (\CU × \CV)^n → \powerset{(\CU × \CV)}}_{n ∈
    \N}$ is a learner. ⦉
⦉

¶ ⦊
  ‖ \ssection{Consistent and complete datasets} ⦉
⦉

¶ ⦊
  ‖ Let $D = ((u_i, v_i))_{i = 1}^{n}$ be a dataset and $R ⊂
    X × Y$ a relation. ⦉

  ‖ $D$ is ❬consistent with $R$❭ if each $(u_i, v_i) ∈ R$. ⦉

  ‖ $D$ is ❬consistent❭ if there exists a relation with which
    it is consistent. ⦉

  ‖ A dataset is always consistent (take $R = \CU × \CV$). ⦉

  ‖ $D$ is ❬functionally consistent❭ if it is consistent with a
    function; in this case, $x_i = x_j ⇒ y_i = y_j$. ⦉

  ‖ $D$ is ❬functionally complete❭ if $\union_i\set{x_i} = X$. ⦉

  ‖ In this case, the dataset includes every element of the
    relation. ⦉
⦉

¶ ⦊
  ‖ \ssubsection{Other terminology} ⦉
⦉

¶ ⦊
  ‖ Other terms for the inputs include ❬independent variables❭,
    ❬explanatory variables❭, ❬precepts❭, ❬covariates❭, ❬patterns❭,
    ❬instances❭, or ❬observations❭. ⦉

  ‖ Other terms for the outputs include ❬dependent variables❭,
    ❬explained variables❭, ❬postcepts❭, ❬targets❭, ❬outcomes❭,
    ❬labels❭ or ❬observational outcomes❭. ⦉

  ‖ An input, output pair is sometimes called a ❬record pair❭. ⦉
⦉

¶ ⦊
  ‖ Other terms for a learner include ❬learning algorithm❭, or
    ❬supervised learning algorithm❭. ⦉

  ‖ Other terms for a predictor include ❬input-output❭ mapping,
    ❬prediction rule❭, ❬hypothesis❭, ❬concept❭, or ❬classifier❭. ⦉
⦉
