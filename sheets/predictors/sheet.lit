<!--
!name:predictors
!need:lists
-->

Â§ Why â¦‰
Â¶ â¦Š
  â€– We discuss inferring (or learning) functions from examples. â¦‰
â¦‰

Â§ Definitions â¦‰
Â¶ â¦Š
  â€– Suppose $ğ’°$ and $ğ’±$ are two sets. â¦‰

  â€– A â¬predictorâ­ from $ğ’°$ to $ğ’±$ is a function $f: ğ’° â†’ ğ’±$. â¦‰

  â€– We call $ğ’°$ the â¬inputsâ­, $ğ’±$ the â¬outputsâ­, and $f(u)$ the
    â¬predictionâ­ of $f$ on $u âˆˆ ğ’°$. â¦‰
â¦‰

Â¶ â¦Š
  â€– An â¬inductorâ­ is a function from datasets in $ğ’° Ã— ğ’±$ to
    predictors from $ğ’°$ to $ğ’±$. â¦‰

  â€– A â¬learnerâ­ (or â¬learning algorithmâ­) is a family of
    inductors whose index set is $ğ—¡$, and whose $n$th term is
    is an inductor for a dataset of size $n$. â¦‰
â¦‰

Â§ Predicting relations â¦‰
Â¶ â¦Š
  â€– A â¬relation inductorâ­ is a function from finite datasets in
    $ğ’° Ã— ğ’±$ to â€¹relationsâ€º on $ğ’° Ã— ğ’±$. â¦‰

  â€– Since we can associate any relation $R$ between $ğ’°$ and $ğ’±$
    with a function $f: ğ’° Ã— ğ’± â†’ \set{0, 1}$, $f(u, v) = 1$
    if and only if $(u, v) âˆˆ R$, the predictor case accomodates
    general relations, beyond functions. â¦‰
â¦‰

Â§Â§ Notation â¦‰
Â¶ â¦Š
  â€– Let $D$ be a dataset of size $n$ in $ğ’° Ã— ğ’±$. â¦‰

  â€– Let $g: ğ’° â†’ ğ’±$, a predictor, which makes prediction $g(u)$
    on input $u âˆˆ ğ’°$. â¦‰

  â€– Let $G_n: (ğ’° Ã— ğ’±)^n â†’ (ğ’° Ã— ğ’±)$ be an inductor, so that
    $G_n(D)$ is the predictor which the inductor associates with
    dataset $D$. â¦‰

  â€– Then $\set{G_n: (ğ’° Ã— ğ’±)^n â†’ \powerset{(ğ’° Ã— ğ’±)}}_{n âˆˆ ğ—¡}$
    is a learner. â¦‰
â¦‰

Â§ Consistent and complete datasets â¦‰
Â¶ â¦Š
  â€– Let $D = ((u_i, v_i))_{i = 1}^{n}$ be a dataset and $R âŠ‚
    X Ã— Y$ a relation. â¦‰

  â€– $D$ is â¬consistent withâ­ $R$ if $(u_i, v_i) âˆˆ R$ for all
    $i = 1, â€¦, n$. â¦‰

  â€– $D$ is â¬consistentâ­ if there exists a relation with which
    it is consistent. â¦‰

  â€– A dataset is always consistent (take $R = ğ’° Ã— ğ’±$). â¦‰

  â€– $D$ is â¬functionally consistentâ­ if it is consistent with a
    function; in this case, $x_i = x_j â‡’ y_i = y_j$. â¦‰

  â€– $D$ is â¬functionally completeâ­ if $âˆª_i\set{x_i} = X$. â¦‰

  â€– In this case, the dataset includes every element of the
    relation. â¦‰
â¦‰

Â§Â§ Other terminology â¦‰
Â¶ â¦Š
  â€– Other terms for the inputs include â¬independent variablesâ­,
    â¬explanatory variablesâ­, â¬preceptsâ­, â¬covariatesâ­, â¬patternsâ­,
    â¬instancesâ­, or â¬observationsâ­. â¦‰

  â€– Other terms for the outputs include â¬dependent variablesâ­,
    â¬explained variablesâ­, â¬postceptsâ­, â¬targetsâ­, â¬outcomesâ­,
    â¬labelsâ­ or â¬observational outcomesâ­. â¦‰

  â€– An input-output pair is sometimes called a â¬record pairâ­. â¦‰
â¦‰

Â¶ â¦Š
  â€– Other terms for a learner include â¬learning algorithmâ­, or
    â¬supervised learning algorithmâ­. â¦‰

  â€– Other terms for a predictor include â¬input-output mappingâ­,
    â¬prediction ruleâ­, â¬hypothesisâ­, â¬conceptâ­, or â¬classifierâ­. â¦‰
â¦‰
