%!name:hypothesis_classes
%!need:supervised_probabilistic_data_models
%!refs:shai_shalev-schwartz2014understanding

\ssection{Why}

We consider the set of predictors from which we select.

\ssection{Definition}

Let $(X, \CX, \mu)$ and $f: X \to Y$ be probabilistic data-generation model.
A \t{hypothesis class} $\CH \subset (X \to Y)$ is a subset of measurable functions.
For a dataset $D \in (X \times Y)^n$, a \t{restricted empirical error minimizer} of $\CH$ is a hypothesis $h \in \CH$ with minimal (among elements of $\CH$) empirical error on $D$.

\ssubsection{Inductive Bias}

Many authorities call the hypothesis class a \t{inductive bias} and speak of \say{biasing} the \say{learning algorithm}.
Since one specifies the hypothesis class prior to the data it often said to \say{encode prior knowledge about the problem to be learned.}

\ssection{Realizable classes}

Some hypothesis classes are better than others.
For example, a hypothesis class that includes the correct labeling function seems preferable to a class that does not.

We formulate a weaker condition that captures the case when $f \in \CH$.
A hypothesis class $\CH$ is \t{realizable} if there exists $h^{\star} \in \CH$ with
\[
	\mu(\Set{x \in X}{h^\star(x) \neq f(x)}) = 0.%\footnote{Future editions will comment on the measurability of this set. It is no object for finite $\CX$.} In fact, it is no object for any measurable $h$ and $f$.
\]
This condition is natural because if $f \in \CH$, then $\CH$ is realizable.
Moreover, the condition has two natural corollaries

First, there exists $h^\star$ so that
\[
	\mu^n(\Set*{x \in X^n}{\num{\Set*{i \in [n]}{h^\star(x_i) \neq f(x_i)}} \neq 0}) = 0.
\]
We interpret this as follows: \say{there exists a hypothesis whose probability of achieving nonzero empirical risk is zero.}

Second, denote by $M_x$ the empirical risk minimizers of $x \in X^n$. Then,
\[
	\mu^n(\Set*{x \in X^n}{\forall h \in M_x, \forall i, h(x_i) = f(x_i)}) = 1.
\]
We interpret this as follows: \say{all empirical risk minimizers will achieve zero empirical risk on the dataset, with probability 1.}

Roughly speaking, there exists a hypothesis for which the event that it achieves zero empirical risk has probability one.
In this event, every hypothesis in the set of empirical risk minimizers must achieve zero empirical risk.
This is a consequence of the hypothesis class being realizable.
% see page 17 of shai_shalev-schwartz2014understanding for this.
