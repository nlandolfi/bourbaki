%!name:normal_differential_mutual_information
%!need:normal_differential_entropy
%!need:differential_mutual_information
%!need:normal_correlation

\ssection{Why}

What is the differential mutual information
between two components of a multivariate normal.

\ssection{Result}

\begin{prop}
Let $g \sim \normal{\mu}{\Sigma}$.
Then the mutual information between
component $i$ and component $j$ is
\[
  -\frac{1}{2}\ln(1 - \rho_{ij}^2)
\]
where $\rho_{ij}$ is the correlation
between components $i$ and $j$.
\end{prop}
