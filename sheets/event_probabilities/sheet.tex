
%!name:event_probabilities
%!need:probability_distributions

\section*{Why}

Since one and only one outcome occurs, given a distribution on outcomes, we define the probability of a set of outcomes as the sum of their probabilities.

\section*{Definition}

Suppose $p$ is a distribution on $\Omega $.
For any event $A \subset \Omega $, we call the value $\sum_{a \in A} p(a)$ the \t{event probability}.
We refer to the probability \textit{of} $A$.
The probability $A$ is the sum of the probabilities of its outcomes.

We can define a function $\mathbfsf{P} : \powerset{\Omega } \to \R $ by $\mathbfsf{P} (A) = \sum_{a \in A} p(a)$.
We call $\mathbfsf{P} $ \t{the event probability function} (or \t{the probability measure}) induced by $p$.
Since $\mathbfsf{P} $ depends on the sample space $\Omega $ and the distribution $p$, we ocassionally denote this dependence by $\mathbfsf{P} _{\Omega , p}$ or $\mathbfsf{P} _p$.

\section*{Example: die}

Define $p: \set{1, \dots , 6} \to \R $ by $p(\omega ) = 1/6$ for $\omega  = 1, \dots , 6$.
Define the event $E = \set{2, 4, 6}$.
Then
    \[
\textstyle
\mathbfsf{P} (E) = \sum_{\omega  \in E} p(\omega ) = p(2) + p(4) + p(6) = 1/2.
    \]

\section*{Properties of $\mathbfsf{P} $}

As a result of the conditions on $p$, $\mathbfsf{P} $ satisfies
    \begin{enumerate}
      \item $\mathbfsf{P} (A) \geq 0$ for all $A \subset \Omega $;
      \item $\mathbfsf{P} (\Omega ) = 1$ (and $\mathbfsf{P} (\varnothing) = 0$);
      \item $\mathbfsf{P} (A) + \mathbfsf{P} (B)$ for all $A, B \subset \Omega $ and $A \cap  B = \varnothing$.
This statement follows from the more general identity
          \[
\mathbfsf{P} (A \cup B) = \mathbfsf{P} (A) + \mathbfsf{P} (B) - \mathbfsf{P} (A \cap  B)
          \]
for $A, B \subset \Omega $, by using $P(\varnothing) = 0$ of (2) above.
    \end{enumerate}

Do all such $\mathbfsf{P} $ satisfying (1)-(3) have a corresponding underlying probability distribution?
In other words, suppose $f: \powerset{\Omega } \to \R $ satifies (1)-(3).
These three conditions are sometimes called the \t{axioms of probability for finite sets}.

Define $q: \Omega  \to \R $ by $q(\omega ) = f(\set{\omega })$.
If $f$ satisfies the axioms, then $q$ is a probability distribution.
For this reason we call any function satisfying (i)-(iii) an \t{event probability function} (or a \t{probability measure}).

\section*{Probability by cases}

Let $\mathbfsf{P} $ be a probability event function.
Suppose $A_1, \dots , A_n$ partition $\Omega $.
Then for any $B \subset \Omega $,
    \[
\textstyle
\mathbfsf{P} (B) = \sum_{i = 1}^{n} \mathbfsf{P} (A_i \cap  B).
    \]
Some authors call this the \t{law of total probability}.
