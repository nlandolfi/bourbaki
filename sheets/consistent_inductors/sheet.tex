%!name:consistent_inductors
%!need:predictors

\ssection{Why}

We discuss inductors that produce relations consistent with their given datasets.

\ssection{Definition}

Let $(x_1, y_1), \dots, (x_n, y_n)$ be a dataset in $X \times Y$.
Let $\CR$ be the set of all relations on $X \times Y$.

A \t{consistent inductor} $\set{G_n: (X \times Y)^n \to \CR}_{n}$ is one for which, for all $n \in \N$, for all $D_n \in (X \times Y)^n$, $D$ is consistent with $G_n(D_n)$.
In other words, a consistent inductor always produces a relation with which the dataset is consistent.

The interpretation follows.
Fix a relation $R^\star$.
And let every dataset \say{shown} to the algorithm $G_n$ be constructed by selecting elements from $R^{\star}$.
In other words, every dataset is a sequence in $R^\star$.
In this case, a dataset $D_n \in (X \times Y)^n$ is always consistent with $R^\star$ and so a consistent inductor will never \say{eliminate} $R^{\star}$.
In other words, the inductor, in order to be consistent \say{must eliminate} every inconsistent relation.

We may \say{hope} to give the algorithm a \say{large and diverse} datset, so that several of the elements of $R^\star$ are included.
In this case, the algorithm can \say{eliminate} many smaller relations in $\CR$ which did not include records in the dataset.


\ssection{Functionally consistent}

The rub is that any dataset is consistent with the complete relation $X \times Y$.
So we can often consider a set $\CH \subset \CR$ of relations.
It is common to call this a \t{hypothesis class}, especially for the case in which it consists of functional relations.
