<!--yaml
name: stochastic_dynamical_systems
needs:
    - dynamic_optimization_problems
    - real-valued_random_variable_expectation
-->

Â§ Why â¦‰
Â¶ â¦Š
  â€– We want to model uncertain outcomes in dynamical systems.
    â€  â¦Š
      â€– Future editions will expand. â¦‰
    â¦‰â¦‰
â¦‰

Â§ Definition â¦‰
Â¶ â¦Š
  â€– Let $ğ’³_0, ğ’³_1, â€¦, ğ’³_{T}$ and $ğ’°_0, ğ’°_1, â€¦, ğ’°_{T-1}$ be
    sets. â¦‰

  â€– Let $(Î©, ğ’œ, ğ—£)$ be a probability space. â¦‰

  â€– Let $ğ’²_{0}, â€¦, ğ’²_{T}$. â¦‰

  â€– Let $w_{t}: Î© â†’ ğ’²_{t}$ for $t = 0, â€¦, T$ be random
    variables. â¦‰

  â€– For $t = 0$, $â€¦$, $T-1$, let $f_{t}: ğ’³_t Ã— ğ’°_t Ã— ğ’²_t â†’
    ğ’³_{t+1}$. â¦‰
â¦‰

Â¶ â¦Š
  â€– We call the sequence
    â—‡ â¦Š
      â€– ğ’Ÿ = ((ğ’³_t)_{t = 0}^{T}), (ğ’°_t)_{t=0}^{T-1},
        (w_t)_{t=0}^{T-1}, (f_t)_{t=1}^{T-1}) â¦‰
    â¦‰
    a â¬stochastic discrete-time dynamical systemâ­. â¦‰

  â€– We call $w_t$ the â¬noiseâ­ variables. â¦‰
â¦‰

Â§ Problem â¦‰
Â¶ â¦Š
  â€– Let $x_0: Î© â†’ ğ’³_0$ be a random variable. â¦‰

  â€– Define $x_1: Î© â†’ ğ’³_1$, $â€¦$, $x_T: Î© â†’ ğ’³_t$ by
    â—‡ â¦Š
      â€– x_{t+1} = f_t(x_t, u_t, w_t) â¦‰
    â¦‰
    for $t = 0, â€¦, T-1$. â¦‰

  â€– Roughly speaking, the state transition functions are
    nondeterministic. â¦‰

  â€– In other words, it is uncertain which state we will arrive
    in given our current state and action. â¦‰

  â€– The choice $u_t$ only determines the distribution of
    $x_{t+1}$. â¦‰

  â€– Here $x_0$ is (still) called the â¬initial stateâ­ and is a
    random variable, usually assumed independent of the $w_t$. â¦‰
â¦‰

Â¶ â¦Š
  â€– Let $g_t: ğ’³_t Ã— ğ’°_t Ã— ğ’²_t â†’ ğ—¥ âˆª \set{âˆ}$ for $t = 0,
    â€¦, T-1$ and $g_{T}: ğ’³_T Ã— ğ’²_T â†’ ğ—¥ âˆª \set{âˆ}$. â¦‰

  â€– We call $(x_0, ğ’Ÿ, (g_t)_{t = 0}^{T})$ a â¬stochastic dynamic
    optimization problemâ­. â¦‰

  â€– As with dynamic optimization problems, we call $g_t$ the
    â¬stage cost functionâ­ and $g_T$ the â¬terminal cost functionâ­. â¦‰

  â€– It is common for these to not depend on $w_T$ (in other
    words, to be deterministic). â¦‰

  â€– It is also common for these to take infinite values to
    encode constraints. â¦‰
â¦‰

Â¶ â¦Š
  â€– As before, a stochastic dynamic optimization problem is just
    an optimization problem. â¦‰

  â€– Define $U = ğ’°_0 Ã— ğ’°_1 Ã— â‹¯ Ã— ğ’°_{T-1}$ and let $u âˆˆ U$. â¦‰

  â€– Define $C: Î© â†’ ğ—¥$ by
    â—‡ â¦Š
      â€– C = âˆ‘_{t = 0}^{T-1} g_t(x_t, u_t, w_t) + g_T(x_T, w_T). â¦‰
    â¦‰â¦‰

  â€– We call $C$ the â¬total costâ­ for actions $u$. â¦‰

  â€– It is a random variable. â¦‰
â¦‰

Â¶ â¦Š
  â€– Define $J: U â†’ ğ—¥ âˆª \set{âˆ}$ by
    â—‡ â¦Š
      â€– J = ğ—˜( â¦‰

      â€– âˆ‘_{t = 0}^{T-1} g_t(x_t, u_t, w_t) + g_T(x_T, w_T) â¦‰

      â€– ). â¦‰
    â¦‰â¦‰

  â€– $J(u)$ is the â¬expected total costâ­ for inputs $u$. â¦‰
â¦‰

Â¶ â¦Š
  â€– The optimization problem is $(U, J)$. â¦‰

  â€– In other words, the objective is the mean total stage cost
    plus the terminal cost. â¦‰
â¦‰

Â§Â§ Other terminology â¦‰
Â¶ â¦Š
  â€– Stochastic dynamic optimization problems are frequently called
    â¬stochastic control problemsâ­. â¦‰
â¦‰
