%!name:covariance
%!need:variance

\ssection{Why}

\footnote{Future editions will include this.}

\ssection{Definition}

The \t{covariance} between two random variables which are each integrable and whose product is integrable is the expectation of their product less the product of their expectation.

\ssubsection{Notation}

Let $f$ and $g$
be two integrable
random variables
with $fg$ integrable.
Denote the covariance
of $f$ with $g$
by $\cov(f, g)$.
We defined it:
\[
  \cov(f, g) = \Expect(fg) - \Expect(f)\Expect(g).
\]

\ssubsection{Properties}

\begin{prop}
  Covariance is symmetric and billinear.\footnote{Future editions will include an account.}
\end{prop}

\begin{prop}
The covariance of
a random variable
with itself is its variance.
\begin{proof}
  Let $f$ be a square-integrable
  real-valued random variable,
  then
  \[
    \cov(f, f) = \Expect(ff) - \Expect(f)\Expect(f) = \Expect(f^2) - (\Expect(f))^2 = \var(f).
  \]
\end{proof}
\end{prop}

\begin{prop}
The variance of a
sum of integrable
real-valued random variables
whose pairwise products
are integrable
is the double sum of
the pairwise covariances.
\begin{proof}
Let $f_1, \dots, f_n$
be integrable
random variables
with $f_if_j$ integrable
for all $i,j = 1, \dots, n$.
Using the billinearity,
\[
  \begin{aligned}
  \var\parens*{\sum_{i = 1}^{n} f_i}
  &= \cov\parens*{\sum_{i = 1}^{n} f_i, \sum_{i = 1}^{n}f_i} \\
    &= \sum_{i = 1}^{n} \sum_{j = 1}^{n} \cov(f_i, f_j)
  \end{aligned}
\]
\end{proof}
\end{prop}
