<!--
!name:distortion_functions
!need:quantizations
!need:random_variables
!need:expectation
!need:differential_relative_entropy
!refs:cover/chapter_10
-->

Â§ Why â¦‰
Â¶ â¦Š
  â€– We want to quantify the error of compressing a real-valued
    random variable. â¦‰
â¦‰

Â§ Definition â¦‰
Â¶ â¦Š
  â€– Let $ğ’³$ be a finite set and $q: ğ—¥ â†’ ğ’³$ a quantization
    (seeâ£
    <a href='/sheets/quantizations.html'>
      â€– Quantizations â¦‰
    </a>
    ) of $ğ—¥$. â¦‰

  â€– Also, fix a probability space $(Î©, ğ’œ, ğ—£)$ and a random
    variable $x: Î© â†’ ğ—¥$. â¦‰
â¦‰

Â¶ â¦Š
  â€– The â¬compressionâ­ $\hat{x}: Î© â†’ ğ’³$ of $x$ under $q$ is $q
    âˆ˜ x$. â¦‰

  â€– A â¬distortion functionâ­ for $x$ and $\hat{x}$ is a function
    â—‡ â¦Š
      â€– d: (Î© â†’ ğ—¥) Ã— (Î© â†’ ğ’³) â†’ ğ—¥. â¦‰
    â¦‰â¦‰

  â€– Roughly speaking, a distortion function is meant to quantify
    the error in using this compression. â¦‰
â¦‰

Â§Â§ Examples â¦‰
Â¶ â¦Š
  â€– The â¬expected mean-squared-error distortionâ­ $d_{\text{mse}}$
    between $x$ and $\hat{x}$ is
    â—‡ â¦Š
      â€– d_{\text{mse}}(x, \hat{x}) = ğ—˜[(x - \hat{x})^2] â¦‰
    â¦‰â¦‰

  â€– The â¬Kulback-Liebler distortionâ­ $d_{\text{kld}}$ defined by
    â—‡ â¦Š
      â€– d_{\text{kld}}(x, \hat{x}) = ğ—˜[d_{\text{kl}}(ğ—£(y âˆˆ Â· |x,
        \hat{x}) |ğ—£(y âˆˆ Â· |\hat{x}))] â¦‰
    â¦‰
    where $y$ is some random variable that depends on $x$.
    â€  â¦Š
      â€– Future editions will clarify this sentence. â¦‰
    â¦‰â¦‰
â¦‰

<tex>
  â€– \blankpage â¦‰
</tex>
