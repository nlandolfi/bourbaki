%!name:expectation_maximization
%!need:distribution_expectation
%!need:conditional_distributions
%!need:optimizers
%!need:distribution_selection

\ssection{Why}\footnote{Future editions will include.}


\ssection{Definition}

Let $Z$ and $X$ be non-empty finite sets.
We want to model a distribution
$p^\theta: Z \times X \to \R$.
We parameterize a family
of distributions by a parameter $\theta$.
We have a dataset $(x^1, \dots, x^n)$.
Given a parameter $\theta^0$, we want
to solve
\[
  \maximization{\theta}{\sum_{k = 1}^{n}
    \Expect_{p^{\theta^0}_{z \mid x}(z, x^k)}
    \left[
      \log p^{\theta}(z, x)
    \right]
  }
\]

\ssubsection{Binary Gaussian Mixture Example}
The

\comment{

\[
  \maximization{\theta}{\sum_{k = 1}^{n} \log p^{\theta}_x(x^k)}
\]
For $k = 1,\dots,n$
we express
\[
  \log p_{x}^{\theta}(x^k) = \sum_{z \in Z} p^\theta(z, x^k) =
  \sum_{z \in Z} p_z^\theta(z)p^\theta_{x\mid z}(x^k, z)
\]
For $k = 1, \dots, n$ let
$q^i: Z \to \R$ be a distribution on $Z$.
Then, for $k = 1\dots,n$ we express
\[
  \log p_{x}^{\theta}(x^i) = \log \left( \Expect_{z \sim q}\left[
    p_{x \mid z}^\theta (x^k, z) \frac{p^{\theta}_z(z)}{q^k(z)}
    \right]
  \right)
\]
We can lower bound this expression using Jensen's inequality
\[
  \log p_{x}^{\theta}(x^k) \geq \Expect_{z \sim q} \left[
    \log \left(p_{x \mid z}^\theta (x^k, z) \frac{p^{\theta}_z(z)}{q^k(z)}\right)
    \right]
\]
Jensen's inequality is tight if $q^k(z) \propto p_{x \mid z}(x^k, z)p_z(z)$
(some argument about it being constant?)
which means (?)
\[
  q^k(z) = p_{z \mid x}(z \mid x^k)
\]
So finally we have
\[
  \log p_{x}^\theta(x^k) \approx \Expect_{z \sim p_{z\mid x}(\cdot, x^k)}
  \left[
    \log p^\theta(z, x^k) - \log p_{z \mid x}^{\theta^0}(z, \mid x_{k})
  \right]
\]
So given $\theta^0$ we will solve
\[
  \maximization{\theta}{ \sum_{k = 1}^{n}
    \Expect_{z \sim p_{x \mid x^k}}
  \left[
    \log p^\theta(z, x^k) - \log p_{z \mid x}^{\theta^0}(z, \mid x_{k})
  \right]
  }
\]
}

\blankpage
