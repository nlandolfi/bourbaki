<!--yaml
name: maximum_likelihood_tree_normals
needs:
    - maximum_likelihood_multivariate_normals
    - matrix_trace
    - tree_approximators_of_a_normal
-->

¬ß Why ‚¶â
¬∂ ‚¶ä
  ‚Äñ What if we use the principle of maximum likelihood to
    select the maximum likelihood normal density which factors
    according to a tree? ‚¶â
‚¶â

¬ß Definition ‚¶â
¬∂ ‚¶ä
  ‚Äñ A ‚ù¨maximum likelihood tree normal‚ù≠ of a dataset in $ùó•^d$ is
    a multivariate normal density that factors according to a
    tree and maximizes the likelihood of the dataset. ‚¶â
‚¶â

¬ß Results ‚¶â
<statement type='proposition'>
  ¬∂ ‚¶ä
    ‚Äñ Let $D = (x^1, ‚Ä¶, x^n)$ be a dataset in $ùó•^d$. ‚¶â

    ‚Äñ A normal density is a maximum likelihood tree normal of
      $D$ if and only if it is an optimal tree approximator of
      the empirical normal density of $D$. ‚¶â
  ‚¶â

  <proof>
    ¬∂ ‚¶ä
      ‚Äñ First, let $f: ùó•^d ‚Üí ùó•$ be a normal density. ‚¶â
    ‚¶â

    ¬∂ ‚¶ä
      ‚Äñ First, express the log likelihood of $f$ on a record
        $x^k$ by
        ‚óá ‚¶ä
          ‚Äñ \log f(x^k) = - \frac{1}{2} (x^k - Œº)^{\tp} ‚ààv{Œ£}
            (x^k - Œº) - \frac{1}{2} \log \det Œ£ - \frac{d}{2}\log
            2œÄ. ‚¶â
        ‚¶â‚¶â
      ¬∂ ‚¶ä
        ‚Äñ Second, use the trace to rewrite the quadratic form ‚¶â
        ‚óá ‚¶ä
          ‚Äñ -\frac{1}{2}\tr{(Œ£^{-1} (x^k - Œº) (x^k - Œº)^{\tp})}. ‚¶â
        ‚¶â
      ‚¶â

      ¬∂ ‚¶ä
        ‚Äñ Third, use these two, and the linearity of trace to
          express the average negative log likelihood by ‚¶â
      ‚¶â

      ¬∂ ‚¶ä
        ‚óá ‚¶ä
          ‚Äñ \begin{aligned} ‚¶â

          ‚Äñ - \frac{1}{n} ‚àë_{k = 1}^{n} \log f(x^k) ÔºÜ=
            \frac{1}{2} \tr{(Œ£^{-1}(\frac{1}{n}‚àë_{i = 1}^{n} (x^k -
            Œº)(x^k - Œº)^{\tp}))} + \frac{1}{2}\log\detŒ£ +
            \frac{d}{2}\log 2œÄ. ‚¶â

          ‚Äñ \end{aligned} ‚¶â
        ‚¶â
      ‚¶â

      ¬∂ ‚¶ä
        ‚Äñ Fourth, use matrix calculus (or the derivation in
          Proposition 1 of Multivariate Normal Maximum Likelihood)
          to see that, for a minimizer of the negative average
          log likelihood, the mean must be $\frac{1}{n} ‚àë_{i =
          1}^{n} x^k$. ‚¶â
      ‚¶â

      ¬∂ ‚¶ä
        ‚Äñ Fifth, recognize the empirical covariance matrix
          $\frac{1}{n}‚àë_{k = 1}^{n} (x^k - Œº)(x^k - Œº)^{\tp}$;
          denote it by $S$. ‚¶â
      ‚¶â

      ¬∂ ‚¶ä
        ‚Äñ Sixth, change variables with $P = Œ£^{-1}$ and express ‚¶â
        ‚óá ‚¶ä
          ‚Äñ \log{(\det{(Œ£)})} = \log{(\det{(\inv{P})})} =
            \log{(\inv{(\det P)})} = -\log{(\det{(P)})} ‚¶â
        ‚¶â
      ‚¶â

      ¬∂ ‚¶ä
        ‚Äñ Seventh, write the likelihood in simplified form (using
          circulant property of trace) ‚¶â
        ‚óá ‚¶ä
          ‚Äñ \frac{1}{2} \tr{(SP)} - \frac{1}{2} \log \det P -
            \frac{d}{2}\log 2œÄ ‚¶â
        ‚¶â
      ‚¶â

      ¬∂ ‚¶ä
        ‚Äñ Eighth, drop the constant and prefactors: ‚¶â
        ‚óá ‚¶ä
          ‚Äñ \tr{(SP)} - \log \det P ‚¶â
        ‚¶â
      ‚¶â

      ¬∂ ‚¶ä
        ‚Äñ Ninth, if $g$ is a normal with then the tree density
          approximation objective is the same equivalent to ‚¶â
        ‚óá ‚¶ä
          ‚Äñ d(g, f) = h(g, f) - h(f) ‚àº h(g, f) = - ‚ààt_{ùó•^d}
            g\log f. ‚¶â
        ‚¶â
      ‚¶â

      ¬∂ ‚¶ä
        ‚Äñ TODO: ‚¶â

        ‚Äñ Extra, the let $g$ be normal and $f$ be normal. The
          tree normal approximation problem ‚¶â
        ‚óá ‚¶ä
          ‚Äñ d(g, f) ‚àº h(g, f) = - ‚ààt_{R^d} g \log f. ‚¶â
        ‚¶â

        ‚Äñ The log of $f$ is
          ‚óá ‚¶ä
            ‚Äñ - \frac{1}{2} \tr{( Œ£_f ‚ààt_{ùó•^d} (x - Œº_f)(x -
              Œº_f)^{\tp} dx )} - \frac{1}{2} \log \det Œ£_f^{-1} -
              \frac{d}{2} \log 2œÄ ‚¶â
          ‚¶â‚¶â
        ¬∂ ‚¶ä
          ‚Äñ Since the set of optimal solutions for both
            optimization is contained in the set of normal
            densities which match on the mean we can assume that
            $Œº_f = Œº_g$. ‚¶â

          ‚Äñ So the approximation objective is equivalent to ‚¶â
          ‚óá ‚¶ä
            ‚Äñ \tr{P_f Œ£_g} - \log \det P_f, ‚¶â
          ‚¶â

          ‚Äñ which is exactly the maximum likelihood objective. ‚¶â
        ‚¶â

        ¬∂ ‚¶ä
          ‚Äñ Thus, a solution is a maximum likelihood tree normal
            of a dataset if and only if it is an optimal tree
            approximator of the empirical normal density of the
            dataset. ‚¶â
        ‚¶â
      ‚¶â
    ‚¶â
  </proof>
</statement>