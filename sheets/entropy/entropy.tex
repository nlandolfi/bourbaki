\input{../../sheet.tex}
\sbasic
\input{../objects/macros.tex}
\input{../set_equality/macros.tex}
\input{../sets/macros.tex}
\input{../unordered_pairs/macros.tex}
\input{../identity/macros.tex}
\input{../set_inclusion/macros.tex}
\input{../sentences/macros.tex}
\input{../ordered_pairs/macros.tex}
\input{../equations/macros.tex}
\input{../power_set/macros.tex}
\input{../operations/macros.tex}
\input{../set_specification/macros.tex}
\input{../relations/macros.tex}
\input{../equation_solutions/macros.tex}
\input{../families/macros.tex}
\input{../algebras/macros.tex}
\input{../set_unions/macros.tex}
\input{../set_intersections/macros.tex}
\input{../empty_set/macros.tex}
\input{../functions/macros.tex}
\input{../zero/macros.tex}
\input{../natural_sums/macros.tex}
\input{../family_operations/macros.tex}
\input{../common_sense/macros.tex}
\input{../natural_numbers/macros.tex}
\input{../injective_functions/macros.tex}
\input{../integer_numbers/macros.tex}
\input{../natural_summation/macros.tex}
\input{../probability/macros.tex}
\input{../cardinality/macros.tex}
\input{../rational_numbers/macros.tex}
\input{../real_summation/macros.tex}
\input{../probability_outcomes/macros.tex}
\input{../intervals/macros.tex}
\input{../real_numbers/macros.tex}
\input{../probability_distributions/macros.tex}
\input{../logarithm/macros.tex}
\input{./macros.tex}
\sstart
\stitle{Entropy}

\ssection{Why}

\ssection{Definition}

The entropy of a distribution
is the
expectation of the negative
logarithm of the distribution
under the distribution.

\ssubsection{Notation}

Let $R$ denote the set of real numbers.
Let $A$ be a finite set.
Let $p:A \to R$ be a distribution.
The entropy of $p$ is
\[
  -\sum_{a \in A} p(a) \log(p(a)).
\]
We denote the entropy of $p$ by
$H(p)$.
\strats
