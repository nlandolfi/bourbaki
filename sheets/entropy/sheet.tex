%!name:entropy
%!need:probability_distributions
%!need:logarithm

\ssection{Why}

\ssection{Definition}

The entropy of a distribution
is the
expectation of the negative
logarithm of the distribution
under the distribution.

\ssubsection{Notation}

Let $A$ be a finite set.
Let $p:A \to \R$ be a distribution.
The entropy of $p$ is
\[
  -\sum_{a \in A} p(a) \log(p(a)).
\]
We denote the entropy of $p$ by
$H(p)$.

\blankpage
