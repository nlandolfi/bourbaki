%!name:random_variable_independence
%!need:random_variables
%!need:direct_products
%!need:sigma_algebra_independence

\ssection{Why}

What does it mean for
two random variables to
be independent?
What are the events associated
with a random variable?\footnote{Future editions will modify this.}

\ssection{Definition}

Two random variables are \t{independent} if the sigma algebras generated by the random variables are independent.
In generaly, a family of random variables are \t{independent} if the sigma algebras generated by the random variables are independent.

\ssubsection{Notation}

Let $(X, \SA, \mu)$ be a probability
space and $(Y, \SB)$ be a measurable
space.
Let $f_1,f_2: X \to Y$ be a random variables.
If the random variables are independent
we write $f_1 \perp f_2$.

\ssubsection{Results}

\begin{prop}
Let $f_1, \dots, f_n$
be independent real-valued
random variables
defined on a probability
space $(X, \SA, \mu)$.

Let $B_1, \dots, B_n$
be Borel sets of
real numbers
and let $A_i = f_i^{-1}(B_i)$.
Let $A = \intersect_{i = 1}^{n} f_i^{-1}(B_i)$.
Then
\[
  \mu(A)
  = \product_{i = 1}^{n} \mu(A_i)
\]
  \begin{proof}
    Since $f_i$ are independent, so
    are the sigma algebras they generate.
    $A_i$ are in each of these sigma
    algebras, so by definition of
    independence the measure of
    the intersection
    is the product of the measures.
  \end{proof}
\end{prop}
