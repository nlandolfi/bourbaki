¶ ⦊
  ‖ ❲%!name:conditional_event_probabilities❳ ⦉

  ‖ ❲%!need:event_probabilities❳ ⦉
⦉

¶ ⦊
  ‖ \ssection{Why} ⦉
⦉

¶ ⦊
  ‖ Given that we know that one event has occured, we want
    language for what the new probabilities should be.
    † ⦊
      ‖ Future editions will improve. ⦉
    ⦉⦉
⦉

¶ ⦊
  ‖ \ssection{Definition} ⦉

  ‖ Let $𝗣: \powerset{Ω} → 𝗥$ be a finite probability measure. ⦉

  ‖ Let $A, B ⊂ Ω$ and $𝗣(B) ≠ 0$. ⦉

  ‖ The ❬conditional probability❭ of $A$ ❬given❭ $B$ is fraction
    of the probability of $A ∩ B$ over the probability of $B$. ⦉
⦉

¶ ⦊
  ‖ \ssubsection{Notation} ⦉

  ‖ In a slightly slippery but universally standard notation, we
    denote the conditional probability of $A$ given $B$ by $𝗣(A
    | B)$. ⦉

  ‖ In other words, we define
    ◇ ⦊
      ‖ 𝗣(A | B) = \frac{𝗣(A ∩ B)}{𝗣(B)}, ⦉
    ⦉⦉

  ‖ whenever $A, B ⊂ Ω$ and $𝗣(B) ≠ 0$. ⦉
⦉

¶ ⦊
  ‖ \ssubsection{Induced conditional distribution} ⦉

  ‖ Conditioning on an event $B$ induces a new distribution on
    the set of outcomes. ⦉

  ‖ For $𝗣_p$, define $q: Ω → 𝗥$ by
    ◇ ⦊
      ‖ q(ω) = \begin{cases} ⦉

      ‖ \frac{p(ω)}{𝗣(B)} ❲&❳ \text{ if } ω ∈ B ᜶ ⦉

      ‖ 0 ❲&❳ \text{ otherwise. } ᜶ ⦉

      ‖ \end{cases} ⦉
    ⦉⦉

  ‖ In this case $𝗣_q(A) = 𝗣_p(A | B)$. ⦉

  ‖ We call $q$ the ❬conditional distribution❭ induced by
    ❬conditioning on❭ the event $B$. ⦉
⦉

¶ ⦊
  ‖ \ssection{Total probability} ⦉

  ‖ Using the notation $𝗣(\cdot | \cdot)$, we can express the
    law of total probability for $𝗣(B)$, $B ⊂ Ω$, as
    ◇ ⦊
      ‖ \textstyle ⦉

      ‖ 𝗣(B) = ∑_{i = 1}^{n} 𝗣(A_i)𝗣(B | A_i), ⦉
    ⦉
    where $A_1, …, A_n$ partition $Ω$. ⦉
⦉
