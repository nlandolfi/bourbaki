Â¶ â¦Š
  â€– â²%!name:real_matrix-vector_productsâ³ â¦‰

  â€– â²%thur vector_as_matrices %!need:real_matricesâ³ â¦‰

  â€– â²%!need:vectors_as_matricesâ³ â¦‰

  â€– â²%!need:real_linear_combinationsâ³ â¦‰

  â€– â²%!refs:nlaâ³ â¦‰
â¦‰

Â¶ â¦Š
  â€– \ssection{Why} â¦‰

  â€– We explore matrix-vector multiplication. â¦‰
â¦‰

Â¶ â¦Š
  â€– \ssection{Definition} â¦‰

  â€– Given a matrix $A âˆˆ ğ—¥^{m Ã— n}$ and a vector $x âˆˆ ğ—¥^{n}$,
    the â¬productâ­ of $A$ â¬withâ­ $x$ is the vector $y âˆˆ ğ—¥^{m}$
    defined by
    â—‡ â¦Š
      â€– y_i = âˆ‘_{j = 1}^{n} A_{ij} x_j, \quad i = 1, â€¦, m. â¦‰
    â¦‰â¦‰
â¦‰

Â¶ â¦Š
  â€– \ssubsection{Notation} â¦‰

  â€– We denote the product of $A$ with $x$ by $Ax$. â¦‰

  â€– With which we concisely write the system linear equations
    $(A, b)$ as $b = Ax$. â¦‰
â¦‰

Â¶ â¦Š
  â€– This notation suggests both algebraic and geometric
    interpretations of solving systems of linear equations. â¦‰

  â€– The algebraic interpretation is that we are interested in
    the invertibility of the function $x \mapsto Ax$. â¦‰

  â€– In other words, we are interested in the existence of an
    inverse element of $A$. â¦‰

  â€– The geometric interpretation is that $A$ transforms the
    vector $x$. â¦‰
â¦‰

Â¶ â¦Š
  â€– Conversely, we can view $x$ as transforming (acting on) $A$. â¦‰

  â€– Let $a^j âˆˆ ğ—¥^m$ denote the $j$th column of $A$, then
    â—‡ â¦Š
      â€– Ax = âˆ‘_{j = 1}^{n} x_j a^j. â¦‰
    â¦‰â¦‰

  â€– In other words, $y$ is linear combination of the columns of
    $A$. â¦‰
â¦‰

Â¶ â¦Š
  â€– \ssection{Properties} â¦‰

  â€– We call the function $f: ğ—¥^n â†’ ğ—¥^m$ defined by $f(x) =
    Ax$ the â¬matrix multiplication functionâ­ (or â¬matrix-vector
    product functionâ­) associated with $A$. â¦‰

  â€– $f$ is satisfies the following two important properties:
    ğ« â¦Š
      â€£ $A(x + y) = Ax + Ay$ â¦‰

      â€£ $A(\alpha x) = \alpha Ax$. â¦‰
    â¦‰â¦‰

  â€– We call such a function $f$ â¬linearâ­. â¦‰

  â€– In other words, the matrix multiplication function is linear. â¦‰

  â€– Conversely, if $g: ğ—¥^n â†’ ğ—¥^m$ is linear, there exists a
    matrix inducing $g$. â¦‰
â¦‰

Â¶ â¦Š
  â€– \begin{proposition} â¦‰

  â€– Let $f: ğ—¥^n â†’ ğ—¥^m$ be linear. â¦‰

  â€– Then there exists a unique $A âˆˆ ğ—¥^{m Ã— n}$ satisfying
    $f(x) = Ax$ for all $x âˆˆ ğ—¥^n$. â¦‰

  â€– \end{proposition} â¦‰
â¦‰

Â¶ â¦Š
  â€– \begin{proof} â¦‰

  â€– Evaluate $f$ at the standard unit vectors $e_i$. â¦‰

  â€– The $i$th component of $e_i$ is 1 and all other components
    are 0. â¦‰

  â€– \end{proof} â¦‰
â¦‰
