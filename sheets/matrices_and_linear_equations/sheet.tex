%!name:matrices_and_linear_equations
%!need:matrix-vector_products
%!need:linear_equations

\ssection{Why}

We discuss linear systems of equations using the algebra of matrices.\footnote{Future sheets may invert this ordering, and motivate matrices by linear equations.}

\ssection{Discussion}

Let $(A \in \R^{m \times n}, b \in \R^{m})$ be a linear system of equations.
The two-dimensional array $A$ is a matrix.
Recall that we want to find $x \in \R^{n}$ to satisfy the simultaneous equations
\[
  \begin{aligned}
  A_{11}x_1 & \cdots & A_{1n}x_n & = b_1 \\
  & & \vdots & \\
  A_{m1}x_1 & \cdots & A_{mn}x_n & = b_m
  \end{aligned}
\]

Using the notation for a matrix-vector product, we can compactly write the above as
\[
  Ax = b.
\]
This short statement encodes all $m$ linear equations.
For this reason $A$ is often called the \t{coefficient matrix}.

Moreover it provides an algebraic and geometric interpretation of solving systems of linear equations.
The algebraic interpretation is that we are interested in the invertibility of the map $x \mapsto Ax$.
In other words, we are interested in the existence of an inverse element of $A$.
The geometric interpretation is that $A$ transforms the vector $x$.

\blankpage
