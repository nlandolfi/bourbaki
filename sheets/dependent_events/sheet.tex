%!name:dependent_events
%!need:conditional_event_probabilities

\ssection{Why}
We want to talk about how knowledge of one aspect of an outcome can give us knowledge about another aspect.

\ssection{Definition}

Two events $A, B \subset \Omega $ are \t{independent} under a probability measure $\mathbfsf{P} : \powerset{\Omega } \to \R $ if
  \[
\mathbfsf{P} (A \cap B) = \mathbfsf{P} (A)\mathbfsf{P} (B).
  \]
In other words, they are independent if the probability of their intersection is the product of their respective probabilities.
Otherwise, we call $A$ and $B$ \t{dependent}.

In the case that $\mathbfsf{P} (B) \neq 0$, then $\mathbfsf{P} (A \cap B) = \mathbfsf{P} (A)\mathbfsf{P} (B)$ is equivalent to $\mathbfsf{P} (A \mid B) = \mathbfsf{P} (A)$, which more clearly expresses the intuition captured by the definition.
Roughly speaking, we interpret this second expression as encoding the fact that the occurence of event $B$ does not change the probability---intuitively, the \say{credibility}---of the event $A$.

\ssubsection{Example: two dice}

Define $\Omega  = \Set{(\omega _1, \omega _2)}{ \omega _i \in \set{1, \dots, 6}}$, and interpret $\omega  \in \Omega $ as corresponding to pips face up after rolling two dice.
Define $p: \Omega  \to \R $ by $p(\omega ) = \nicefrac{1}{36}$.

Two events are $A = \Set{\omega  \in \Omega }{ \omega _1 + \omega _2 > 5}$, \say{the sum is greater than 5}, and $B = \Set{\omega  \in \Omega }{\omega _1 > 3}$, \say{the number of pips on the first die is greater than 3}.
Then $\mathbfsf{P} (A) = \nicefrac{26}{36}$.
Also, $\mathbfsf{P} (A \mid B) = \nicefrac{17}{16}$.
So, these events are dependent.
Roughly speaking, we say that knowing $B$ tells us something about $A$.
In this case, we say that it \say{makes $A$ more probable.}

In the language used to describe the events, we say that knowledge that the number of pips on the first die is greater than three makes its more probable that the sum of the number of pips on each die is greater than 5.

\ssubsection{Basic implications}
Since $\mathbfsf{P} (\cdot \mid B)$ is a probability measure, and the events $A$ and $\relcomplement{A}{\Omega }$ partition $\Omega $, we have
  \[
\mathbfsf{P} (A \mid B) + \mathbfsf{P} (\relcomplement{A}{\Omega } \mid B) = 1.
  \]
From which we deduce $\mathbfsf{P} (\relcomplement{A}{\Omega } \mid B) = 1 - \mathbfsf{P} (A) = \mathbfsf{P} (\relcomplement{A}{\Omega })$.
Which is equivalent to $\mathbfsf{P} (\relcomplement{A}{\Omega } \cap B) = \mathbfsf{P} (\relcomplement{A}{\Omega })\mathbfsf{P} (B)$.
In other words, $B$ and $\relcomplement{A}{\Omega }$ are independent events.
Similarly, $A$ and $\relcomplement{B}{\Omega }$ are independent events.
Since $(\Omega  - A) \cap (\Omega  - B) = \Omega  - (A \cup B)$, we have
  \[
\mathbfsf{P} (A \cup B) + P(\relcomplement{A}{\Omega } \cap \relcomplement{B}{\Omega }) = 1.
  \]
Since $\mathbfsf{P} (A \cup B) = \mathbfsf{P} (A) + \mathbfsf{P} (B) - \mathbfsf{P} (A \cap B)$, we obtain
  \[
P(\relcomplement{A}{\Omega } \cap \relcomplement{B}{\Omega }) = 1 - \mathbfsf{P} (A) - \mathbfsf{P} (B) - \mathbfsf{P} (A)\mathbfsf{P} (B).
  \]
We can express the right hand side as $(1 - \mathbfsf{P} (A))(1 - \mathbfsf{P} (B))$ or $\mathbfsf{P} (\relcomplement{A}{\Omega })\mathbfsf{P} (\relcomplement{B}{\Omega })$.
In other words, $\relcomplement{A}{\Omega }$ and $\relcomplement{B}{\Omega }$ are independent.
