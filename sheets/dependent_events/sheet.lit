<!--
!name:dependent_events
!need:conditional_event_probabilities
-->

§ Why ⦉
¶ ⦊
  ‖ We want to talk about how knowledge of one aspect of an
    outcome can give us knowledge about another aspect. ⦉
⦉

§ Definition ⦉
¶ ⦊
  ‖ Two events $A, B ⊂ Ω$ are ❬independent❭ under a probability
    measure $𝗣: \powerset{Ω} → 𝗥$ if
    ◇ ⦊
      ‖ 𝗣(A ∩ B) = 𝗣(A)𝗣(B). ⦉
    ⦉⦉

  ‖ In other words, they are independent if the probability of
    their intersection is the product of their respective
    probabilities. ⦉

  ‖ Otherwise, we call $A$ and $B$ ❬dependent❭. ⦉
⦉

¶ ⦊
  ‖ In the case that $𝗣(B) ≠ 0$, then $𝗣(A ∩ B) = 𝗣(A)𝗣(B)$
    is equivalent to $𝗣(A \mid B) = 𝗣(A)$, which more clearly
    expresses the intuition captured by the definition. ⦉

  ‖ Roughly speaking, we interpret this second expression as
    encoding the fact that the occurence of event $B$ does not
    change the probability—intuitively, the “credibility”—of the
    event $A$. ⦉
⦉

§§ Example: two dice ⦉
¶ ⦊
  ‖ Define $Ω = \Set{(ω_1, ω_2)}{ ω_i ∈ \set{1, …, 6}}$, and
    interpret $ω ∈ Ω$ as corresponding to the number of pips
    face up after rolling two dice. ⦉

  ‖ Define $p: Ω → 𝗥$ by $p(ω) = 1/36$. ⦉
⦉

¶ ⦊
  ‖ Two events are $A = \Set{ω ∈ Ω}{ ω_1 + ω_2 > 5}$, “the
    sum is greater than 5”, and $B = \Set{ω ∈ Ω}{ω_1 > 3}$,
    “the number of pips on the first die is greater than 3”. ⦉

  ‖ Then $𝗣(A) = 26/36$. ⦉

  ‖ Also, $𝗣(A | B) = 17/16$. ⦉

  ‖ So, these events are dependent. ⦉

  ‖ Roughly speaking, we say that knowing $B$ tells us something
    about $A$. ⦉

  ‖ In this case, we say that it “makes $A$ more probable.” ⦉
⦉

¶ ⦊
  ‖ In the language used to describe the events, we say that
    knowledge that the number of pips on the first die is
    greater than three makes its more probable that the sum of
    the number of pips on each die is greater than 5. ⦉
⦉

§§ Basic implications ⦉
¶ ⦊
  ‖ Since $𝗣(\cdot | B)$ is a probability measure, and the
    events $A$ and $\relcomplement{A}{Ω}$ partition $Ω$, we have
    ◇ ⦊
      ‖ 𝗣(A | B) + 𝗣(\relcomplement{A}{Ω} | B) = 1. ⦉
    ⦉⦉

  ‖ From which we deduce $𝗣(\relcomplement{A}{Ω} | B) = 1 -
    𝗣(A) = 𝗣(\relcomplement{A}{Ω})$. ⦉

  ‖ Which is equivalent to $𝗣(\relcomplement{A}{Ω} ∩ B) =
    𝗣(\relcomplement{A}{Ω})𝗣(B)$. ⦉

  ‖ In other words, $B$ and $\relcomplement{A}{Ω}$ are independent
    events. ⦉

  ‖ Similarly, $A$ and $\relcomplement{B}{Ω}$ are independent
    events. ⦉

  ‖ Since $(Ω - A) ∩ (Ω - B) = Ω - (A ∪ B)$, we have
    ◇ ⦊
      ‖ 𝗣(A ∪ B) + P(\relcomplement{A}{Ω} ∩ \relcomplement{B}{Ω})
        = 1. ⦉
    ⦉
    Since $𝗣(A ∪ B) = 𝗣(A) + 𝗣(B) - 𝗣(A ∩ B)$, we obtain
    ◇ ⦊
      ‖ P(\relcomplement{A}{Ω} ∩ \relcomplement{B}{Ω}) = 1 - 𝗣(A)
        - 𝗣(B) - 𝗣(A)𝗣(B). ⦉
    ⦉⦉

  ‖ We can express the right hand side as $(1 - 𝗣(A))(1 -
    𝗣(B))$ or $𝗣(\relcomplement{A}{Ω})𝗣(\relcomplement{B}{Ω})$. ⦉

  ‖ In other words, $\relcomplement{A}{Ω}$ and
    $\relcomplement{B}{Ω}$ are independent. ⦉
⦉
