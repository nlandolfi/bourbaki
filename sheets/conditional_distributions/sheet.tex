%!name:conditional_distributions
%!need:marginal_distributions
%!need:conditional_event_probability
%!need:probability_distributions

\ssection{Why}

Conditioning defines a new probability mass function on the set of outcomes.

\ssection{Definition}

The conditional probability
of any two events
defines a new probability
mass function over the
set of outcomes
which is in the second
event.
The conditional probability
of an outcome
is the probability of the
second event
divided into the original probability
of the outcome.

\ssection{Notation}

Let $p$ be a probability
mass function on the set of
outcomes $A$ with the corresponding
event probability function $\PE$.
Then the conditional probability
mass function of $C$ conditioned
on $B$ is $q: C \to \R$, defined
so that
\[
  q(a) = \begin{cases}
    \frac{p(a)}{\PE(B)} & \text{ if } a \in B \\
    0 & \text{ otherwise }.
  \end{cases}
\]

\ssection{Definition}

\ssubsection{Notation}

Let $R$ denote the set of
real numbers.
Let $A_1, \dots, A_n$ be
a sequence of non-empty finite
sets.
Let $A = \prod_{i = 1}^{n} A_i$
Let $p: A \to R$ be a distribution
on $A$.
We denote the conditional
distribution of $i$ on $j$ of
$p$ by $p_{i \mid j}: A_i \times A_j \to R$
For $i,j = 1, \dots, n$ and $i \neq j$
$p_i$ satisifes
\[
  p_{i \mid j}(b, c)p_{j}(c) = p_{ij}(b, c)
\]
for every $b \in A_i$ and $c \in A_j$.
