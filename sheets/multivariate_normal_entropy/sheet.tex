%!name:multivariate_normal_entropy
%!need:positive_semidefinite_matrix_order
%!need:differential_entropy
%!need:probability_measures

\ssection{Why}

\ssection{Result}

\begin{proposition}
Let $x: \Omega \to \R^d$ be a normally distributed random variable on a probability space $(\Omega, \CA, \PM)$ with mean $\mu \in \R^d$ and covariance $\Sigma \succ 0$. Let $g: \R^d \to \R$ be the density of $x$. Then the entropy of $x$ is
\[
  h(g) = -\int g \log g = \frac{1}{2} \log ((2\pi e)^d \det\Sigma)
\]
\end{proposition}

This result tells us the \t{multivariate normal entropy} or \t{Gaussian entropy}.


\blankpage
