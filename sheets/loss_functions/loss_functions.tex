\input{../../sheet.tex}
\sbasic
\input{../set_equality/macros.tex}
\input{../sets/macros.tex}
\input{../ordered_pairs/macros.tex}
\input{../objects/macros.tex}
\input{../set_inclusion/macros.tex}
\input{../sentences/macros.tex}
\input{../relations/macros.tex}
\input{../identity/macros.tex}
\input{../operations/macros.tex}
\input{../set_specification/macros.tex}
\input{../functions/macros.tex}
\input{../equations/macros.tex}
\input{../arithmetic/macros.tex}
\input{../natural_numbers/macros.tex}
\input{../families/macros.tex}
\input{../equation_solutions/macros.tex}
\input{../natural_order/macros.tex}
\input{../natural_families/macros.tex}
\input{../integer_numbers/macros.tex}
\input{../direct_products/macros.tex}
\input{../rational_numbers/macros.tex}
\input{../datasets/macros.tex}
\input{../real_numbers/macros.tex}
\input{../inductors/macros.tex}
\input{./macros.tex}
\sstart
\stitle{Loss Functions}

\ssection{Why}

We want to compare inductors
by comparing their produced predictors.
We compare predictors by judging predictions.

\ssection{Definition}

A \t{loss} function is a nonnegative real-valued function on pairs which is zero only on repeated pairs.
It need not be symmetric.
We interpret the first argument of the
loss function as our prediction
and the second as the recorded value.

The \t{loss of a predictor on a pair} is the
result of the loss function on the pair.
Similarly, the \t{loss of a predictor on  a sequence} of pairs is the sum of the losses on the pairs.
The \t{average loss of a predictor on a sequence} is the loss divided by the length of the sequence.

\ssubsection{Notation}

Let $(a, b) \in A \times B$
where $A$ and $B$ are non-empty sets.
Let $\loss: B \cross B \to \R$.
Let $f: A \to B$.
The loss of $f$ on $(a, b)$ is
\[
  \loss(f(a),b).
\]
Let $s = ((a^1, b^1), \dots, (a^n, b^n))$
be a record sequence.
The loss of $f$ on $s$ is
\[
  \sum_{k = 1}^{n} \loss(f(a^k), b^k).
\]
The average loss of $f$ on $s$ is
\[
  \frac{1}{n} \sum_{k = 1}^{n} \loss(f(a^k), b^k).
\]



\ssubsection{Dual Record Prediction Evaluators}

Let $i$ be an inductor and let
$r$ and $s$ be two record sequences.
Denote the predictor $i(r)$ associated
with $r$ by $f$.
Let $g$ be a prediction evaluator.
Let $s = ((u^1, v^n), \dots, (u^n, v^n))$.
Then consider
\[
  \sum_{i = 1}^{n} g(f(u^n), v^n)).
\]


Consider an inductor, two record
sequences, and a prediction evaluator.
Consider
Consider the predictor
associated with first record sequences.
Consider the evaluator which
sums the prediction errors on the
second record sequence of the
the predictor induced on the first record
sequence.

The natural evaluator associated with
this inductor is the
We consider the pred
The first record sequencerecord sequence

Commonly evaluators have
structure.
We fix a record sequence
and consider the predictor
induced by it.
We consider a second
record sequence
and compare the predictor's
result for a precept with
the postcept paired with it
in the second record sequence.


A \ct{data-set evaluator}{} is
the evaluator for which
\strats
