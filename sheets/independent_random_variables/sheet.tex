%!name:independent_random_variables
%!need:random_variables
%!need:independent_sigma_algebras

\ssection{Why}

What does it mean for two random variables to be independent?
What are the events associated with a random variable?
  \ifhmode\unskip\fi\footnote{
Future editions will modify this.
  }

\ssection{Definition}

Two random variables are \t{independent} if the sigma algebras generated by the random variables are independent.
In general, a family of random variables are \t{independent} if the sigma algebras generated by the random variables are independent.

\ssubsection{Notation}

Let $(X, \mathcal{A} , \mu )$ be a probability space and $(Y, \SB)$ be a measurable space.
Let $f_1,f_2: X \to Y$ be random variables.
If the random variables are independent we write $f_1 \perp f_2$.

\ssubsection{Results}

\begin{prop}
Let $f_1, \dots , f_n$ be independent real-valued random variables defined on a probability space $(X, \mathcal{A} , \mu )$.

Let $B_1, \dots , B_n$ be Borel sets of real numbers and let $A_i = f_i^{-1}(B_i)$.
Let $A = \cap_{i = 1}^{n} f_i^{-1}(B_i)$.
Then
  \[
\mu (A) = \prod_{i = 1}^{n} \mu (A_i)
  \]
\begin{proof}
Since $f_i$ are independent, so are the sigma algebras they generate.
$A_i$ are in each of these sigma algebras, so by definition of independence the measure of the intersection is the product of the measures.
\end{proof}
\end{prop}
