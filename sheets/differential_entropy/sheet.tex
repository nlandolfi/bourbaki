%!name:differential_entropy
%!need:probability_density_function
%!need:entropy

\ssection{Why}

We want a notion of entropy
for continuous random variables.

\ssection{Definition}

The \ct{relative entropy}{}
of a probability density function
is the integral of the density
against the negative log
of the density.

\ssubsection{Notation}

Let $R$ denote the set of
real numbers.
Let $f: R^n \to R$ be
a probability density function.
The differential entropy of $f$
is
\[
  - \int f \log f
\]
We denote the differential entropy
of $f$ by $h(f)$.
