<!DOCTYPE html>
  <meta charset="utf-8"/>
  <head>
    <link rel="stylesheet" href="../style.css">
    <link rel="stylesheet" href="../fonts.css">
    <script src="../pdfjs/build/pdf.js"></script>
  </head>
  <body>
    <div class="header">
      <span class="listing no-border" id="header-trademark-and-title">
        <img id="header-trademark" src="../trademark.jpg" onclick="location.href='../index.html'">
        <span id="header-title" onclick="location.href='./feature_maps.pdf#page=2'"> Feature Maps </span>
      </span>
    </div>
    <div class="subheader">
      <div disabled class="need label"> Links: </div>
      <div class="need" tabindex="0" onclick="location.href='./feature_maps.pdf#page=2'" onkeypress="location.href='./feature_maps.pdf#page=2'">
        <span> Sheet PDF </span>
        <span class="caret">›</span>
      </div>
      <div class="need" tabindex="0" onclick="location.href='./feature_maps-graph.pdf'" onkeypress="location.href='./feature_maps-graph.pdf'">
        <span> Graph PDF </span>
        <span class="caret">›</span>
      </div>
      
        <div disabled class="need label"> Needs: </div>
        
            <div class="need" tabindex="0" onclick="location.href='./least_squares_linear_regressors.html'" onkeypress="location.href='./least_squares_linear_regressors.html'">
              <span>
                Least Squares Linear Regressors
              </span>
              <span class="caret">›</span>
            </div>
        
      
      
        <div disabled class="need label"> Needed by: </div>
        
          <div class="need" tabindex="0" onclick="location.href='./featurized_probabilistic_linear_models.html'" onkeypress="location.href='./featurized_probabilistic_linear_models.html'">
            <span>
            Featurized Probabilistic Linear Models
            </span>
            <span class="caret">›</span>
          </div>
        
          <div class="need" tabindex="0" onclick="location.href='./polynomial_regressors.html'" onkeypress="location.href='./polynomial_regressors.html'">
            <span>
            Polynomial Regressors
            </span>
            <span class="caret">›</span>
          </div>
        
          <div class="need" tabindex="0" onclick="location.href='./probabilistic_errors_linear_model.html'" onkeypress="location.href='./probabilistic_errors_linear_model.html'">
            <span>
            Probabilistic Errors Linear Model
            </span>
            <span class="caret">›</span>
          </div>
        
      
    </div>

      <link rel="stylesheet" href="../katex/katex.min.css">
      <script src="../katex/katex.min.js"></script>
      <script src="../katex/auto-render.min.js"></script>
      <script>
      document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(
          document.body,
          {
            delimiters: [
              {left: "$$", right: "$$", display: true},
              {left: "$", right: "$", display: false},
            ],
          },
        );
      });
    </script>
    <div id="sheet-card" class="card">
      <div class="sheet-listing" id="why"><h1 class="sheet">1. Why</h1></div><div class="sheet-listing"><p class="sheet"> Linear predictors are simple and we know how to select the parameters. The main downside is that there may not be a linear relationship between inputs and outputs.</p></div><div class="sheet-listing" id="definition"><h1 class="sheet">2. Definition</h1></div><div class="sheet-listing"><p class="sheet"> A \t{feature map} (or \t{regression function}) for outputs $A$ is a mapping $\phi: A \to \R^d$. In this setting, we call $a \in A$ the \t{raw input record} and we call $\phi(a)$ an \t{embedding}, \t{feature embedding} or \t{feature vector}. We call the components of a feature vector the \t{features}. We call $\phi(A)$ the \t{regression range}.</p></div><div class="sheet-listing"><p class="sheet"> A feature map is \t{faithful} if, whenever records $a_i$ and $a_j$ are in some sense "similar" in the set $A$, the embeddings $\phi(a_i)$ and $\phi(a_j)$ are close in the vector space $\R^d$.</p></div><div class="sheet-listing"><p class="sheet"> Since it is common for raw input records $a \in A$ to consist of many fields, it is regular to have several feature maps $\phi_i$ which operate component-wise on the fields of $a$. These are sometimes called \t{basis functions}, by analogy with real function approximators (see \sheetref{real_function_approximators}{Real Function Apppoximators}). We concatenate these field feature maps and commonly add a constant feature $1$. Since $\R^d$ is a vector space, it is common to refer to it in this case as the \t{feature space}.</p></div><div class="sheet-listing"><p class="sheet"> Given a dataset $a = (a^1, \dots, a^n)$ in $A$ and a feature map $\phi: A \to \R^d$, the \t{embedded dataset} of $a$ with respect to $\phi$ is the dataset $(\phi(a^1), \dots, \phi(a^n)$ in $\R^d$.</p></div><div class="sheet-listing"><h2 class="sheet" id="featurized_consistency:_a_route_around_$x_\neq_\r^d$">2.1 Featurized consistency: a route around $X \neq \R^d$</h2></div><div class="sheet-listing"><p class="sheet"> Recall that a dataset is parametrically consistent with the family $\set{h_{\theta}: X \to Y}_{\theta}$ if there exists $\theta^\star$ so that the dataset is consistent with $\theta^{\star}$. We saw how to pick $\theta$ if we use a linear model with a squared loss (see \sheetref{least_squares_linear_regressors}{Least Squares Linear Regressors}).</p></div><div class="sheet-listing"><p class="sheet"> Let $\CG = \set{g_{\theta}: \R^d \to \R}_{\theta}$. A dataset is \t{featurized parametrically consistent} with respect to the family $\CG$ and the feature map $\phi: X \to \R^d$ if it is parametrically consistent with respect to $\CG \composed \phi = \Set*{g \composed \phi}{g \in \CG}$.</p></div><div class="sheet-listing"><p class="sheet"> The interpretation is that we have transformed the problem of selecting a predictor on an arbitrary space $X$ to the problem of selecting a predictor on the space $\R^d$. In so doing, we can continue to use simple predictors, such as those that are linear and minimize the squared error on the dataset.\footnote{Future editions are likely to modify this section.}</p></div><div class="sheet-listing"><p class="sheet"> In other words, we have "shifted emphasis} from the model function $h: X \to \R$ to the \t{regression function" from $\R^d \to \R$. If we know the features and the input $x$, then we know the \t{regression vector} $\phi(x)$. The \t{regression range} is the set $\Set*{\phi(x)}{x \in X}$. In this case linearity pertains to the parameters $\theta \in \R^d$ instead of the inputs (or experimental conditions) $x \in X$.</p></div>
    </div>

    <div style="display: flex; flex-direction: row; justify-content: center; flex-wrap: wrap">

    <div id="wrapper1">
      <canvas id="page1" style="direction: ltr;"></canvas>
    </div>
    <div id="wrapper2">
      <canvas id="page2" style="direction: ltr;"></canvas>
    </div>
    <div id="wrapper3">
    <canvas id="page3" style="border: 1px solid black; direction: ltr;"></canvas>
    </div>
      <script id="script">
        // If absolute URL from the remote server is provided, configure the CORS
        // header on that server.
        var url = './feature_maps.pdf';

        // The workerSrc property shall be specified.
        pdfjsLib.GlobalWorkerOptions.workerSrc =
          '../pdfjs/build/pdf.worker.js';

        var PRINT_RESOLUTION = 300;

        function render(page, wrapper, canvas) {
          var scale = 7;
          var viewport = page.getViewport({scale: scale});
          var context = canvas.getContext('2d');

          canvas.width = viewport.width;
          canvas.height = viewport.height;
          canvas.style.width = "100%";
          canvas.style.height = "100%";
          wrapper.style.width = Math.floor(viewport.width/scale) + 'pt';
          wrapper.style.height = Math.floor(viewport.height/scale) + 'pt';

          // see https://stackoverflow.com/questions/37861686/pdfjs-blurry-pdf-on-ipad
          // who knows if this works...
          context.imageSmoothingEnabled = false;
          context.webkitImageSmoothingEnabled = false;
          context.mozImageSmoothingEnabled = false;
          context.oImageSmoothingEnabled = false;

          /*

          if (window.devicePixelRatio > 1) {
            var canvasWidth = canvas.width;
            var canvasHeight = canvas.height;

            canvas.width = canvasWidth * window.devicePixelRatio;
            canvas.height = canvasHeight * window.devicePixelRatio;
            canvas.style.width = canvasWidth + "px";
            canvas.style.height = canvasHeight + "px";

            context.scale(window.devicePixelRatio, window.devicePixelRatio);
          }
          //end see
          */

          var renderContext = {
            canvasContext: context,
            viewport: viewport
          };
          page.render(renderContext);
        }

        // Asynchronous download PDF
        var loadingTask = pdfjsLib.getDocument(url);
        loadingTask.promise.then(function(pdf) {

          // Fetch the first page
          pdf.getPage(2).then(function(page) {
              render(page, document.getElementById('wrapper1'), document.getElementById('page1'));
          });

          // Fetch the second page
          pdf.getPage(3).then(function(page) {
            render(page, document.getElementById('wrapper2'), document.getElementById('page2'));
          });

          // Fetch the third page
          pdf.getPage(4).then(function(page) {
            render(page, document.getElementById('wrapper3'), document.getElementById('page3'));
          });
        });
      </script>

    <!-- PAGES -->
    <!--
    <iframe id="sheet-pdf" src="./feature_maps.pdf#page=2">
    </iframe>
    <iframe id="sheet-pdf" src="./feature_maps.pdf#page=3">
    </iframe>
    -->
    <!-- PAGES -->

    </div>

    <!-- <iframe id="graph-pdf" src="./feature_maps-graph.pdf">
    </iframe>
    -->

    <span id="footer">
      Copyright 2021 The Bourbaki Authors. Version c8a962f40.
    </span>
  </body>
</html>
