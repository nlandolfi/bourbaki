<!DOCTYPE html>
  <meta charset="utf-8"/>
  <head>
    <link rel="stylesheet" href="../style.css">
    <link rel="stylesheet" href="../fonts.css">
    <script src="../pdfjs/build/pdf.js"></script>
  </head>
  <body>
    <div class="header">
      <span class="listing no-border" id="header-trademark-and-title">
        <img id="header-trademark" src="../trademark.jpg" onclick="location.href='../index.html'">
        <span id="header-title" onclick="location.href='./eigenvalues_and_eigenvectors.pdf#page=2'"> Eigenvalues and Eigenvectors </span>
      </span>
    </div>
    <div class="subheader">
      <div disabled class="need label"> Links: </div>
      <div class="need" tabindex="0" onclick="location.href='./eigenvalues_and_eigenvectors.pdf#page=2'" onkeypress="location.href='./eigenvalues_and_eigenvectors.pdf#page=2'">
        <span> Sheet PDF </span>
        <span class="caret">›</span>
      </div>
      <div class="need" tabindex="0" onclick="location.href='./eigenvalues_and_eigenvectors-graph.pdf'" onkeypress="location.href='./eigenvalues_and_eigenvectors-graph.pdf'">
        <span> Graph PDF </span>
        <span class="caret">›</span>
      </div>
      
        <div disabled class="need label"> Needs: </div>
        
            <div class="need" tabindex="0" onclick="location.href='./matrix_determinants.html'" onkeypress="location.href='./matrix_determinants.html'">
              <span>
                Matrix Determinants
              </span>
              <span class="caret">›</span>
            </div>
        
            <div class="need" tabindex="0" onclick="location.href='./monic_polynomials.html'" onkeypress="location.href='./monic_polynomials.html'">
              <span>
                Monic Polynomials
              </span>
              <span class="caret">›</span>
            </div>
        
            <div class="need" tabindex="0" onclick="location.href='./norms.html'" onkeypress="location.href='./norms.html'">
              <span>
                Norms
              </span>
              <span class="caret">›</span>
            </div>
        
            <div class="need" tabindex="0" onclick="location.href='./real_matrices.html'" onkeypress="location.href='./real_matrices.html'">
              <span>
                Real Matrices
              </span>
              <span class="caret">›</span>
            </div>
        
            <div class="need" tabindex="0" onclick="location.href='./real_vectors.html'" onkeypress="location.href='./real_vectors.html'">
              <span>
                Real Vectors
              </span>
              <span class="caret">›</span>
            </div>
        
      
      
        <div disabled class="need label"> Needed by: </div>
        
          <div class="need" tabindex="0" onclick="location.href='./eigenvalue_decomposition.html'" onkeypress="location.href='./eigenvalue_decomposition.html'">
            <span>
            Eigenvalue Decomposition
            </span>
            <span class="caret">›</span>
          </div>
        
          <div class="need" tabindex="0" onclick="location.href='./symmetric_real_matrix_eigenvalues.html'" onkeypress="location.href='./symmetric_real_matrix_eigenvalues.html'">
            <span>
            Symmetric Real Matrix Eigenvalues
            </span>
            <span class="caret">›</span>
          </div>
        
      
    </div>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {Augment: {
    Definitions: {macros: {nicefrac: 'XFrac'}},
    Parse: {prototype: {
      XFrac: function (name) {
        var num = this.ParseArg(name);
        var den = this.ParseArg(name);
        this.Push(MathJax.ElementJax.mml.mfrac(num,den).With({bevelled: true}));
      }
    }}
  }}
});
</script>
    <script>
      MathJax = {
        loader: {load: ['[tex]/mathtools', '[tex]/upgreek', '[tex]/physics']},
        tex: {
          inlineMath: [
              ['\\(', '\\)'],
              ['$', '$']
            ],
          displayMath: [
              ['$$', '$$'],
              ['\\[', '\\]']
            ],
          macros: {
                  powerset: ["2^{#1}", 1],
                  CV: "\\mathcal{V}",
                  ceil: ["\\lceil #1 \\rceil", 1],
                  num: ["\\abs{#1}",1],
                  Set: ["\\{#1 : #2\\}", 2],
          },
          packages: {'[+]': ['mathtools', 'upgreek', 'physics']},
        },
      };
    </script>
    <script src="../mathjax/polyfill.min.js"></script>
    <script id="MathJax-script" async src="../mathjax/tex-mml-chtml.js"></script>
    <!--
      <link rel="stylesheet" href="../katex/katex.min.css">
      <script src="../katex/katex.min.js"></script>
      <script src="../katex/auto-render.min.js"></script>
      <script>
      document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(
          document.body,
          {
            delimiters: [
              {left: "$$", right: "$$", display: true},
              {left: "$", right: "$", display: false},
            ],
          },
        );
      });
    </script>
    -->
    <script src="../cytoscape/cytoscape.min.js"></script>

    <div id="sheet-card" class="card">
      <div class="sheet-listing"><p class="sheet"> \section*{Why}</p></div><div class="sheet-listing"><p class="sheet"> We discuss vectors for which the action of a matrix is scalar multiplication. \ifhmode\unskip\fi\footnote{ Future editions will expand. }</p></div><div class="sheet-listing"><p class="sheet"> \section*{Definition}</p></div><div class="sheet-listing"><p class="sheet"> Let $A \in \R ^{n \times n}$ be a square matrix. A nonzero vector $x \in \R ^{n}$ is an \t{eigenvector} of $A$, and $\lambda  \in \R $ is its corresponding \t{eigenvalue}, if $A x = \lambda  x$. In other words, $x \neq 0$ is an eigenvector if the action of $A$ on $x$ is to mimic scalar multiplication.</p></div><div class="sheet-listing"><p class="sheet"> Speaking of eigenvalues is sensible only when the matrix involved is square. In other words, when the domain and codomain are the same. We often care about eigenvalue computations when a matrix is compounded iteratively.</p></div><div class="sheet-listing"><p class="sheet"> \section*{Eigenspaces}</p></div><div class="sheet-listing"><p class="sheet"> If $x$ is an eigenvector with eigenvalue $\lambda $, then for any $\alpha  \in \R $, $\alpha  x$ is an eigenvector with eigenvalue $\alpha \lambda $, since $A (\alpha  x) = \alpha  (Ax) = (\alpha \lambda ) x$. In other words, if $A$ has an eigenvector then the action of $A$ on some subspace $S \subset \R ^n$ is to mimic scalar multiplication. In this case, we call the subspace $S$ an \t{eigenspace}, and any nonzero $x \in S$ an eigenvector.</p></div><div class="sheet-listing"><p class="sheet"> An eigenspace is an \t{invariant subspace} of $A$. In other words, if $E$ is an eigenspace corresponding to eigenvalue $\lambda $ then $AE \subset E$.</p></div><div class="sheet-listing"><p class="sheet"> The dimension of $E$ is the maximum number of linear independent eigenvectors which have the same eigenvalue $\lambda $. We call this number the \t{geometric multiplicity} of $\lambda $.</p></div><div class="sheet-listing"><p class="sheet"> \section*{Characteristic polynomial}</p></div><div class="sheet-listing"><p class="sheet"> If $x$ is an eigenvector for $A$ associated with $\lambda $ then $Ax = \lambda  x$ so $Ax - \lambda  x = 0$ and $(A - \lambda  I)x = 0$. In other words, $x$ is an element of the nullspace of $A - \lambda  I$. Or equivalently, $\lambda  I - A$.</p></div><div class="sheet-listing"><p class="sheet"> The \t{characteristic polynomial} of $A \in \R ^{n \times n}$ is the polynomial $p: \R  \to \R $ in defined by \[ p(x) = \det (zI - A). \] $p$ is monic: the coefficient of the degree $n$ term is 1. \begin{proposition} $\lambda $ is an eigenvalue of $A$ if and only if $p(\lambda ) = 0$. \begin{proof} Since $\lambda $ is an eigenvalue if and only if there is a nonzero vector $x$ such that $\lambda  x - Ax = 0$, if and only if $\lambda  I - A$ is singular, if and only if $\det(\lambda  I - A) = 0$. \end{proof} \label{proposition:eigenvalues_and_eigenvectors:characteristic_polynomial} \end{proposition} A simple consequence of Proposition~\ref{proposition:eigenvalues_and_eigenvectors:characteristic_polynomial} is that a (real) matrix may have complex eigenvalues.</p></div>
    </div>

    <div style="display: flex; flex-direction: row; justify-content: center; flex-wrap: wrap">

    <div id="wrapper1">
      <canvas id="page1" style="direction: ltr;"></canvas>
    </div>
    <div id="wrapper2">
      <canvas id="page2" style="direction: ltr;"></canvas>
    </div>
    <div id="wrapper3">
    <canvas id="page3" style="direction: ltr;" onclick="location.href='./eigenvalues_and_eigenvectors-graph.pdf'"></canvas>
    </div>
      <script id="script">
        // If absolute URL from the remote server is provided, configure the CORS
        // header on that server.
        var url = './eigenvalues_and_eigenvectors.pdf';

        // The workerSrc property shall be specified.
        pdfjsLib.GlobalWorkerOptions.workerSrc =
          '../pdfjs/build/pdf.worker.js';

        var PRINT_RESOLUTION = 300;

        function render(page, wrapper, canvas) {
          var scale = 7;
          var viewport = page.getViewport({scale: scale});
          var context = canvas.getContext('2d');

          canvas.width = viewport.width;
          canvas.height = viewport.height;
          canvas.style.width = "100%";
          canvas.style.height = "100%";
          wrapper.style.width = Math.floor(viewport.width/scale) + 'pt';
          wrapper.style.height = Math.floor(viewport.height/scale) + 'pt';

          // see https://stackoverflow.com/questions/37861686/pdfjs-blurry-pdf-on-ipad
          // who knows if this works...
          context.imageSmoothingEnabled = false;
          context.webkitImageSmoothingEnabled = false;
          context.mozImageSmoothingEnabled = false;
          context.oImageSmoothingEnabled = false;

          /*

          if (window.devicePixelRatio > 1) {
            var canvasWidth = canvas.width;
            var canvasHeight = canvas.height;

            canvas.width = canvasWidth * window.devicePixelRatio;
            canvas.height = canvasHeight * window.devicePixelRatio;
            canvas.style.width = canvasWidth + "px";
            canvas.style.height = canvasHeight + "px";

            context.scale(window.devicePixelRatio, window.devicePixelRatio);
          }
          //end see
          */

          var renderContext = {
            canvasContext: context,
            viewport: viewport
          };
          page.render(renderContext);
        }

        // Asynchronous download PDF
        var loadingTask = pdfjsLib.getDocument(url);
        loadingTask.promise.then(function(pdf) {

          // Fetch the first page
          pdf.getPage(2).then(function(page) {
              render(page, document.getElementById('wrapper1'), document.getElementById('page1'));
          });

          // Fetch the second page
          pdf.getPage(3).then(function(page) {
            render(page, document.getElementById('wrapper2'), document.getElementById('page2'));
          });

          // Fetch the third page
          pdf.getPage(4).then(function(page) {
            render(page, document.getElementById('wrapper3'), document.getElementById('page3'));
          });
        });
      </script>

    <!-- PAGES -->
    <!--
    <iframe id="sheet-pdf" src="./eigenvalues_and_eigenvectors.pdf#page=2">
    </iframe>
    <iframe id="sheet-pdf" src="./eigenvalues_and_eigenvectors.pdf#page=3">
    </iframe>
    -->
    <!-- PAGES -->

    </div>

    <!-- <iframe id="graph-pdf" src="./eigenvalues_and_eigenvectors-graph.pdf">
    </iframe>
    -->

  
    <div class="lit">
    <!--
!name:eigenvalues_and_eigenvectors
!need:real_matrices
!need:real_vectors
!need:norms
!need:matrix_determinants
!need:monic_polynomials
-->

<h1>
Why </h1>

<p>
 <span class='run'>We discuss vectors for which the action of a
  matrix is scalar multiplication.<sup id='footnote-1-reference'><a href='#footnote-1'>1</a></sup></span>
</p>

<h1>
Definition </h1>

<p>
 <span class='run'>Let $A ∈ 𝗥^{n × n}$ be a square matrix. </span>

 <span class='run'>A nonzero vector $x ∈ 𝗥^{n}$ is an
  <span class='term'>eigenvector</span> of $A$, and
  $λ ∈ 𝗥$ is its corresponding
  <span class='term'>eigenvalue</span>, if $A x = λ
  x$. </span>

 <span class='run'>In other words, $x ≠ 0$ is an eigenvector if
  the action of $A$ on $x$ is to mimic scalar
  multiplication. </span>
</p>


<p>
 <span class='run'>Speaking of eigenvalues is sensible only when
  the matrix involved is square. </span>

 <span class='run'>In other words, when the domain and codomain
  are the same. </span>

 <span class='run'>We often care about eigenvalue computations when
  a matrix is compounded iteratively. </span>
</p>


<!--
<div data-littype='paragraph'>
  <div data-littype='run'> ❲%\ssubsection{Notation}❳ </div>

  <div data-littype='run'> ❲%❳ </div>

  <div data-littype='run'> ❲%The spectrum of $A ∈ 𝗥^{n × n}$ is sometimes denoted $\Lambda(A)$.❳ </div>
</div>
-->

<h1>
Eigenspaces </h1>

<p>
 <span class='run'>If $x$ is an eigenvector with eigenvalue $λ$,
  then for any $α ∈ 𝗥$, $α x$ is an eigenvector
  with eigenvalue $αλ$, since $A (α x) = α (Ax)
  = (αλ) x$. </span>

 <span class='run'>In other words, if $A$ has an eigenvector then
  the action of $A$ on some subspace $S ⊂ 𝗥^n$
  is to mimic scalar multiplication. </span>

 <span class='run'>In this case, we call the subspace $S$ an
  <span class='term'>eigenspace</span>, and any
  nonzero $x ∈ S$ an eigenvector. </span>
</p>


<p>
 <span class='run'>An eigenspace is an <span class='term'>invariant
  subspace</span> of $A$. </span>

 <span class='run'>In other words, if $E$ is an eigenspace
  corresponding to eigenvalue $λ$ then $AE ⊂ E$. </span>
</p>


<p>
 <span class='run'>The dimension of $E$ is the maximum number of
  linear independent eigenvectors which have the
  same eigenvalue $λ$. </span>

 <span class='run'>We call this number the
  <span class='term'>geometric multiplicity</span> of
  $λ$. </span>
</p>

<h1>
Characteristic polynomial </h1>

<p>
 <span class='run'>If $x$ is an eigenvector for $A$ associated
  with $λ$ then $Ax = λ x$ so $Ax - λ x = 0$
  and $(A - λ I)x = 0$. </span>

 <span class='run'>In other words, $x$ is an element of the
  nullspace of $A - λ I$. Or equivalently, $λ I
  - A$. </span>
</p>


<p>
 <span class='run'>The <span class='term'>characteristic
  polynomial</span> of $A ∈ 𝗥^{n × n}$ is the
  polynomial $p: 𝗥 → 𝗥$ in defined by
  <p>\[
   p(x) = \det (zI - A). 
  \]</p>
  <span class='run'>$p$ is monic: the coefficient of the degree
   $n$ term is 1. </span>

  <span class='run'>\begin{proposition} </span>

  <span class='run'>$λ$ is an eigenvalue of $A$ if and only if
   $p(λ) = 0$. </span>

  <span class='run'>\begin{proof} </span>

  <span class='run'>Since $λ$ is an eigenvalue if and only if
   there is a nonzero vector $x$ such that $λ x
   - Ax = 0$, if and only if $λ I - A$ is
   singular, if and only if $\det(λ I - A) = 0$. </span>

  <span class='run'>\end{proof} </span>

  <span class='run'>\label{proposition:eigenvalues_and_eigenvectors:characteristic_polynomial} </span>

  <span class='run'>\end{proposition} </span>

  <span class='run'>A simple consequence of
   Proposition~\ref{proposition:eigenvalues_and_eigenvectors:characteristic_polynomial}
   is that a (real) matrix may have complex
   eigenvalues. </span></span>
</p>


<!--
formerly Matrix Eigenvectors sheet

%!name:matrix_eigenvectors
%!need:matrix-vector_products
%!need:norms

\ssection{Why}\footnote{Future editions will include an account.}

\ssection{Definition}

If the result of multiplying a vector by a real square matrix is the same as scaling the vector by a real number then we call the vector a \t{scaled vector}.
If a vector is a scaled vector, then the result of scaling it with any real number is a scaled vector.
% ($Ax = \alpha x \implies A \beta x = \beta Ax = \beta \alpha x$).

The scaled version of a scaled vector is acted upon by the matrix in a similar manner as the original scaled vector.
So we want to characterize this notion by picking one representative member from this set of vectors which are scalar multiples of each other, and a reasonable choice is the vector which has norm one.\footnote{Future editions will change this language.}

An \t{eigenvector} is a scaled vector whose norm is one.
An \t{eigenvalue} corresponding to an eigenvector is the real number by which the eigenvector is scaled by the matrix.
So eigenvectors and eigenvalues come in pairs.

\blankpage

-->
<ol class='footnotes'><li id='footnote-1'> <span class='run'>Future editions will expand. </span><a href='#footnote-1-reference'>↩︎</a></li></ol>
    </div>
  

  <!--
  <div id="cy" style="height:1000px;width:1000px;">
  </div>
    <script>
      var cy = cytoscape({
        container: document.getElementById('cy'), // container to render in
                elements: [ // list of graph elements to start with
                            { // node a
                                          data: { id: 'a' }
                                        },
                            { // node b
                                          data: { id: 'b' }
                                        },
                            { // edge ab
                                          data: { id: 'ab', source: 'a', target: 'b' }
                                        }
                          ],

                style: [ // the stylesheet for the graph
                            {
                                          selector: 'node',
                                          style: {
                                                          'background-color': '#666',
                                                          'label': 'data(id)'
                                                        }
                                        },

                            {
                                          selector: 'edge',
                                          style: {
                                                          'width': 3,
                                                          'line-color': '#ccc',
                                                          'target-arrow-color': '#ccc',
                                                          'target-arrow-shape': 'triangle',
                                                          'curve-style': 'bezier'
                                                        }
                                        }
                          ],

                layout: {
                            name: 'grid',
                            rows: 1
                          }

      });
    </script>
    -->


    <span id="footer">
      Copyright 2022 The Bourbaki Authors. Version 77ab37752.
    </span>
  </body>
</html>
