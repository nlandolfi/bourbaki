<!DOCTYPE html>
  <meta charset="utf-8"/>
  <head>
    <link rel="stylesheet" href="../style.css">
    <link rel="stylesheet" href="../fonts.css">
    <script src="../pdfjs/build/pdf.js"></script>
  </head>
  <body>
    <div class="header">
      <span class="listing no-border" id="header-trademark-and-title">
        <img id="header-trademark" src="../trademark.jpg" onclick="location.href='../index.html'">
        <span id="header-title" onclick="location.href='./variational_autoencoders.pdf#page=2'"> Variational Autoencoders </span>
      </span>
    </div>
    <div class="subheader">
      <div disabled class="need label"> Links: </div>
      <div class="need" tabindex="0" onclick="location.href='./variational_autoencoders.pdf#page=2'" onkeypress="location.href='./variational_autoencoders.pdf#page=2'">
        <span> Sheet PDF </span>
        <span class="caret">›</span>
      </div>
      <div class="need" tabindex="0" onclick="location.href='./variational_autoencoders-graph.pdf'" onkeypress="location.href='./variational_autoencoders-graph.pdf'">
        <span> Graph PDF </span>
        <span class="caret">›</span>
      </div>
      
        <div disabled class="need label"> Needs: </div>
        
            <div class="need" tabindex="0" onclick="location.href='./autoencoders.html'" onkeypress="location.href='./autoencoders.html'">
              <span>
                Autoencoders
              </span>
              <span class="caret">›</span>
            </div>
        
            <div class="need" tabindex="0" onclick="location.href='./parametric_distribution_network_families.html'" onkeypress="location.href='./parametric_distribution_network_families.html'">
              <span>
                Parametric Distribution Network Families
              </span>
              <span class="caret">›</span>
            </div>
        
            <div class="need" tabindex="0" onclick="location.href='./probabilistic_models.html'" onkeypress="location.href='./probabilistic_models.html'">
              <span>
                Probabilistic Models
              </span>
              <span class="caret">›</span>
            </div>
        
      
      
    </div>

      <link rel="stylesheet" href="../katex/katex.min.css">
      <script src="../katex/katex.min.js"></script>
      <script src="../katex/auto-render.min.js"></script>
      <script>
      document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(
          document.body,
          {
            delimiters: [
              {left: "$$", right: "$$", display: true},
              {left: "$", right: "$", display: false},
            ],
          },
        );
      });
    </script>
    <div id="sheet-card" class="card">
      <div class="sheet-listing" id="why}\footnote{future_editions_will_include._future_editions_may_also_change_the_name_of_this_sheet._it_is_also_likely_that_there_will_be_added_prerequisite_sheets_on_variational_inference."><h1 class="sheet">1. Why}\footnote{Future editions will include. Future editions may also change the name of this sheet. It is also likely that there will be added prerequisite sheets on variational inference.</h1></div><div class="sheet-listing" id="parameterizing_distributions"><h1 class="sheet">2. Parameterizing distributions</h1></div><div class="sheet-listing" id="definition"><h1 class="sheet">3. Definition</h1></div><div class="sheet-listing"><p class="sheet"> A \t{variational autoencoder} is an ordered pair whose first coordinate with \t{latent distribution} (density) $p_z: Z \to \R$ and \t{observation distribution} (density) $p_x: X \to \R$ is a ordered pair $()$ discrete (continuous) latent set $Z$ and discrete (continuous) observation set $X$ is a tuple</p></div><div class="sheet-listing"><p class="sheet"> where (a) $\nu$ is an autoencoder (which need not be regular, see \sheetref{autoencoders}{Autoencoders}), (b) $q_{z \mid x}: Z \times X \to \R$ is a conditional distribution (density) called the \t{recognition distribution} (\t{recognition density}), (c) $p_{z}: Z \to \R$ is a distribution (density) called the \t{latent prior model}, and (d) $p_{x \mid z}: X \times Z \to \R$ is a conditional distribution (density) called the \t{generating model}.</p></div><div class="sheet-listing"><p class="sheet"> In other words, for (a) $q_{z \mid x}(\cdot, \xi): Z \to \R$ is a distribution (density) for each $\xi \in X$ and for (d) $p_{x \mid z}(\cdot, \zeta): X \to \R$ is a distribution (density) on $X$ for each $\zeta \in Z$.</p></div><div class="sheet-listing"><p class="sheet"> If the model has discrete latent set and discrete observation set (or continuous latent set and continuous observation set), the \t{joint distribution} (\t{joint density}) $p_{zx}: Z \times X \to \R$ is defined by $p_{zx} = p_{z}p_{x \mid z}$. The \t{observation distribution}</p></div><div class="sheet-listing"><p class="sheet"> A \t{continuous-continuous variational autoencoder family} (\t{discrete-discrete}, \t{discrete-continuous}, \t{continuous-discrete}) is a tuple \[ (\nu, \set{(q^{(\theta)}, p_z^{(\theta)}, p_{x \mid z}^{(\theta))})}_{\theta \in \Theta}), \] where: \begin{itemize}</p></div><div class="sheet-listing"><p class="sheet"> \item $\nu$ is an autoencoder with encoder $f: \R^d \to \R^k$ and decoder $g: \R^\ell \to \R^m$. The autoencoder need not be regular, see \sheetref{autoencoders}{Autoencoders}).</p></div><div class="sheet-listing"><p class="sheet"> \item $\Theta \subset \R^p$. The \t{parameter set} (or \t{parameter space}).</p></div><div class="sheet-listing"><p class="sheet"> \item $q^{(\theta)}: \R^h \to \R$ is a density (distribution, density, distribution), for each $\theta \in \Theta$. We call $\set{q^{(\theta)}}_{\theta \in \Theta}$ the \t{recognition model family}.</p></div><div class="sheet-listing"><p class="sheet"> \item $p_{z}^{\theta}: \R^h \to \R$ is a density (distribution, distribution, density), for each $\theta \in \Theta$. We call $\set{p_{z}^{(\theta)}}_{\theta}$ the \t{latent prior model family}.</p></div><div class="sheet-listing"><p class="sheet"> \item $p_{x \mid z}^{(\theta)}: \R^d \times \R^h \to \R$ is a conditional density (distribution, density, distribution). In other words,  $p_{x \mid z}^{(\theta)}(\cdot, \zeta): \R^d \to \R$ is a density (distribution, density, distribution) for every $\zeta \in \R^d$. We call $\set{p_{x \mid z}^{(\theta)}}_{\theta \in \Theta}$ the \t{observation model family}. \end{itemize}</p></div><div class="sheet-listing"><p class="sheet"> A \t{variational autoencoder} (or \t{VAE}) may refer to any of the above. The convention we have adopted is "latent type}-\say{observation type".</p></div><div class="sheet-listing"><p class="sheet"> \blankpage</p></div>
    </div>

    <div style="display: flex; flex-direction: row; justify-content: center; flex-wrap: wrap">

    <div id="wrapper1">
      <canvas id="page1" style="direction: ltr;"></canvas>
    </div>
    <div id="wrapper2">
      <canvas id="page2" style="direction: ltr;"></canvas>
    </div>
    <div id="wrapper3">
    <canvas id="page3" style="direction: ltr;" onclick="location.href='./variational_autoencoders-graph.pdf'"></canvas>
    </div>
      <script id="script">
        // If absolute URL from the remote server is provided, configure the CORS
        // header on that server.
        var url = './variational_autoencoders.pdf';

        // The workerSrc property shall be specified.
        pdfjsLib.GlobalWorkerOptions.workerSrc =
          '../pdfjs/build/pdf.worker.js';

        var PRINT_RESOLUTION = 300;

        function render(page, wrapper, canvas) {
          var scale = 7;
          var viewport = page.getViewport({scale: scale});
          var context = canvas.getContext('2d');

          canvas.width = viewport.width;
          canvas.height = viewport.height;
          canvas.style.width = "100%";
          canvas.style.height = "100%";
          wrapper.style.width = Math.floor(viewport.width/scale) + 'pt';
          wrapper.style.height = Math.floor(viewport.height/scale) + 'pt';

          // see https://stackoverflow.com/questions/37861686/pdfjs-blurry-pdf-on-ipad
          // who knows if this works...
          context.imageSmoothingEnabled = false;
          context.webkitImageSmoothingEnabled = false;
          context.mozImageSmoothingEnabled = false;
          context.oImageSmoothingEnabled = false;

          /*

          if (window.devicePixelRatio > 1) {
            var canvasWidth = canvas.width;
            var canvasHeight = canvas.height;

            canvas.width = canvasWidth * window.devicePixelRatio;
            canvas.height = canvasHeight * window.devicePixelRatio;
            canvas.style.width = canvasWidth + "px";
            canvas.style.height = canvasHeight + "px";

            context.scale(window.devicePixelRatio, window.devicePixelRatio);
          }
          //end see
          */

          var renderContext = {
            canvasContext: context,
            viewport: viewport
          };
          page.render(renderContext);
        }

        // Asynchronous download PDF
        var loadingTask = pdfjsLib.getDocument(url);
        loadingTask.promise.then(function(pdf) {

          // Fetch the first page
          pdf.getPage(2).then(function(page) {
              render(page, document.getElementById('wrapper1'), document.getElementById('page1'));
          });

          // Fetch the second page
          pdf.getPage(3).then(function(page) {
            render(page, document.getElementById('wrapper2'), document.getElementById('page2'));
          });

          // Fetch the third page
          pdf.getPage(4).then(function(page) {
            render(page, document.getElementById('wrapper3'), document.getElementById('page3'));
          });
        });
      </script>

    <!-- PAGES -->
    <!--
    <iframe id="sheet-pdf" src="./variational_autoencoders.pdf#page=2">
    </iframe>
    <iframe id="sheet-pdf" src="./variational_autoencoders.pdf#page=3">
    </iframe>
    -->
    <!-- PAGES -->

    </div>

    <!-- <iframe id="graph-pdf" src="./variational_autoencoders-graph.pdf">
    </iframe>
    -->

    <span id="footer">
      Copyright 2022 The Bourbaki Authors. Version c38f38914.
    </span>
  </body>
</html>
