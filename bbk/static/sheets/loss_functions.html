<!DOCTYPE html>
  <meta charset="utf-8"/>
  <head>
    <link rel="stylesheet" href="../style.css">
    <link rel="stylesheet" href="../fonts.css">
    <script src="../pdfjs/build/pdf.js"></script>
  </head>
  <body>
    <div class="header">
      <span class="listing no-border" id="header-trademark-and-title">
        <img id="header-trademark" src="../trademark.jpg" onclick="location.href='../index.html'">
        <span id="header-title" onclick="location.href='./loss_functions.pdf#page=2'"> Loss Functions </span>
      </span>
    </div>
    <div class="subheader">
      <div disabled class="need label"> Links: </div>
      <div class="need" tabindex="0" onclick="location.href='./loss_functions.pdf#page=2'" onkeypress="location.href='./loss_functions.pdf#page=2'">
        <span> Sheet PDF </span>
        <span class="caret">›</span>
      </div>
      <div class="need" tabindex="0" onclick="location.href='./loss_functions-graph.pdf'" onkeypress="location.href='./loss_functions-graph.pdf'">
        <span> Graph PDF </span>
        <span class="caret">›</span>
      </div>
      
        <div disabled class="need label"> Needs: </div>
        
            <div class="need" tabindex="0" onclick="location.href='./inductors.html'" onkeypress="location.href='./inductors.html'">
              <span>
                Inductors
              </span>
              <span class="caret">›</span>
            </div>
        
            <div class="need" tabindex="0" onclick="location.href='./real_numbers.html'" onkeypress="location.href='./real_numbers.html'">
              <span>
                Real Numbers
              </span>
              <span class="caret">›</span>
            </div>
        
      
      
        <div disabled class="need label"> Needed by: </div>
        
          <div class="need" tabindex="0" onclick="location.href='./least_squares_linear_regressors.html'" onkeypress="location.href='./least_squares_linear_regressors.html'">
            <span>
            Least Squares Linear Regressors
            </span>
            <span class="caret">›</span>
          </div>
        
          <div class="need" tabindex="0" onclick="location.href='./normal_random_function_regressors.html'" onkeypress="location.href='./normal_random_function_regressors.html'">
            <span>
            Normal Random Function Regressors
            </span>
            <span class="caret">›</span>
          </div>
        
      
    </div>

      <link rel="stylesheet" href="../katex/katex.min.css">
      <script src="../katex/katex.min.js"></script>
      <script src="../katex/auto-render.min.js"></script>
      <script>
      document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(
          document.body,
          {
            delimiters: [
              {left: "$$", right: "$$", display: true},
              {left: "$", right: "$", display: false},
            ],
          },
        );
      });
    </script>
    <div id="sheet-card" class="card">
      <div class="sheet-listing" id="why"><h1 class="sheet">1. Why</h1></div><div class="sheet-listing"><p class="sheet"> We compare inductors by comparing the predictors they produce. We compare predictors by judging predictions.</p></div><div class="sheet-listing" id="definition"><h1 class="sheet">2. Definition</h1></div><div class="sheet-listing"><p class="sheet"> A \t{loss} function is a nonnegative real-valued function on pairs which is zero only on repeated pairs. It need not be symmetric. A loss function is often also called a \t{cost} or \t{risk} function.</p></div><div class="sheet-listing"><p class="sheet"> We use loss functions to judge a prediction in comparison to the recorded postcept. The first argument of the loss function is the predicted postcept and the second is the recorded (observed, true, recorded) postcept.</p></div><div class="sheet-listing"><p class="sheet"> The \t{loss of a predictor on a pair} is the result of the loss function on the pair. Similarly, the \t{loss of a predictor on a dataset} of record pairs is the sum of the losses on the pairs of the dataset. Likewise, the \t{average loss} of a predictor is the loss of the predictor on the dataset divided by the size of the dataset. The average loss is also known as the \t{empirical risk} of the predictor on the dataset.</p></div><div class="sheet-listing"><h2 class="sheet" id="notation">2.1 Notation</h2></div><div class="sheet-listing"><p class="sheet"> Let $(a, b) \in A \times B$; $A, B \neq \emptyset$. For a lost function $\loss: B \cross B \to \R$ and predictor $f: A \to B$, the loss of $f$ on $(a, b)$ is $\loss(f(a),b)$. Let $s = ((a^1, b^1), \dots, (a^n, b^n))$ be a record sequence. The loss of $f$ on $s$ is $\sum_{k = 1}^{n} \loss(f(a^k), b^k)$. The average loss of $f$ on $s$ is $(\nicefrac{1}{n})\sum_{k = 1}^{n} \loss(f(a^k), b^k)$.</p></div><div class="sheet-listing" id="training_and_test_loss"><h1 class="sheet">3. Training and test loss</h1></div><div class="sheet-listing"><p class="sheet"> Recall that $s$ is a dataset of records pairs in $A \times B$. We call a predictor $f: A \to B$ an \t{interpolator} of the dataset $s$ if, for each pair $(a^i, b^i)$ in the dataset, $f(a^i) = b^i$. An interpolator achieves zero loss on the dataset it interpolates.</p></div><div class="sheet-listing"><p class="sheet"> The rub is that an interpolator may have nonzero loss a record pair which is not contained in the dataset used to construct it. For this reason, it is common to consider two datasets. First, the one used to construct the predictor (the \t{training dataset}) and second, one used to evaluate the predictor (the \t{test dataset}, \t{validation dataset} or \t{evaluation dataset}).</p></div><div class="sheet-listing"><p class="sheet"> We judge a predictor by its average loss on the test dataset. We call this the \t{test loss}, in contrast with the \t{train loss} obtained on the dataset used to construct the predictor. A predictor whose average test loss is much larger than its average train lost is said to be \t{overfit} to the train dataset.\footnote{Many authorities will refer to this as the "problem} or \say{danger} of overfitting."</p></div><div class="sheet-listing"><p class="sheet"> Roughly speaking, we judge an inductor by some aggregation metric of the loss of predictors it produces on datasets.</p></div>
    </div>

    <div style="display: flex; flex-direction: row; justify-content: center; flex-wrap: wrap">

    <div id="wrapper1">
      <canvas id="page1" style="direction: ltr;"></canvas>
    </div>
    <div id="wrapper2">
      <canvas id="page2" style="direction: ltr;"></canvas>
    </div>
    <div id="wrapper3">
    <canvas id="page3" style="border: 1px solid black; direction: ltr;"></canvas>
    </div>
      <script id="script">
        // If absolute URL from the remote server is provided, configure the CORS
        // header on that server.
        var url = './loss_functions.pdf';

        // The workerSrc property shall be specified.
        pdfjsLib.GlobalWorkerOptions.workerSrc =
          '../pdfjs/build/pdf.worker.js';

        var PRINT_RESOLUTION = 300;

        function render(page, wrapper, canvas) {
          var scale = 7;
          var viewport = page.getViewport({scale: scale});
          var context = canvas.getContext('2d');

          canvas.width = viewport.width;
          canvas.height = viewport.height;
          canvas.style.width = "100%";
          canvas.style.height = "100%";
          wrapper.style.width = Math.floor(viewport.width/scale) + 'pt';
          wrapper.style.height = Math.floor(viewport.height/scale) + 'pt';

          // see https://stackoverflow.com/questions/37861686/pdfjs-blurry-pdf-on-ipad
          // who knows if this works...
          context.imageSmoothingEnabled = false;
          context.webkitImageSmoothingEnabled = false;
          context.mozImageSmoothingEnabled = false;
          context.oImageSmoothingEnabled = false;

          /*

          if (window.devicePixelRatio > 1) {
            var canvasWidth = canvas.width;
            var canvasHeight = canvas.height;

            canvas.width = canvasWidth * window.devicePixelRatio;
            canvas.height = canvasHeight * window.devicePixelRatio;
            canvas.style.width = canvasWidth + "px";
            canvas.style.height = canvasHeight + "px";

            context.scale(window.devicePixelRatio, window.devicePixelRatio);
          }
          //end see
          */

          var renderContext = {
            canvasContext: context,
            viewport: viewport
          };
          page.render(renderContext);
        }

        // Asynchronous download PDF
        var loadingTask = pdfjsLib.getDocument(url);
        loadingTask.promise.then(function(pdf) {

          // Fetch the first page
          pdf.getPage(2).then(function(page) {
              render(page, document.getElementById('wrapper1'), document.getElementById('page1'));
          });

          // Fetch the second page
          pdf.getPage(3).then(function(page) {
            render(page, document.getElementById('wrapper2'), document.getElementById('page2'));
          });

          // Fetch the third page
          pdf.getPage(4).then(function(page) {
            render(page, document.getElementById('wrapper3'), document.getElementById('page3'));
          });
        });
      </script>

    <!-- PAGES -->
    <!--
    <iframe id="sheet-pdf" src="./loss_functions.pdf#page=2">
    </iframe>
    <iframe id="sheet-pdf" src="./loss_functions.pdf#page=3">
    </iframe>
    -->
    <!-- PAGES -->

    </div>

    <!-- <iframe id="graph-pdf" src="./loss_functions-graph.pdf">
    </iframe>
    -->

    <span id="footer">
      Copyright 2021 The Bourbaki Authors. Version 98f4e0b90.
    </span>
  </body>
</html>
