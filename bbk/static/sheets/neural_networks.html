<!DOCTYPE html>
  <meta charset="utf-8"/>
  <head>
    <link rel="stylesheet" href="../style.css">
    <link rel="stylesheet" href="../fonts.css">
    <script src="../pdfjs/build/pdf.js"></script>
  </head>
  <body>
    <div class="header">
      <span class="listing no-border" id="header-trademark-and-title">
        <img id="header-trademark" src="../trademark.jpg" onclick="location.href='../index.html'">
        <span id="header-title" onclick="location.href='./neural_networks.pdf#page=2'"> Neural Networks </span>
      </span>
    </div>
    <div class="subheader">
      <div disabled class="need label"> Links: </div>
      <div class="need" tabindex="0" onclick="location.href='./neural_networks.pdf#page=2'" onkeypress="location.href='./neural_networks.pdf#page=2'">
        <span> Sheet PDF </span>
        <span class="caret">‚Ä∫</span>
      </div>
      <div class="need" tabindex="0" onclick="location.href='./neural_networks-graph.pdf'" onkeypress="location.href='./neural_networks-graph.pdf'">
        <span> Graph PDF </span>
        <span class="caret">‚Ä∫</span>
      </div>
      
        <div disabled class="need label"> Needs: </div>
        
            <div class="need" tabindex="0" onclick="location.href='./real_matrix-vector_products.html'" onkeypress="location.href='./real_matrix-vector_products.html'">
              <span>
                Real Matrix-Vector Products
              </span>
              <span class="caret">‚Ä∫</span>
            </div>
        
            <div class="need" tabindex="0" onclick="location.href='./regressors.html'" onkeypress="location.href='./regressors.html'">
              <span>
                Regressors
              </span>
              <span class="caret">‚Ä∫</span>
            </div>
        
      
      
        <div disabled class="need label"> Needed by: </div>
        
          <div class="need" tabindex="0" onclick="location.href='./autoencoders.html'" onkeypress="location.href='./autoencoders.html'">
            <span>
            Autoencoders
            </span>
            <span class="caret">‚Ä∫</span>
          </div>
        
          <div class="need" tabindex="0" onclick="location.href='./neural_distribution_families.html'" onkeypress="location.href='./neural_distribution_families.html'">
            <span>
            Neural Distribution Families
            </span>
            <span class="caret">‚Ä∫</span>
          </div>
        
      
    </div>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {Augment: {
    Definitions: {macros: {nicefrac: 'XFrac'}},
    Parse: {prototype: {
      XFrac: function (name) {
        var num = this.ParseArg(name);
        var den = this.ParseArg(name);
        this.Push(MathJax.ElementJax.mml.mfrac(num,den).With({bevelled: true}));
      }
    }}
  }}
});
</script>
    <script>
      MathJax = {
        loader: {load: ['[tex]/mathtools', '[tex]/upgreek', '[tex]/physics']},
        tex: {
          inlineMath: [
              ['\\(', '\\)'],
              ['$', '$']
            ],
          displayMath: [
              ['$$', '$$'],
              ['\\[', '\\]']
            ],
          macros: {
                  powerset: ["2^{#1}", 1],
                  CV: "\\mathcal{V}",
          },
          packages: {'[+]': ['mathtools', 'upgreek', 'physics']},
        },
      };
    </script>
    <script src="../mathjax/polyfill.min.js"></script>
    <script id="MathJax-script" async src="../mathjax/tex-mml-chtml.js"></script>
    <!--
      <link rel="stylesheet" href="../katex/katex.min.css">
      <script src="../katex/katex.min.js"></script>
      <script src="../katex/auto-render.min.js"></script>
      <script>
      document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(
          document.body,
          {
            delimiters: [
              {left: "$$", right: "$$", display: true},
              {left: "$", right: "$", display: false},
            ],
          },
        );
      });
    </script>
    -->
    <script src="../cytoscape/cytoscape.min.js"></script>

    <div id="sheet-card" class="card">
      <div class="sheet-listing" id="why"><h1 class="sheet">1. Why</h1></div><div class="sheet-listing"><p class="sheet"> \ifhmode\unskip\fi\footnote{ Future editions will include. Future editions may change the name of this sheet to \t{computation networks}, or may add prerequisite sheet on computation graphs. }</p></div><div class="sheet-listing" id="definition"><h1 class="sheet">2. Definition</h1></div><div class="sheet-listing"><p class="sheet"> A sequence of functions $(g_1, \dots, g_\ell)$ is \t{composable} if $g_i$ is composible with $g_{i-1}$ for $i = 2, \dots, \ell$. In this case we write $g_\ell \composed g_{\ell-1} \composed \cdots \composed g_2 \composed g_1$. For example, we write $g_3 \composed g_2 \composed g_1$ for $(g_1, g_2, g_3)$.</p></div><div class="sheet-listing"><p class="sheet"> A \t{neural network} (or \t{feedforward neural network}) from $\R^n$ to $\R^m$ is a sequence of composable functions $(g_1, \dots, g_{\ell})$, $\dom g_1 = \R^n$, $\ran g_\ell \subset \R^m$, satisfying \[ g_i(\xi) = h_i(A_i \xi + b_i) \] for some conforming matrices $A_i$, vectors $b_i$ and functions $h_i$.</p></div><div class="sheet-listing"><p class="sheet"> The $i$th \t{layer} of the neural network is the $i$th function $g_i$. The $i$th \t{activation} of the neural network is the function $h_i$. A \t{neural network} is called \t{deep} if its number of layers is larger than 3.</p></div><div class="sheet-listing"><p class="sheet"> We call the composition of the layers of the neural network the \t{network predictor} (or just \t{predictor}). We also call it \t{the function} of the network. \ifhmode\unskip\fi\footnote{ Many authorities refer to a neural network as a function. Strictly speaking that is true for us, as well, since a sequence is a function. But the meaning of the common use is in reference to the \t{network predictor}. }</p></div><div class="sheet-listing"><p class="sheet"> A \t{multi-layer perceptron} (\t{MLP}) is a neural network with 2 layers (1 \t{hidden layer}) and for which $A_i$ and $b_i$ have unrestricted nonzero entries.</p></div><div class="sheet-listing"><p class="sheet"> \blankpage</p></div>
    </div>

    <div style="display: flex; flex-direction: row; justify-content: center; flex-wrap: wrap">

    <div id="wrapper1">
      <canvas id="page1" style="direction: ltr;"></canvas>
    </div>
    <div id="wrapper2">
      <canvas id="page2" style="direction: ltr;"></canvas>
    </div>
    <div id="wrapper3">
    <canvas id="page3" style="direction: ltr;" onclick="location.href='./neural_networks-graph.pdf'"></canvas>
    </div>
      <script id="script">
        // If absolute URL from the remote server is provided, configure the CORS
        // header on that server.
        var url = './neural_networks.pdf';

        // The workerSrc property shall be specified.
        pdfjsLib.GlobalWorkerOptions.workerSrc =
          '../pdfjs/build/pdf.worker.js';

        var PRINT_RESOLUTION = 300;

        function render(page, wrapper, canvas) {
          var scale = 7;
          var viewport = page.getViewport({scale: scale});
          var context = canvas.getContext('2d');

          canvas.width = viewport.width;
          canvas.height = viewport.height;
          canvas.style.width = "100%";
          canvas.style.height = "100%";
          wrapper.style.width = Math.floor(viewport.width/scale) + 'pt';
          wrapper.style.height = Math.floor(viewport.height/scale) + 'pt';

          // see https://stackoverflow.com/questions/37861686/pdfjs-blurry-pdf-on-ipad
          // who knows if this works...
          context.imageSmoothingEnabled = false;
          context.webkitImageSmoothingEnabled = false;
          context.mozImageSmoothingEnabled = false;
          context.oImageSmoothingEnabled = false;

          /*

          if (window.devicePixelRatio > 1) {
            var canvasWidth = canvas.width;
            var canvasHeight = canvas.height;

            canvas.width = canvasWidth * window.devicePixelRatio;
            canvas.height = canvasHeight * window.devicePixelRatio;
            canvas.style.width = canvasWidth + "px";
            canvas.style.height = canvasHeight + "px";

            context.scale(window.devicePixelRatio, window.devicePixelRatio);
          }
          //end see
          */

          var renderContext = {
            canvasContext: context,
            viewport: viewport
          };
          page.render(renderContext);
        }

        // Asynchronous download PDF
        var loadingTask = pdfjsLib.getDocument(url);
        loadingTask.promise.then(function(pdf) {

          // Fetch the first page
          pdf.getPage(2).then(function(page) {
              render(page, document.getElementById('wrapper1'), document.getElementById('page1'));
          });

          // Fetch the second page
          pdf.getPage(3).then(function(page) {
            render(page, document.getElementById('wrapper2'), document.getElementById('page2'));
          });

          // Fetch the third page
          pdf.getPage(4).then(function(page) {
            render(page, document.getElementById('wrapper3'), document.getElementById('page3'));
          });
        });
      </script>

    <!-- PAGES -->
    <!--
    <iframe id="sheet-pdf" src="./neural_networks.pdf#page=2">
    </iframe>
    <iframe id="sheet-pdf" src="./neural_networks.pdf#page=3">
    </iframe>
    -->
    <!-- PAGES -->

    </div>

    <!-- <iframe id="graph-pdf" src="./neural_networks-graph.pdf">
    </iframe>
    -->

  
    <div class="lit">
    <p>
 <span class='run'>‚ù≤%!name:neural_networks‚ù≥ </span>

 <span class='run'>‚ù≤%!need:regressors‚ù≥ </span>

 <span class='run'>‚ù≤% %!need:inductors‚ù≥ </span>

 <span class='run'>‚ù≤%!need:real_matrix-vector_products‚ù≥ </span>

 <span class='run'>‚ù≤%!refs:‚àïsanjay_lall‚àïintroduction_to_machine_learning‚àïneural_networks‚ù≥ </span>
</p>


<p>
 <span class='run'>\ssection{Why}[footnote skipped in this version]</span>
</p>


<p>
 <span class='run'>\ssection{Definition} </span>
</p>


<p>
 <span class='run'>A sequence of functions $(g_1, ‚Ä¶, g_‚Ñì)$ is
  <span class='term'>composable</span> if $g_i$ is
  composible with $g_{i-1}$ for $i = 2, ‚Ä¶, ‚Ñì$. </span>

 <span class='run'>In this case we write $g_‚Ñì \composed g_{‚Ñì-1}
  \composed ‚ãØ \composed g_2 \composed g_1$. For
  example, we write $g_3 \composed g_2 \composed
  g_1$ for $(g_1, g_2, g_3)$. </span>
</p>


<p>
 <span class='run'>A <span class='term'>neural network</span> (or
  <span class='term'>feedforward neural network</span>)
  from $ùó•^n$ to $ùó•^m$ is a sequence of composable
  functions $(g_1, ‚Ä¶, g_{‚Ñì})$, $\dom g_1 = ùó•^n$,
  $\ran g_‚Ñì ‚äÇ ùó•^m$, satisfying
  <p>\[
   g_i(Œæ) = h_i(A_i Œæ + b_i) </span>
  \]</p>
  for some conforming matrices $A_i$, vectors
  $b_i$ and functions $h_i$. </span>
</p>


<p>
 <span class='run'>The $i$th <span class='term'>layer</span> of the
  neural network is the $i$th function $g_i$. </span>

 <span class='run'>The $i$th <span class='term'>activation</span> of
  the neural network is the function $h_i$. </span>

 <span class='run'>A <span class='term'>neural network</span> is
  called <span class='term'>deep</span> if its number
  of layers is larger than 3. </span>
</p>


<p>
 <span class='run'>We call the composition of the layers of the
  neural network the <span class='term'>network
  predictor</span> (or just
  <span class='term'>predictor</span>). </span>

 <span class='run'>We also call it <span class='term'>the
  function</span> of the network.[footnote skipped in this version]</span>
</p>


<p>
 <span class='run'>A <span class='term'>multi-layer perceptron</span>
  (<span class='term'>MLP</span>) is a neural network
  with 2 layers (1 <span class='term'>hidden
  layer</span>) and for which $A_i$ and $b_i$ have
  unrestricted nonzero entries. </span>
</p>


<p>
 <span class='run'></span>

 <span class='run'>‚ù≤% \ssubsection{Notation}‚ù≥ </span>

 <span class='run'>‚ù≤%‚ù≥ </span>

 <span class='run'>‚ù≤% Let $g^1: ùó•^d ‚Üí ùó•^k$, $g^2: ùó•^k ‚Üí ùó•^k$, $g^3: ùó•^k ‚Üí ùó•^m$.‚ù≥ </span>

 <span class='run'>‚ù≤% Then $(g^1, g^2, g^3)$ is a neural network.‚ù≥ </span>

 <span class='run'>‚ù≤% Notice that the codomain of $g^1$ ($ùó•^k$‚ù≥ </span>

 <span class='run'>‚ù≤%‚ù≥ </span>

 <span class='run'>‚ù≤% \ssubsection{Activation functions}‚ù≥ </span>

 <span class='run'>‚ù≤%‚ù≥ </span>

 <span class='run'>‚ù≤% An activation function $h: ùó• ‚Üí ùó•$ is nonlinear.‚ù≥ </span>
</p>


<p>
 <span class='run'>\blankpage </span>
</p>

    </div>
  

  <!--
  <div id="cy" style="height:1000px;width:1000px;">
  </div>
    <script>
      var cy = cytoscape({
        container: document.getElementById('cy'), // container to render in
                elements: [ // list of graph elements to start with
                            { // node a
                                          data: { id: 'a' }
                                        },
                            { // node b
                                          data: { id: 'b' }
                                        },
                            { // edge ab
                                          data: { id: 'ab', source: 'a', target: 'b' }
                                        }
                          ],

                style: [ // the stylesheet for the graph
                            {
                                          selector: 'node',
                                          style: {
                                                          'background-color': '#666',
                                                          'label': 'data(id)'
                                                        }
                                        },

                            {
                                          selector: 'edge',
                                          style: {
                                                          'width': 3,
                                                          'line-color': '#ccc',
                                                          'target-arrow-color': '#ccc',
                                                          'target-arrow-shape': 'triangle',
                                                          'curve-style': 'bezier'
                                                        }
                                        }
                          ],

                layout: {
                            name: 'grid',
                            rows: 1
                          }

      });
    </script>
    -->


    <span id="footer">
      Copyright 2022 The Bourbaki Authors. Version d1cba987d.
    </span>
  </body>
</html>
