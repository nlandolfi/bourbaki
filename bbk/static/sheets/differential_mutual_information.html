<!DOCTYPE html>
  <meta charset="utf-8"/>
  <head>
    <link rel="stylesheet" href="../style.css">
    <link rel="stylesheet" href="../fonts.css">
  </head>
  <body>
    <div class="header">
      <span class="listing no-border" id="header-trademark-and-title">
        <img id="header-trademark" src="../trademark.jpg" onclick="location.href='../index.html'">
        <span id="header-title" onclick="location.href='./differential_mutual_information.pdf'"> Differential Mutual Information </span>
      </span>
    </div>
    <div class="subheader">
      <div disabled class="need label"> Links: </div>
      <div class="need" tabindex="0" onclick="location.href='./differential_mutual_information.pdf'" onkeypress="location.href='./differential_mutual_information.pdf'">
        <span> Sheet PDF </span>
        <span class="caret">›</span>
      </div>
      <div class="need" tabindex="0" onclick="location.href='./differential_mutual_information-graph.pdf'" onkeypress="location.href='./differential_mutual_information-graph.pdf'">
        <span> Graph PDF </span>
        <span class="caret">›</span>
      </div>
      
        <div disabled class="need label"> Needs: </div>
        
            <div class="need" tabindex="0" onclick="location.href='./differential_relative_entropy.html'" onkeypress="location.href='./differential_relative_entropy.html'">
              <span>
                Differential Relative Entropy
              </span>
              <span class="caret">›</span>
            </div>
        
            <div class="need" tabindex="0" onclick="location.href='./marginal_densities.html'" onkeypress="location.href='./marginal_densities.html'">
              <span>
                Marginal Densities
              </span>
              <span class="caret">›</span>
            </div>
        
            <div class="need" tabindex="0" onclick="location.href='./mutual_information.html'" onkeypress="location.href='./mutual_information.html'">
              <span>
                Mutual Information
              </span>
              <span class="caret">›</span>
            </div>
        
      
      
        <div disabled class="need label"> Needed by: </div>
        
          <div class="need" tabindex="0" onclick="location.href='./differential_mutual_information_graph.html'" onkeypress="location.href='./differential_mutual_information_graph.html'">
            <span>
            Differential Mutual Information Graph
            </span>
            <span class="caret">›</span>
          </div>
        
          <div class="need" tabindex="0" onclick="location.href='./normal_differential_mutual_information.html'" onkeypress="location.href='./normal_differential_mutual_information.html'">
            <span>
            Normal Differential Mutual Information
            </span>
            <span class="caret">›</span>
          </div>
        
      
    </div>

      <link rel="stylesheet" href="../katex/katex.min.css">
      <script src="../katex/katex.min.js"></script>
      <script src="../katex/auto-render.min.js"></script>
      <script>
      document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(
          document.body,
          {
            delimiters: [
              {left: "$$", right: "$$", display: true},
              {left: "$", right: "$", display: false},
            ],
          },
        );
      });
    </script>
    <div id="sheet-card" class="card">
      <div class="sheet-listing" id="why"><h1 class="sheet">1. Why</h1></div><div class="sheet-listing" id="definition"><h1 class="sheet">2. Definition</h1></div><div class="sheet-listing"><h2 class="sheet" id="notation">2.1 Notation</h2></div><div class="sheet-listing"><p class="sheet"> The differential mutual information between $i$ and $j$th components of a multivariate density is the differential relative entropy of the $i,j$th marginal density with the product of the $i$th and $j$th marginal densities.</p></div><div class="sheet-listing"><h2 class="sheet" id="notation">2.2 Notation</h2></div><div class="sheet-listing"><p class="sheet"> Let $f: \R^d \to \R$. Let $d$ denote the differential relative entropy. The mutual information between $i$ and $j$ for $i,j = 1, \dots, d$ and $i \neq j$ is \[ d(f_{ij}, f_{i}f_{j}) \]</p></div>
    </div>

    <iframe id="sheet-pdf" src="./differential_mutual_information.pdf">
    </iframe>

    <iframe id="graph-pdf" src="./differential_mutual_information-graph.pdf">
    </iframe>

  </body>
</html>`
